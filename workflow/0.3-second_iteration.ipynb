{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b029f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c2b4506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedIterationCoder:\n",
    "    \"\"\"Enhanced IterationCoder that handles feedback loops and conversation history\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, model):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "    \n",
    "    def code_response(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"Code a response with conversation history support\"\"\"\n",
    "        question_data = state[\"question_data\"]\n",
    "        is_question_43 = state[\"is_question_43\"]\n",
    "        conversation_history = state.get(\"conversation_history\", [])\n",
    "        \n",
    "        # Prepare system and initial messages\n",
    "        if is_question_43:\n",
    "            system_msg = system_prompt_43\n",
    "            initial_msg = f\"{initial_prompt_43}\\n\\nQuestion: {question_data['Question']}\\n\\nStudent response: {question_data['Response']}\"\n",
    "        else:\n",
    "            system_msg = system_prompt\n",
    "            initial_msg = f\"{initial_prompt}\\n\\nQuestion: {question_data['Question']}\\n\\nStudent response: {question_data['Response']}\"\n",
    "        \n",
    "        # Build conversation with history\n",
    "        messages = [SystemMessage(content=system_msg)]\n",
    "        \n",
    "        # Add conversation history if available\n",
    "        if conversation_history:\n",
    "            messages.extend(conversation_history)\n",
    "        else:\n",
    "            # First iteration - add initial message\n",
    "            messages.append(HumanMessage(content=initial_msg))\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke(messages)\n",
    "            return {\n",
    "                \"iteration_name\": self.name,\n",
    "                \"raw_response\": response.content,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in {self.name}: {str(e)}\")\n",
    "            return {\n",
    "                \"iteration_name\": self.name,\n",
    "                \"raw_response\": f\"Error: {str(e)}\",\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"error\": True\n",
    "            }\n",
    "    \n",
    "    def code_with_feedback(self, state: AgentState, feedback: str) -> Dict[str, Any]:\n",
    "        \"\"\"Code with researcher feedback\"\"\"\n",
    "        question_data = state[\"question_data\"]\n",
    "        is_question_43 = state[\"is_question_43\"]\n",
    "        conversation_history = state.get(\"conversation_history\", [])\n",
    "        \n",
    "        # Prepare system message\n",
    "        if is_question_43:\n",
    "            system_msg = system_prompt_43\n",
    "        else:\n",
    "            system_msg = system_prompt\n",
    "        \n",
    "        # Build conversation with history and feedback\n",
    "        messages = [SystemMessage(content=system_msg)]\n",
    "        messages.extend(conversation_history)\n",
    "        \n",
    "        # Add feedback message\n",
    "        feedback_msg = f\"\"\"Based on the researcher's feedback, please recode the response:\n",
    "\n",
    "                            Researcher Feedback: {feedback}\n",
    "\n",
    "                            Please provide your coding in the specified output format: {OUTPUT_FORMAT if not is_question_43 else OUTPUT_FORMAT_43}\n",
    "\n",
    "                            JUST RETURN THE DESIRED OUTPUT, DO NOT ADD ANYTHING ELSE.\n",
    "                            Return a single valid JSON object ONLY.\n",
    "                            No markdown, no backticks, no prose.\"\"\"\n",
    "        \n",
    "        messages.append(HumanMessage(content=feedback_msg))\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke(messages)\n",
    "            return {\n",
    "                \"iteration_name\": self.name,\n",
    "                \"raw_response\": response.content,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"with_feedback\": True\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in {self.name} with feedback: {str(e)}\")\n",
    "            return {\n",
    "                \"iteration_name\": self.name,\n",
    "                \"raw_response\": f\"Error: {str(e)}\",\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"error\": True,\n",
    "                \"with_feedback\": True\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0696b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff56c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc31f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc4dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a2651a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenticCodingSystem:\n",
    "    \"\"\"Main agentic coding system using LangGraph\"\"\"\n",
    "    \n",
    "    def __init__(self, model, log_file: str = \"agreement_logs.txt\"):\n",
    "        self.model = model\n",
    "        self.log_file = log_file\n",
    "        \n",
    "        # Initialize agents\n",
    "        self.orchestrator = OrchestratorAgent(model)\n",
    "        self.researcher = ResearcherAgent(model)\n",
    "        self.agreement_calculator = AgreementCalculator()\n",
    "        \n",
    "        # Build the graph\n",
    "        self.graph = self._build_graph()\n",
    "    \n",
    "    def _build_graph(self) -> StateGraph:\n",
    "        \"\"\"Build the LangGraph workflow\"\"\"\n",
    "        workflow = StateGraph(AgentState)\n",
    "        \n",
    "        # Add nodes\n",
    "        workflow.add_node(\"initial_iterations\", run_initial_iterations_node)\n",
    "        workflow.add_node(\"final_decision\", make_final_decision_node)\n",
    "        workflow.add_node(\"validate\", validate_coding_node)\n",
    "        workflow.add_node(\"feedback_loop\", handle_feedback_loop_node)\n",
    "        workflow.add_node(\"log_metrics\", log_metrics_node)\n",
    "        \n",
    "        # Set entry point\n",
    "        workflow.set_entry_point(\"initial_iterations\")\n",
    "        \n",
    "        # Add edges\n",
    "        workflow.add_edge(\"initial_iterations\", \"log_metrics\")\n",
    "        workflow.add_edge(\"log_metrics\", \"final_decision\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"final_decision\",\n",
    "            should_validate,\n",
    "            {\n",
    "                \"validate\": \"validate\",\n",
    "                \"end\": END\n",
    "            }\n",
    "        )\n",
    "        workflow.add_conditional_edges(\n",
    "            \"validate\",\n",
    "            should_continue_workflow,\n",
    "            {\n",
    "                \"feedback_loop\": \"feedback_loop\",\n",
    "                \"end\": END\n",
    "            }\n",
    "        )\n",
    "        workflow.add_edge(\"feedback_loop\", \"log_metrics\")\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    def process_question(self, response_id: str, question_key: str, question_data: Dict[str, Any], \n",
    "                        max_iterations: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"Process a single question through the agentic system\"\"\"\n",
    "        \n",
    "        # Determine if it's question 43\n",
    "        question_num = question_key.split(\" \")[1] if \" \" in question_key else question_key\n",
    "        is_question_43 = (question_num == \"43\")\n",
    "        \n",
    "        # Initialize state\n",
    "        initial_state = AgentState(\n",
    "            response_id=response_id,\n",
    "            question_key=question_key,\n",
    "            question_data=question_data,\n",
    "            is_question_43=is_question_43,\n",
    "            iteration_results=[],\n",
    "            final_codes=None,\n",
    "            conversation_history=[],\n",
    "            agreement_metrics={},\n",
    "            researcher_feedback=None,\n",
    "            max_iterations=max_iterations,\n",
    "            current_iteration=0,\n",
    "            is_complete=False,\n",
    "            needs_feedback=False,\n",
    "            orchestrator=self.orchestrator,\n",
    "            researcher=self.researcher,\n",
    "            agreement_calculator=self.agreement_calculator,\n",
    "            log_file=self.log_file\n",
    "        )\n",
    "        \n",
    "        # Run the workflow\n",
    "        try:\n",
    "            final_state = self.graph.invoke(initial_state)\n",
    "            \n",
    "            # Mark as complete\n",
    "            final_state[\"is_complete\"] = True\n",
    "            \n",
    "            # Final log\n",
    "            self.agreement_calculator.log_agreement_metrics(final_state, self.log_file)\n",
    "            \n",
    "            return {\n",
    "                \"response_id\": response_id,\n",
    "                \"question_key\": question_key,\n",
    "                \"final_codes\": final_state[\"final_codes\"],\n",
    "                \"iteration_results\": final_state[\"iteration_results\"],\n",
    "                \"researcher_feedback\": final_state[\"researcher_feedback\"],\n",
    "                \"agreement_metrics\": final_state[\"agreement_metrics\"],\n",
    "                \"conversation_history\": final_state[\"conversation_history\"],\n",
    "                \"total_iterations\": final_state[\"current_iteration\"]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {response_id} - {question_key}: {str(e)}\")\n",
    "            return {\n",
    "                \"response_id\": response_id,\n",
    "                \"question_key\": question_key,\n",
    "                \"error\": str(e),\n",
    "                \"final_codes\": None\n",
    "            }\n",
    "    \n",
    "    def process_survey_file(self, survey_file_path: str, output_dir: str = \"agentic_coding_results\") -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process an entire survey file\"\"\"\n",
    "        \n",
    "        # Create output directory\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load survey data\n",
    "        with open(survey_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            survey_data = json.load(f)\n",
    "        \n",
    "        response_id = survey_data.get(\"ResponseId\", \"\")\n",
    "        results = []\n",
    "        \n",
    "        logger.info(f\"Processing survey file: {survey_file_path}\")\n",
    "        \n",
    "        # Process each question\n",
    "        for key, value in survey_data.items():\n",
    "            if key.startswith(\"Question \") and isinstance(value, dict) and \"Response\" in value:\n",
    "                logger.info(f\"Processing {key} for response {response_id}\")\n",
    "                \n",
    "                result = self.process_question(response_id, key, value)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Save individual result\n",
    "                result_file = output_path / f\"{response_id}_{key.replace(' ', '_')}_result.json\"\n",
    "                with open(result_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save combined results\n",
    "        combined_file = output_path / f\"{response_id}_all_results.json\"\n",
    "        with open(combined_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"Completed processing {response_id}. Results saved to {output_path}\")\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198912bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage and testing\n",
    "# def test_agentic_system():\n",
    "#     \"\"\"Test the agentic coding system with a sample question\"\"\"\n",
    "    \n",
    "#     # Initialize the system\n",
    "#     system = AgenticCodingSystem(model_azure, log_file=\"test_agreement_logs.txt\")\n",
    "    \n",
    "#     # Sample question data\n",
    "#     sample_question_data = {\n",
    "#         \"Question\": \"Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?\",\n",
    "#         \"Response\": \"AI tends to be more uplifting or supportive than teachers, so when I ask for its opinion on something I've written it'll compliment whereas my teacher will have edits to my work. Both are useful and important.\"\n",
    "#     }\n",
    "    \n",
    "#     # Process the question\n",
    "#     result = system.process_question(\n",
    "#         response_id=\"TEST_001\",\n",
    "#         question_key=\"Question 40\",\n",
    "#         question_data=sample_question_data,\n",
    "#         max_iterations=3\n",
    "#     )\n",
    "    \n",
    "#     print(\"Processing Result:\")\n",
    "#     print(json.dumps(result, indent=2))\n",
    "    \n",
    "#     return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "540c72f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_result = test_agentic_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1cc70e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_surveys(survey_dir: str = \"temp_survey\", output_dir: str = \"agentic_coding_results\"):\n",
    "    \"\"\"Process multiple survey files using the fixed agentic system\"\"\"\n",
    "    \n",
    "    # Initialize the fixed system\n",
    "    system = FixedAgenticCodingSystem(model_azure, log_file=f\"{output_dir}/agreement_logs.txt\")\n",
    "    \n",
    "    # Get survey files\n",
    "    survey_path = Path(survey_dir)\n",
    "    survey_files = [f for f in survey_path.glob(\"*.json\") if f.name != \".DS_Store\"]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for survey_file in survey_files:\n",
    "        print(f\"Processing {survey_file.name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load survey data\n",
    "            with open(survey_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                survey_data = json.load(f)\n",
    "            \n",
    "            response_id = survey_data.get(\"ResponseId\", \"\")\n",
    "            results = []\n",
    "            \n",
    "            logger.info(f\"Processing survey file: {survey_file}\")\n",
    "            \n",
    "            # Process each question\n",
    "            for key, value in survey_data.items():\n",
    "                if key.startswith(\"Question \") and isinstance(value, dict) and \"Response\" in value:\n",
    "                    logger.info(f\"Processing {key} for response {response_id}\")\n",
    "                    \n",
    "                    result = system.process_question_simple(response_id, key, value)\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Save individual result\n",
    "                    result_file = Path(output_dir) / f\"{response_id}_{key.replace(' ', '_')}_result.json\"\n",
    "                    with open(result_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            # Save combined results for this response\n",
    "            combined_file = Path(output_dir) / f\"{response_id}_all_results.json\"\n",
    "            with open(combined_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            all_results.extend(results)\n",
    "            logger.info(f\"Completed processing {response_id}. Results saved to {output_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {survey_file.name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save all results\n",
    "    combined_file = Path(output_dir) / \"all_agentic_results.json\"\n",
    "    with open(combined_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nCompleted processing {len(survey_files)} survey files\")\n",
    "    print(f\"Total results: {len(all_results)}\")\n",
    "    print(f\"Combined results saved to: {combined_file}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Uncomment to run batch processing\n",
    "# batch_results = process_multiple_surveys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "13b488b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing survey file: temp_survey/R_4C4j4KNUq9N3VGC.json\n",
      "INFO:__main__:Processing Question 40 for response R_4C4j4KNUq9N3VGC\n",
      "INFO:__main__:Processing R_4C4j4KNUq9N3VGC - Question 40\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4C4j4KNUq9N3VGC.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4CKOoHgU8hp01rg.json\n",
      "INFO:__main__:Processing Question 40 for response R_4CKOoHgU8hp01rg\n",
      "INFO:__main__:Processing R_4CKOoHgU8hp01rg - Question 40\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing R_4C4j4KNUq9N3VGC.json: Object of type HumanMessage is not JSON serializable\n",
      "Processing R_4CKOoHgU8hp01rg.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[190]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m batch_results = \u001b[43mprocess_multiple_surveys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[189]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mprocess_multiple_surveys\u001b[39m\u001b[34m(survey_dir, output_dir)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key.startswith(\u001b[33m\"\u001b[39m\u001b[33mQuestion \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mResponse\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[32m     29\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for response \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     result = \u001b[43msystem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_question_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     results.append(result)\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Save individual result\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[187]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mFixedAgenticCodingSystem.process_question_simple\u001b[39m\u001b[34m(self, response_id, question_key, question_data, max_iterations)\u001b[39m\n\u001b[32m     28\u001b[39m conversation_history = []\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m coder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.orchestrator.iteration_coders:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     result = \u001b[43mcoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcode_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis_question_43\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_question_43\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation_history\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_history\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     iteration_results.append(result)\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Parse the response\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mEnhancedIterationCoder.code_response\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     30\u001b[39m     messages.append(HumanMessage(content=initial_msg))\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     35\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33miteration_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mraw_response\u001b[39m\u001b[33m\"\u001b[39m: response.content,\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: datetime.now().isoformat()\n\u001b[32m     38\u001b[39m     }\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:393\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> BaseMessage:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    403\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1019\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m     **kwargs: Any,\n\u001b[32m   1017\u001b[39m ) -> LLMResult:\n\u001b[32m   1018\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:837\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    836\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    843\u001b[39m         )\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    845\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1085\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1083\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1178\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1172\u001b[39m             response,\n\u001b[32m   1173\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1174\u001b[39m             metadata=generation_info,\n\u001b[32m   1175\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1176\u001b[39m         )\n\u001b[32m   1177\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1179\u001b[39m         response = raw_response.parse()\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quali_project/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "batch_results = process_multiple_surveys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c742bca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing survey file: temp_survey/R_4C4j4KNUq9N3VGC.json\n",
      "INFO:__main__:Processing Question 40 for response R_4C4j4KNUq9N3VGC\n",
      "INFO:__main__:Processing R_4C4j4KNUq9N3VGC - Question 40\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4C4j4KNUq9N3VGC.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_4C4j4KNUq9N3VGC\n",
      "INFO:__main__:Processing R_4C4j4KNUq9N3VGC - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_4C4j4KNUq9N3VGC\n",
      "INFO:__main__:Processing R_4C4j4KNUq9N3VGC - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 21.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4C4j4KNUq9N3VGC. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4CKOoHgU8hp01rg.json\n",
      "INFO:__main__:Processing Question 40 for response R_4CKOoHgU8hp01rg\n",
      "INFO:__main__:Processing R_4CKOoHgU8hp01rg - Question 40\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4CKOoHgU8hp01rg.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_4CKOoHgU8hp01rg\n",
      "INFO:__main__:Processing R_4CKOoHgU8hp01rg - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 10.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_4CKOoHgU8hp01rg\n",
      "INFO:__main__:Processing R_4CKOoHgU8hp01rg - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4CKOoHgU8hp01rg. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_43e00PZDT3YYIZ2.json\n",
      "INFO:__main__:Processing Question 43 for response R_43e00PZDT3YYIZ2\n",
      "INFO:__main__:Processing R_43e00PZDT3YYIZ2 - Question 43\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_43e00PZDT3YYIZ2.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Handling feedback loop...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 8.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_43e00PZDT3YYIZ2. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4P0PnRK3k4DjAxR.json\n",
      "INFO:__main__:Processing Question 40 for response R_4P0PnRK3k4DjAxR\n",
      "INFO:__main__:Processing R_4P0PnRK3k4DjAxR - Question 40\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4P0PnRK3k4DjAxR.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 6.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Handling feedback loop...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 6.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 7.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_4P0PnRK3k4DjAxR\n",
      "INFO:__main__:Processing R_4P0PnRK3k4DjAxR - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 10.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 6.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_4P0PnRK3k4DjAxR\n",
      "INFO:__main__:Processing R_4P0PnRK3k4DjAxR - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4P0PnRK3k4DjAxR. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4Ka5vRl3NuBJ1Af.json\n",
      "INFO:__main__:Processing Question 40 for response R_4Ka5vRl3NuBJ1Af\n",
      "INFO:__main__:Processing R_4Ka5vRl3NuBJ1Af - Question 40\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 7.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4Ka5vRl3NuBJ1Af.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_4Ka5vRl3NuBJ1Af\n",
      "INFO:__main__:Processing R_4Ka5vRl3NuBJ1Af - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 8.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 7.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_4Ka5vRl3NuBJ1Af\n",
      "INFO:__main__:Processing R_4Ka5vRl3NuBJ1Af - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4Ka5vRl3NuBJ1Af. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4AYVtTmMd0q7vte.json\n",
      "INFO:__main__:Processing Question 40 for response R_4AYVtTmMd0q7vte\n",
      "INFO:__main__:Processing R_4AYVtTmMd0q7vte - Question 40\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4AYVtTmMd0q7vte.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_4AYVtTmMd0q7vte\n",
      "INFO:__main__:Processing R_4AYVtTmMd0q7vte - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 9.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_4AYVtTmMd0q7vte\n",
      "INFO:__main__:Processing R_4AYVtTmMd0q7vte - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 5.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4AYVtTmMd0q7vte. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_1gTNWbmwxtRxrf8.json\n",
      "INFO:__main__:Processing Question 40 for response R_1gTNWbmwxtRxrf8\n",
      "INFO:__main__:Processing R_1gTNWbmwxtRxrf8 - Question 40\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 11.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_1gTNWbmwxtRxrf8.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_1gTNWbmwxtRxrf8\n",
      "INFO:__main__:Processing R_1gTNWbmwxtRxrf8 - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 9.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_1gTNWbmwxtRxrf8\n",
      "INFO:__main__:Processing R_1gTNWbmwxtRxrf8 - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_1gTNWbmwxtRxrf8. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4sn9pI5HdvhV5gI.json\n",
      "INFO:__main__:Processing Question 43 for response R_4sn9pI5HdvhV5gI\n",
      "INFO:__main__:Processing R_4sn9pI5HdvhV5gI - Question 43\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 11.000000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4sn9pI5HdvhV5gI.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4sn9pI5HdvhV5gI. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_1VQ5hmwtdpRmnmu.json\n",
      "INFO:__main__:Processing Question 40 for response R_1VQ5hmwtdpRmnmu\n",
      "INFO:__main__:Processing R_1VQ5hmwtdpRmnmu - Question 40\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_1VQ5hmwtdpRmnmu.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 6.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 9.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 41 for response R_1VQ5hmwtdpRmnmu\n",
      "INFO:__main__:Processing R_1VQ5hmwtdpRmnmu - Question 41\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Processing Question 42 for response R_1VQ5hmwtdpRmnmu\n",
      "INFO:__main__:Processing R_1VQ5hmwtdpRmnmu - Question 42\n",
      "INFO:__main__:Running initial iterations...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 12.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_1VQ5hmwtdpRmnmu. Results saved to agentic_coding_results\n",
      "INFO:__main__:Processing survey file: temp_survey/R_4aRLJoWmhKsYLOF.json\n",
      "INFO:__main__:Processing Question 43 for response R_4aRLJoWmhKsYLOF\n",
      "INFO:__main__:Processing R_4aRLJoWmhKsYLOF - Question 43\n",
      "INFO:__main__:Running initial iterations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4aRLJoWmhKsYLOF.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 6.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Logging initial metrics...\n",
      "INFO:__main__:Making final decision...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 7.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Running researcher validation...\n",
      "INFO:httpx:HTTP Request: POST https://cic-topic-modeling.openai.azure.com/openai/deployments/gpt-4-32k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Completed processing R_4aRLJoWmhKsYLOF. Results saved to agentic_coding_results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed processing 10 survey files\n",
      "Total results: 24\n",
      "Combined results saved to: agentic_coding_results/all_agentic_results.json\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6094ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fixed version of the AgenticCodingSystem\n",
    "# class FixedAgenticCodingSystem:\n",
    "#     \"\"\"Fixed version of the agentic coding system\"\"\"\n",
    "    \n",
    "#     def __init__(self, model, log_file: str = \"agreement_logs.txt\"):\n",
    "#         self.model = model\n",
    "#         self.log_file = log_file\n",
    "        \n",
    "#         # Initialize agents\n",
    "#         self.orchestrator = OrchestratorAgent(model)\n",
    "#         self.researcher = ResearcherAgent(model)\n",
    "#         self.agreement_calculator = AgreementCalculator()\n",
    "    \n",
    "#     def process_question_simple(self, response_id: str, question_key: str, question_data: Dict[str, Any], \n",
    "#                                max_iterations: int = 3) -> Dict[str, Any]:\n",
    "#         \"\"\"Process a single question through the agentic system (simplified version)\"\"\"\n",
    "        \n",
    "#         # Determine if it's question 43\n",
    "#         question_num = question_key.split(\" \")[1] if \" \" in question_key else question_key\n",
    "#         is_question_43 = (question_num == \"43\")\n",
    "        \n",
    "#         logger.info(f\"Processing {response_id} - {question_key}\")\n",
    "        \n",
    "#         try:\n",
    "#             # Step 1: Run initial iterations\n",
    "#             logger.info(\"Running initial iterations...\")\n",
    "#             iteration_results = []\n",
    "#             conversation_history = []\n",
    "            \n",
    "#             for coder in self.orchestrator.iteration_coders:\n",
    "#                 result = coder.code_response({\n",
    "#                     \"question_data\": question_data,\n",
    "#                     \"is_question_43\": is_question_43,\n",
    "#                     \"conversation_history\": conversation_history\n",
    "#                 })\n",
    "#                 iteration_results.append(result)\n",
    "                \n",
    "#                 # Parse the response\n",
    "#                 parsed_obj, error = parse_iteration_json(result[\"raw_response\"])\n",
    "#                 result[\"parsed_response\"] = parsed_obj\n",
    "#                 result[\"parse_error\"] = error\n",
    "                \n",
    "#                 # Add to conversation history\n",
    "#                 if not result.get(\"error\", False):\n",
    "#                     conversation_history.append(HumanMessage(content=result[\"raw_response\"]))\n",
    "            \n",
    "#             # Step 2: Log initial metrics\n",
    "#             logger.info(\"Logging initial metrics...\")\n",
    "#             iteration_agreement = self.agreement_calculator.calculate_iteration_agreement(iteration_results)\n",
    "            \n",
    "#             # Step 3: Make final decision\n",
    "#             logger.info(\"Making final decision...\")\n",
    "#             valid_results = [r for r in iteration_results if not r.get(\"error\", False) and r.get(\"parsed_response\")]\n",
    "            \n",
    "#             if not valid_results:\n",
    "#                 logger.warning(\"No valid iteration results found\")\n",
    "#                 final_codes = {\"error\": \"No valid coding results\"}\n",
    "#             else:\n",
    "#                 # Use the orchestrator model to make final decision\n",
    "#                 decision_prompt = f\"\"\"As an expert researcher, you need to make a final decision on the coding for this question based on three iterations.\n",
    "\n",
    "# Question: {question_data['Question']}\n",
    "# Student Response: {question_data['Response']}\n",
    "\n",
    "# Iteration Results:\n",
    "# \"\"\"\n",
    "                \n",
    "#                 for i, result in enumerate(valid_results, 1):\n",
    "#                     decision_prompt += f\"\\nIteration {i}:\\n{json.dumps(result['parsed_response'], indent=2)}\\n\"\n",
    "                \n",
    "#                 decision_prompt += f\"\"\"\n",
    "\n",
    "# Please analyze these iterations and provide the final coding decision. Consider:\n",
    "# 1. Consistency across iterations\n",
    "# 2. Quality of reasoning\n",
    "# 3. Adherence to coding framework\n",
    "\n",
    "# Provide your final decision in the same format: {OUTPUT_FORMAT if not is_question_43 else OUTPUT_FORMAT_43}\n",
    "\n",
    "# JUST RETURN THE DESIRED OUTPUT, DO NOT ADD ANYTHING ELSE.\n",
    "# Return a single valid JSON object ONLY.\n",
    "# No markdown, no backticks, no prose.\"\"\"\n",
    "\n",
    "#                 try:\n",
    "#                     response = self.model.invoke([HumanMessage(content=decision_prompt)])\n",
    "#                     final_obj, error = parse_iteration_json(response.content)\n",
    "#                     final_codes = final_obj if final_obj else {\"_raw\": response.content, \"_error\": error}\n",
    "#                 except Exception as e:\n",
    "#                     logger.error(f\"Error in final decision: {str(e)}\")\n",
    "#                     final_codes = {\"error\": str(e)}\n",
    "            \n",
    "#             # Step 4: Researcher validation\n",
    "#             logger.info(\"Running researcher validation...\")\n",
    "#             validation_prompt = f\"\"\"As a senior researcher, you need to validate the final coding decision for this question.\n",
    "\n",
    "# Question: {question_data['Question']}\n",
    "# Student Response: {question_data['Response']}\n",
    "\n",
    "# Final Coding Decision:\n",
    "# {json.dumps(final_codes, indent=2)}\n",
    "\n",
    "# Original Iteration Results:\n",
    "# \"\"\"\n",
    "            \n",
    "#             for i, result in enumerate(iteration_results, 1):\n",
    "#                 validation_prompt += f\"\\nIteration {i}:\\n{json.dumps(result.get('parsed_response', {}), indent=2)}\\n\"\n",
    "            \n",
    "#             validation_prompt += \"\"\"\n",
    "\n",
    "# Please provide your validation in the following JSON format:\n",
    "# {\n",
    "#     \"agreement\": true/false,\n",
    "#     \"quality_score\": 1-5,\n",
    "#     \"feedback\": \"Detailed feedback explaining your decision\",\n",
    "#     \"discrepancies\": [\"list of major issues if any\"],\n",
    "#     \"recommendations\": [\"list of suggestions for improvement if any\"]\n",
    "# }\n",
    "\n",
    "# Consider:\n",
    "# 1. Accuracy of coding according to the framework\n",
    "# 2. Consistency with iteration results\n",
    "# 3. Quality of reasoning\n",
    "# 4. Completeness of analysis\n",
    "# 5. Adherence to coding strategy\n",
    "\n",
    "# JUST RETURN THE DESIRED OUTPUT, DO NOT ADD ANYTHING ELSE.\n",
    "# Return a single valid JSON object ONLY.\n",
    "# No markdown, no backticks, no prose.\"\"\"\n",
    "\n",
    "#             try:\n",
    "#                 response = self.model.invoke([HumanMessage(content=validation_prompt)])\n",
    "#                 validation_obj, error = parse_iteration_json(response.content)\n",
    "                \n",
    "#                 if validation_obj:\n",
    "#                     researcher_feedback = validation_obj\n",
    "#                     needs_feedback = not validation_obj.get(\"agreement\", False)\n",
    "#                 else:\n",
    "#                     logger.error(f\"Failed to parse researcher validation: {error}\")\n",
    "#                     researcher_feedback = {\"agreement\": True, \"error\": error}\n",
    "#                     needs_feedback = False\n",
    "                    \n",
    "#             except Exception as e:\n",
    "#                 logger.error(f\"Error in researcher validation: {str(e)}\")\n",
    "#                 researcher_feedback = {\"agreement\": True, \"error\": str(e)}\n",
    "#                 needs_feedback = False\n",
    "            \n",
    "#             # Step 5: Handle feedback loop if needed\n",
    "#             current_iteration = 1\n",
    "#             if needs_feedback and current_iteration < max_iterations:\n",
    "#                 logger.info(\"Handling feedback loop...\")\n",
    "#                 feedback = researcher_feedback.get(\"feedback\", \"\")\n",
    "                \n",
    "#                 # Run new iterations with feedback\n",
    "#                 new_iteration_results = []\n",
    "#                 for coder in self.orchestrator.iteration_coders:\n",
    "#                     result = coder.code_with_feedback({\n",
    "#                         \"question_data\": question_data,\n",
    "#                         \"is_question_43\": is_question_43,\n",
    "#                         \"conversation_history\": conversation_history\n",
    "#                     }, feedback)\n",
    "#                     new_iteration_results.append(result)\n",
    "                    \n",
    "#                     # Parse the response\n",
    "#                     parsed_obj, error = parse_iteration_json(result[\"raw_response\"])\n",
    "#                     result[\"parsed_response\"] = parsed_obj\n",
    "#                     result[\"parse_error\"] = error\n",
    "                    \n",
    "#                     # Add to conversation history\n",
    "#                     if not result.get(\"error\", False):\n",
    "#                         conversation_history.append(HumanMessage(content=result[\"raw_response\"]))\n",
    "                \n",
    "#                 iteration_results = new_iteration_results\n",
    "#                 current_iteration += 1\n",
    "                \n",
    "#                 # Recalculate agreement\n",
    "#                 iteration_agreement = self.agreement_calculator.calculate_iteration_agreement(iteration_results)\n",
    "            \n",
    "#             # Step 6: Final logging\n",
    "#             timestamp = datetime.now().isoformat()\n",
    "#             log_entry = {\n",
    "#                 \"timestamp\": timestamp,\n",
    "#                 \"response_id\": response_id,\n",
    "#                 \"question_key\": question_key,\n",
    "#                 \"iteration\": current_iteration,\n",
    "#                 \"iteration_agreement\": iteration_agreement,\n",
    "#                 \"researcher_feedback\": researcher_feedback,\n",
    "#                 \"needs_feedback\": needs_feedback\n",
    "#             }\n",
    "            \n",
    "#             # Append to log file\n",
    "#             with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "#                 f.write(json.dumps(log_entry) + \"\\n\")\n",
    "            \n",
    "#             return {\n",
    "#                 \"response_id\": response_id,\n",
    "#                 \"question_key\": question_key,\n",
    "#                 \"final_codes\": final_codes,\n",
    "#                 \"iteration_results\": iteration_results,\n",
    "#                 \"researcher_feedback\": researcher_feedback,\n",
    "#                 \"agreement_metrics\": {\n",
    "#                     \"iteration_agreement\": iteration_agreement,\n",
    "#                     \"timestamp\": timestamp\n",
    "#                 },\n",
    "#                 \"conversation_history\": conversation_history,\n",
    "#                 \"total_iterations\": current_iteration\n",
    "#             }\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error processing {response_id} - {question_key}: {str(e)}\")\n",
    "#             return {\n",
    "#                 \"response_id\": response_id,\n",
    "#                 \"question_key\": question_key,\n",
    "#                 \"error\": str(e),\n",
    "#                 \"final_codes\": None\n",
    "#             }\n",
    "\n",
    "# # Test the fixed system\n",
    "# def test_fixed_agentic_system():\n",
    "#     \"\"\"Test the fixed agentic coding system\"\"\"\n",
    "    \n",
    "#     try:\n",
    "#         # Initialize the system\n",
    "#         system = FixedAgenticCodingSystem(model_azure, log_file=\"test_agreement_logs_fixed.txt\")\n",
    "        \n",
    "#         # Sample question data\n",
    "#         sample_question_data = {\n",
    "#             \"Question\": \"Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?\",\n",
    "#             \"Response\": \"AI tends to be more uplifting or supportive than teachers, so when I ask for its opinion on something I've written it'll compliment whereas my teacher will have edits to my work. Both are useful and important.\"\n",
    "#         }\n",
    "        \n",
    "#         # Process the question\n",
    "#         result = system.process_question_simple(\n",
    "#             response_id=\"TEST_001\",\n",
    "#             question_key=\"Question 40\",\n",
    "#             question_data=sample_question_data,\n",
    "#             max_iterations=3\n",
    "#         )\n",
    "        \n",
    "#         print(\"Processing Result:\")\n",
    "#         print(json.dumps(result, indent=2))\n",
    "        \n",
    "#         return result\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in test_fixed_agentic_system: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         return None\n",
    "\n",
    "# # Run the fixed test\n",
    "# test_result_fixed = test_fixed_agentic_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76832cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4ac47b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>Question</th>\n",
       "      <th>Human_Actor_Comparator</th>\n",
       "      <th>Human_Characteristics</th>\n",
       "      <th>Agentic_Actor_Comparator</th>\n",
       "      <th>Agentic_Characteristics</th>\n",
       "      <th>Agentic_Themes</th>\n",
       "      <th>Agentic_SubThemes</th>\n",
       "      <th>Agentic_Reasonings</th>\n",
       "      <th>Researcher_Agreement</th>\n",
       "      <th>Quality_Score</th>\n",
       "      <th>Total_Iterations</th>\n",
       "      <th>Iteration_Agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_4C4j4KNUq9N3VGC</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[A-more, T-more, T-more]</td>\n",
       "      <td>[Speed, Personal, In-depth]</td>\n",
       "      <td>[A-More, T-More, T-More]</td>\n",
       "      <td>[Speed, Personal, Understanding]</td>\n",
       "      <td>[Processes, Relational, Sense-making]</td>\n",
       "      <td>[Access, Relational, Sense-making]</td>\n",
       "      <td>[The phrase 'GenAI gives instant answers anyti...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_4C4j4KNUq9N3VGC</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[A-more, T-more]</td>\n",
       "      <td>[No impact, Positive]</td>\n",
       "      <td>[A-More, T-More, T-More]</td>\n",
       "      <td>[Less effort, Personal, Positivity]</td>\n",
       "      <td>[Processes, Relational, Information]</td>\n",
       "      <td>[Effort, Relational, Tone]</td>\n",
       "      <td>[The term 'efficient' suggests that GenAI feed...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_4C4j4KNUq9N3VGC</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[A-more, T-more, T-more]</td>\n",
       "      <td>[Speed, Specificity, Personal]</td>\n",
       "      <td>[A-More, A-More, T-More, T-More]</td>\n",
       "      <td>[Speed, Objective, In-depth, Personal]</td>\n",
       "      <td>[Processes, Information, Information, Relational]</td>\n",
       "      <td>[Access, Quality, Quality, Relational]</td>\n",
       "      <td>[The phrase 'GenAI feedback was quicker' direc...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_4CKOoHgU8hp01rg</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[A-more, A-less]</td>\n",
       "      <td>[Speed, In-depth]</td>\n",
       "      <td>[A-More, A-Less, T-More, T-More, A-Less, T-Mor...</td>\n",
       "      <td>[Speed, In-depth, In-depth, Understanding, Per...</td>\n",
       "      <td>[Processes, Information, Information, Sense-ma...</td>\n",
       "      <td>[Access, Quality, Quality, Understanding, Rela...</td>\n",
       "      <td>[The phrase 'Provides instant feedback' direct...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_4CKOoHgU8hp01rg</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R_4CKOoHgU8hp01rg</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[A-more, T-more, A-less, T-more]</td>\n",
       "      <td>[Speed, Contextualised, Relevance, Personal]</td>\n",
       "      <td>[A-Less, T-More, T-More, A-More, A-Less, T-Mor...</td>\n",
       "      <td>[In-depth, Specificity, Personal, Speed, Conte...</td>\n",
       "      <td>[Information, Information, Relational, Process...</td>\n",
       "      <td>[Quality, Quality, Relational, Access, Quality...</td>\n",
       "      <td>[The statement 'sometimes lacks detailed, pers...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R_43e00PZDT3YYIZ2</td>\n",
       "      <td>Question 43</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unaware, Contextualised]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Unaware, Contextualised, Unaware]</td>\n",
       "      <td>[Processes, Information, Processes]</td>\n",
       "      <td>[Access, Quality, Access]</td>\n",
       "      <td>[The student states 'I didn't know how / if ge...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R_4P0PnRK3k4DjAxR</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[A-more]</td>\n",
       "      <td>[Ease]</td>\n",
       "      <td>[A-More, T-Less]</td>\n",
       "      <td>[Ease, Personal]</td>\n",
       "      <td>[Processes, Information]</td>\n",
       "      <td>[Access, Quality]</td>\n",
       "      <td>[The phrase 'more convenient/timely to get fee...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R_4P0PnRK3k4DjAxR</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[A-more]</td>\n",
       "      <td>[Understanding]</td>\n",
       "      <td>[A-More]</td>\n",
       "      <td>[Understanding]</td>\n",
       "      <td>[Sense-making]</td>\n",
       "      <td>[Sense-making]</td>\n",
       "      <td>[The statement 'you can ask the AI to explain ...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R_4P0PnRK3k4DjAxR</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R_4Ka5vRl3NuBJ1Af</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[A-less, T-more]</td>\n",
       "      <td>[Specificity, Contextualised]</td>\n",
       "      <td>[A-More, T-More, T-More]</td>\n",
       "      <td>[Volume, Personal, Specificity]</td>\n",
       "      <td>[Information, Relational, Information]</td>\n",
       "      <td>[Quality, Relational, Quality]</td>\n",
       "      <td>[The phrase 'broader in perspectives' suggests...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R_4Ka5vRl3NuBJ1Af</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[B-similar]</td>\n",
       "      <td>[Utility]</td>\n",
       "      <td>[B-Similar]</td>\n",
       "      <td>[Importance]</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[The response 'both are equally useful and can...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R_4Ka5vRl3NuBJ1Af</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[A-more, T-more]</td>\n",
       "      <td>[Ease, Risky]</td>\n",
       "      <td>[A-More, T-More]</td>\n",
       "      <td>[Less effort, Risky]</td>\n",
       "      <td>[Processes, Relational]</td>\n",
       "      <td>[Effort, Risky]</td>\n",
       "      <td>[The student highlights that GenAI allows them...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R_4AYVtTmMd0q7vte</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[A-more, A-more, T-less]</td>\n",
       "      <td>[Ease, Speed, Ease]</td>\n",
       "      <td>[A-More, A-More, T-Less]</td>\n",
       "      <td>[Ease, Speed, Ease]</td>\n",
       "      <td>[Processes, Processes, Processes]</td>\n",
       "      <td>[Access, Access, Access]</td>\n",
       "      <td>[The phrase 'GenAI is available 24/7' directly...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R_4AYVtTmMd0q7vte</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>R_4AYVtTmMd0q7vte</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>R_1gTNWbmwxtRxrf8</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[T-more, A-more]</td>\n",
       "      <td>[Reliable, Understandable]</td>\n",
       "      <td>[T-More, A-More]</td>\n",
       "      <td>[Reliable, Understandable]</td>\n",
       "      <td>[Information, Information]</td>\n",
       "      <td>[Quality, Quality]</td>\n",
       "      <td>[The phrase 'the teacher is always going to be...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1gTNWbmwxtRxrf8</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[B-Similar]</td>\n",
       "      <td>[Positivity]</td>\n",
       "      <td>[Information]</td>\n",
       "      <td>[Tone]</td>\n",
       "      <td>[The statement 'teachers and AI are usually fa...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>R_1gTNWbmwxtRxrf8</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>R_4sn9pI5HdvhV5gI</td>\n",
       "      <td>Question 43</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unaware, Trustworthy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Unaware, Trustworthy]</td>\n",
       "      <td>[Processes, Information]</td>\n",
       "      <td>[Access, Quality]</td>\n",
       "      <td>[The phrase 'Have not thought to use it' indic...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>R_1VQ5hmwtdpRmnmu</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>[B-similar, A-more, T-more]</td>\n",
       "      <td>[Utility, Understanding, In-depth]</td>\n",
       "      <td>[A-More, T-More]</td>\n",
       "      <td>[Specificity, Reflection]</td>\n",
       "      <td>[Information, Sense-making]</td>\n",
       "      <td>[Quality, Sense-making]</td>\n",
       "      <td>[The student highlights that GenAI is helpful ...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>R_1VQ5hmwtdpRmnmu</td>\n",
       "      <td>Question 41</td>\n",
       "      <td>[A-more, T-more]</td>\n",
       "      <td>[No impact, Personal]</td>\n",
       "      <td>[T-More, T-More, A-More]</td>\n",
       "      <td>[Positive, Negative, No impact]</td>\n",
       "      <td>[Feeling, Feeling, Feeling]</td>\n",
       "      <td>[Feeling, Feeling, Feeling]</td>\n",
       "      <td>[The statement 'a teacher's feedback is far mo...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>R_1VQ5hmwtdpRmnmu</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[T-More]</td>\n",
       "      <td>[Reflection]</td>\n",
       "      <td>[Sense-making]</td>\n",
       "      <td>[Reflection]</td>\n",
       "      <td>[The statement 'teachers search more for the g...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>R_4aRLJoWmhKsYLOF</td>\n",
       "      <td>Question 43</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Unaware]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Unaware]</td>\n",
       "      <td>[Processes]</td>\n",
       "      <td>[Access]</td>\n",
       "      <td>[The statement 'Did not know that it could be ...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ResponseId     Question            Human_Actor_Comparator  \\\n",
       "0   R_4C4j4KNUq9N3VGC  Question 40          [A-more, T-more, T-more]   \n",
       "1   R_4C4j4KNUq9N3VGC  Question 41                  [A-more, T-more]   \n",
       "2   R_4C4j4KNUq9N3VGC  Question 42          [A-more, T-more, T-more]   \n",
       "3   R_4CKOoHgU8hp01rg  Question 40                  [A-more, A-less]   \n",
       "4   R_4CKOoHgU8hp01rg  Question 41                                []   \n",
       "5   R_4CKOoHgU8hp01rg  Question 42  [A-more, T-more, A-less, T-more]   \n",
       "6   R_43e00PZDT3YYIZ2  Question 43                                []   \n",
       "7   R_4P0PnRK3k4DjAxR  Question 40                          [A-more]   \n",
       "8   R_4P0PnRK3k4DjAxR  Question 41                          [A-more]   \n",
       "9   R_4P0PnRK3k4DjAxR  Question 42                                []   \n",
       "10  R_4Ka5vRl3NuBJ1Af  Question 40                  [A-less, T-more]   \n",
       "11  R_4Ka5vRl3NuBJ1Af  Question 41                       [B-similar]   \n",
       "12  R_4Ka5vRl3NuBJ1Af  Question 42                  [A-more, T-more]   \n",
       "13  R_4AYVtTmMd0q7vte  Question 40          [A-more, A-more, T-less]   \n",
       "14  R_4AYVtTmMd0q7vte  Question 41                                []   \n",
       "15  R_4AYVtTmMd0q7vte  Question 42                                []   \n",
       "16  R_1gTNWbmwxtRxrf8  Question 40                  [T-more, A-more]   \n",
       "17  R_1gTNWbmwxtRxrf8  Question 41                                []   \n",
       "18  R_1gTNWbmwxtRxrf8  Question 42                                []   \n",
       "19  R_4sn9pI5HdvhV5gI  Question 43                                []   \n",
       "20  R_1VQ5hmwtdpRmnmu  Question 40       [B-similar, A-more, T-more]   \n",
       "21  R_1VQ5hmwtdpRmnmu  Question 41                  [A-more, T-more]   \n",
       "22  R_1VQ5hmwtdpRmnmu  Question 42                                []   \n",
       "23  R_4aRLJoWmhKsYLOF  Question 43                                []   \n",
       "\n",
       "                           Human_Characteristics  \\\n",
       "0                    [Speed, Personal, In-depth]   \n",
       "1                          [No impact, Positive]   \n",
       "2                 [Speed, Specificity, Personal]   \n",
       "3                              [Speed, In-depth]   \n",
       "4                                             []   \n",
       "5   [Speed, Contextualised, Relevance, Personal]   \n",
       "6                      [Unaware, Contextualised]   \n",
       "7                                         [Ease]   \n",
       "8                                [Understanding]   \n",
       "9                                             []   \n",
       "10                 [Specificity, Contextualised]   \n",
       "11                                     [Utility]   \n",
       "12                                 [Ease, Risky]   \n",
       "13                           [Ease, Speed, Ease]   \n",
       "14                                            []   \n",
       "15                                            []   \n",
       "16                    [Reliable, Understandable]   \n",
       "17                                            []   \n",
       "18                                            []   \n",
       "19                        [Unaware, Trustworthy]   \n",
       "20            [Utility, Understanding, In-depth]   \n",
       "21                         [No impact, Personal]   \n",
       "22                                            []   \n",
       "23                                     [Unaware]   \n",
       "\n",
       "                             Agentic_Actor_Comparator  \\\n",
       "0                            [A-More, T-More, T-More]   \n",
       "1                            [A-More, T-More, T-More]   \n",
       "2                    [A-More, A-More, T-More, T-More]   \n",
       "3   [A-More, A-Less, T-More, T-More, A-Less, T-Mor...   \n",
       "4                                                  []   \n",
       "5   [A-Less, T-More, T-More, A-More, A-Less, T-Mor...   \n",
       "6                                                 NaN   \n",
       "7                                    [A-More, T-Less]   \n",
       "8                                            [A-More]   \n",
       "9                                                  []   \n",
       "10                           [A-More, T-More, T-More]   \n",
       "11                                        [B-Similar]   \n",
       "12                                   [A-More, T-More]   \n",
       "13                           [A-More, A-More, T-Less]   \n",
       "14                                                 []   \n",
       "15                                                 []   \n",
       "16                                   [T-More, A-More]   \n",
       "17                                        [B-Similar]   \n",
       "18                                                 []   \n",
       "19                                                NaN   \n",
       "20                                   [A-More, T-More]   \n",
       "21                           [T-More, T-More, A-More]   \n",
       "22                                           [T-More]   \n",
       "23                                                NaN   \n",
       "\n",
       "                              Agentic_Characteristics  \\\n",
       "0                    [Speed, Personal, Understanding]   \n",
       "1                 [Less effort, Personal, Positivity]   \n",
       "2              [Speed, Objective, In-depth, Personal]   \n",
       "3   [Speed, In-depth, In-depth, Understanding, Per...   \n",
       "4                                                  []   \n",
       "5   [In-depth, Specificity, Personal, Speed, Conte...   \n",
       "6                  [Unaware, Contextualised, Unaware]   \n",
       "7                                    [Ease, Personal]   \n",
       "8                                     [Understanding]   \n",
       "9                                                  []   \n",
       "10                    [Volume, Personal, Specificity]   \n",
       "11                                       [Importance]   \n",
       "12                               [Less effort, Risky]   \n",
       "13                                [Ease, Speed, Ease]   \n",
       "14                                                 []   \n",
       "15                                                 []   \n",
       "16                         [Reliable, Understandable]   \n",
       "17                                       [Positivity]   \n",
       "18                                                 []   \n",
       "19                             [Unaware, Trustworthy]   \n",
       "20                          [Specificity, Reflection]   \n",
       "21                    [Positive, Negative, No impact]   \n",
       "22                                       [Reflection]   \n",
       "23                                          [Unaware]   \n",
       "\n",
       "                                       Agentic_Themes  \\\n",
       "0               [Processes, Relational, Sense-making]   \n",
       "1                [Processes, Relational, Information]   \n",
       "2   [Processes, Information, Information, Relational]   \n",
       "3   [Processes, Information, Information, Sense-ma...   \n",
       "4                                                  []   \n",
       "5   [Information, Information, Relational, Process...   \n",
       "6                 [Processes, Information, Processes]   \n",
       "7                            [Processes, Information]   \n",
       "8                                      [Sense-making]   \n",
       "9                                                  []   \n",
       "10             [Information, Relational, Information]   \n",
       "11                                            [Value]   \n",
       "12                            [Processes, Relational]   \n",
       "13                  [Processes, Processes, Processes]   \n",
       "14                                                 []   \n",
       "15                                                 []   \n",
       "16                         [Information, Information]   \n",
       "17                                      [Information]   \n",
       "18                                                 []   \n",
       "19                           [Processes, Information]   \n",
       "20                        [Information, Sense-making]   \n",
       "21                        [Feeling, Feeling, Feeling]   \n",
       "22                                     [Sense-making]   \n",
       "23                                        [Processes]   \n",
       "\n",
       "                                    Agentic_SubThemes  \\\n",
       "0                  [Access, Relational, Sense-making]   \n",
       "1                          [Effort, Relational, Tone]   \n",
       "2              [Access, Quality, Quality, Relational]   \n",
       "3   [Access, Quality, Quality, Understanding, Rela...   \n",
       "4                                                  []   \n",
       "5   [Quality, Quality, Relational, Access, Quality...   \n",
       "6                           [Access, Quality, Access]   \n",
       "7                                   [Access, Quality]   \n",
       "8                                      [Sense-making]   \n",
       "9                                                  []   \n",
       "10                     [Quality, Relational, Quality]   \n",
       "11                                            [Value]   \n",
       "12                                    [Effort, Risky]   \n",
       "13                           [Access, Access, Access]   \n",
       "14                                                 []   \n",
       "15                                                 []   \n",
       "16                                 [Quality, Quality]   \n",
       "17                                             [Tone]   \n",
       "18                                                 []   \n",
       "19                                  [Access, Quality]   \n",
       "20                            [Quality, Sense-making]   \n",
       "21                        [Feeling, Feeling, Feeling]   \n",
       "22                                       [Reflection]   \n",
       "23                                           [Access]   \n",
       "\n",
       "                                   Agentic_Reasonings  Researcher_Agreement  \\\n",
       "0   [The phrase 'GenAI gives instant answers anyti...                  True   \n",
       "1   [The term 'efficient' suggests that GenAI feed...                  True   \n",
       "2   [The phrase 'GenAI feedback was quicker' direc...                  True   \n",
       "3   [The phrase 'Provides instant feedback' direct...                  True   \n",
       "4                                                  []                  True   \n",
       "5   [The statement 'sometimes lacks detailed, pers...                  True   \n",
       "6   [The student states 'I didn't know how / if ge...                 False   \n",
       "7   [The phrase 'more convenient/timely to get fee...                 False   \n",
       "8   [The statement 'you can ask the AI to explain ...                  True   \n",
       "9                                                  []                  True   \n",
       "10  [The phrase 'broader in perspectives' suggests...                  True   \n",
       "11  [The response 'both are equally useful and can...                  True   \n",
       "12  [The student highlights that GenAI allows them...                  True   \n",
       "13  [The phrase 'GenAI is available 24/7' directly...                  True   \n",
       "14                                                 []                  True   \n",
       "15                                                 []                  True   \n",
       "16  [The phrase 'the teacher is always going to be...                  True   \n",
       "17  [The statement 'teachers and AI are usually fa...                  True   \n",
       "18                                                 []                  True   \n",
       "19  [The phrase 'Have not thought to use it' indic...                  True   \n",
       "20  [The student highlights that GenAI is helpful ...                  True   \n",
       "21  [The statement 'a teacher's feedback is far mo...                  True   \n",
       "22  [The statement 'teachers search more for the g...                  True   \n",
       "23  [The statement 'Did not know that it could be ...                  True   \n",
       "\n",
       "    Quality_Score  Total_Iterations  Iteration_Agreement  \n",
       "0               5                 1             0.333333  \n",
       "1               5                 1             0.833333  \n",
       "2               5                 1             0.333333  \n",
       "3               5                 1             0.904762  \n",
       "4               5                 1             1.000000  \n",
       "5               5                 1             1.000000  \n",
       "6               3                 2             1.000000  \n",
       "7               3                 2             1.000000  \n",
       "8               5                 1             0.333333  \n",
       "9               5                 1             1.000000  \n",
       "10              5                 1             0.333333  \n",
       "11              5                 1             0.333333  \n",
       "12              5                 1             0.333333  \n",
       "13              5                 1             0.333333  \n",
       "14              5                 1             1.000000  \n",
       "15              5                 1             1.000000  \n",
       "16              5                 1             0.333333  \n",
       "17              5                 1             0.333333  \n",
       "18              5                 1             1.000000  \n",
       "19              5                 1             1.000000  \n",
       "20              5                 1             0.333333  \n",
       "21              5                 1             0.333333  \n",
       "22              5                 1             0.333333  \n",
       "23              5                 1             1.000000  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_comparison_df = compare_agentic_human_codings(\n",
    "    'agentic_coding_results/all_agentic_results.json',\n",
    "    'temp_survey'\n",
    ")\n",
    "\n",
    "agentic_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b115fc0",
   "metadata": {},
   "source": [
    "## 0. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ededdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_research = \"\"\"\n",
    "\n",
    "                The aim of this study is to investigate how university students use, value, and trust feedback generated by Generative Artificial Intelligence (GenAI) \n",
    "                compared to feedback from teachers. Specifically, the research seeks to understand the different roles that GenAI and teacher feedback play in \n",
    "                higher education, the factors that influence students’ perceptions of their usefulness, reliability, and trustworthiness, and the ways in which these \n",
    "                forms of feedback shape students’ learning experiences, emotions, and engagement with feedback processes.  \n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "actor_codes =  \"\"\"\n",
    "                # Code: A  \n",
    "\n",
    "                **Explanation:** GenAI (also variants such as AI, ChatGPT, etc.)  \n",
    "\n",
    "                ---\n",
    "\n",
    "                # Code: T  \n",
    "\n",
    "                **Explanation:** Teacher (also variants such as lecturer, tutor, staff, etc.)  \n",
    "\n",
    "                ---\n",
    "\n",
    "                # Code: B  \n",
    "\n",
    "                **Explanation:** Both (clear reference to both actors)  \n",
    "\n",
    "              \"\"\"\n",
    "               \n",
    "comparator_codes = \"\"\"\n",
    "\n",
    "                    # Code: More  \n",
    "\n",
    "                    **Explanation:** When the comment indicated that the actor was associated with more (volume, frequency, impact) of the characteristic.   \n",
    "\n",
    "                    ---\n",
    "\n",
    "                    # Code: Less  \n",
    "\n",
    "                    **Explanation:** As above but in reference to less or smaller volume, frequency or impact of the characteristic.  \n",
    "\n",
    "                    ---\n",
    "\n",
    "                    # Code: Similar  \n",
    "\n",
    "                    **Explanation:** When the comment made an explicit statement that both GenAI and Teachers were similar in some way (e.g., they were similarly useful).  \n",
    "\n",
    "\n",
    "                    \"\"\"\n",
    "                    \n",
    "characteristic_codes = \"\"\"\n",
    "                        # Theme: Processes  \n",
    "\n",
    "                        ## Sub-theme: Access  \n",
    "\n",
    "                        ### Code: Ease  \n",
    "                        **Definition:** Is easily accessible, available, or convenient.  \n",
    "\n",
    "                        ### Code: Speed  \n",
    "                        **Definition:** Is immediate, instant or fast. Described as time-efficient, saving time.  \n",
    "\n",
    "                        ### Code: Volume  \n",
    "                        **Definition:** Reference to quantity, volume, scale of information or feedback interactions (e.g., could ask many questions and get lots of responses).  \n",
    "\n",
    "                        ## Sub-theme: Timing  \n",
    "\n",
    "                        ### Code: Before submission  \n",
    "                        **Definition:** Provides information during the production of an assignment task.  \n",
    "\n",
    "                        ### Code: After submission  \n",
    "                        **Definition:** Provides information after the submission of an assignment task.  \n",
    "\n",
    "                        ## Sub-theme: Effort  \n",
    "\n",
    "                        ### Code: Less effort  \n",
    "                        **Definition:** Reduces effort associated with the task. This may be making a task easier in some way, or it may refer to doing the task entirely.  \n",
    "\n",
    "                        ---\n",
    "\n",
    "                        # Theme: Sense-making  \n",
    "\n",
    "                        ## Sub-theme: Sense-making \n",
    "\n",
    "                        ### Code: Understanding  \n",
    "                        **Definition:** Helps me understand.  \n",
    "\n",
    "                        ### Code: Reflection  \n",
    "                        **Definition:** Helps me reflect.  \n",
    "\n",
    "                        ### Code: Progress    \n",
    "                        **Definition:** Helps me know how I’m going.  \n",
    "\n",
    "                        ---\n",
    "\n",
    "                        # Theme: Information  \n",
    "\n",
    "                        ## Sub-theme: Quality  \n",
    "\n",
    "                        ### Code: Specificity  \n",
    "                        **Definition:** Provides specific or detailed information. Antonyms: vague, generic.  \n",
    "\n",
    "                        ### Code: In-depth  \n",
    "                        **Definition:** Provides in-depth or nuanced information. Antonyms: superficial, broad.  \n",
    "\n",
    "                        ### Code: Understandable  \n",
    "                        **Definition:** Information is presented in an understandable, digestible, and comprehensible way.  \n",
    "\n",
    "                        ### Code: Relevance  \n",
    "                        **Definition:** Information is relevant, on topic.  \n",
    "\n",
    "                        ### Code: Contextualised  \n",
    "                        **Definition:** Provides information that is adapted for the context of an assignment, rubrics, discipline, or class. (Not relational).  \n",
    "\n",
    "                        ### Code: Utility  \n",
    "                        **Definition:** Provides useful, usable, or helpful information.  \n",
    "\n",
    "                        ### Code: Reliable  \n",
    "                        **Definition:** Provides information that is accurate, precise, reliable, or trustworthy.  \n",
    "\n",
    "                        ### Code: Objective  \n",
    "                        **Definition:** Is objective in its feedback, judgment, or evaluation. Antonyms: subjective, biased.  \n",
    "\n",
    "                        ## Sub-theme: Tone  \n",
    "\n",
    "                        ### Code: Positivity  \n",
    "                        **Definition:** Makes positive statements, people pleaser\n",
    "\n",
    "                        ### Code: Negativity  \n",
    "                        **Definition:** Makes edits or provides statements that are perceived as negative in tone (e.g. dismissive, insulting, uncaring).  \n",
    "\n",
    "                        ---\n",
    "\n",
    "                        # Theme: Feeling  \n",
    "                        \n",
    "                        ## Sub-theme: Feeling  \n",
    "\n",
    "                        ### Code: Positive  \n",
    "                        **Definition:** Makes me feel a positive feeling. Synonyms: Encouraging, motivating.  \n",
    "\n",
    "                        ### Code: Negative  \n",
    "                        **Definition:** Makes me feel a negative feeling. Synonyms: Frustrating. \n",
    "\n",
    "                        ### Code: No impact\n",
    "                        **Definition:** Makes me feel nothing or indifferent. Has no impact on my emotions or feelings.\n",
    "\n",
    "                        ---\n",
    "\n",
    "                        # Theme: Relational  \n",
    "\n",
    "                        ## Sub-theme: Relational\n",
    "                         \n",
    "                        ### Code: Personal   \n",
    "                        **Definition:** Is supportive. Concerns relational type statements (e.g. the “teacher knows me”’). Closer/ more-distant or embodied (e.g. “I like being face to face with my teacher”). Some statements are about AI being more in tune, more personalised, personal to tastes in language, communication and \"learning styles\".\n",
    "\n",
    "                        ### Code: Risky  \n",
    "                        **Definition:** Makes me vulnerable to their judgement, causes me shame. Possibly related to power, position, self. Synonyms: Implies personal consequence, at risk. Antonyms: non-judgemental, no shame, preserves self, prevents vulnerability\n",
    "\n",
    "                        ### Code: Expert  \n",
    "                        **Definition:** Has a position of knowledge or expertise.  \n",
    "\n",
    "                        ---\n",
    "\n",
    "                        # Theme: Value  \n",
    "\n",
    "                        ## Sub-theme: Value  \n",
    "\n",
    "                        ### Code: Importance \n",
    "                        **Definition:** Is important or valuable.  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "characteristic_codes_v2 = \"\"\"\n",
    "\n",
    "            # Theme: Processes  \n",
    "\n",
    "            ## Sub-theme: Access  \n",
    "\n",
    "            ### Code: Ease  \n",
    "            **Definition:** Refers to the convenience of accessing feedback or support. It captures situations where obtaining assistance is straightforward, uncomplicated, and does not involve significant barriers compared to traditional sources like teachers or professors.  \n",
    "\n",
    "            ### Code: Speed  \n",
    "            **Definition:** Describes the immediacy of receiving responses or feedback. It highlights efficiency and time-saving aspects, where support is delivered rapidly enough to accelerate the learning or task process.  \n",
    "\n",
    "            ### Code: Volume  \n",
    "            **Definition:** Relates to the quantity of feedback or information available. It reflects the ability to engage in multiple interactions, ask numerous questions, and receive abundant responses compared to more limited human feedback.  \n",
    "\n",
    "            ## Sub-theme: Timing  \n",
    "\n",
    "            ### Code: Before submission  \n",
    "            **Definition:** Feedback is provided during the drafting or preparation stage of an assignment. This allows for real-time adjustments, improvements, and refinements prior to final submission.  \n",
    "\n",
    "            ### Code: After submission  \n",
    "            **Definition:** Feedback is received after an assignment has been submitted and graded. While it can inform future work, it does not directly impact the already completed task.  \n",
    "\n",
    "            ## Sub-theme: Effort  \n",
    "\n",
    "            ### Code: Less effort  \n",
    "            **Definition:** Highlights a reduction in the amount of work, energy, or cognitive load required to complete a task. This includes simplifying processes, providing starting points, or removing barriers that typically demand more effort from the student.  \n",
    "\n",
    "            ---\n",
    "\n",
    "            # Theme: Sense-making  \n",
    "\n",
    "            ## Sub-theme: Sense-making  \n",
    "\n",
    "            ### Code: Understanding  \n",
    "            **Definition:** Enables students to better comprehend concepts, ideas, or tasks. It involves organising thoughts, clarifying confusion, and making content more digestible for learning.  \n",
    "\n",
    "            ### Code: Reflection  \n",
    "            **Definition:** Encourages self-examination and critical thinking about one’s own learning, performance, or perspective. It involves generating insights that prompt deeper consideration of personal approaches.  \n",
    "\n",
    "            ### Code: Progress    \n",
    "            **Definition:** Provides indicators of how well a student is performing or advancing. It supports self-monitoring by offering feedback that signals whether learning or task outcomes are on track.  \n",
    "\n",
    "            ---\n",
    "\n",
    "            # Theme: Information  \n",
    "\n",
    "            ## Sub-theme: Quality  \n",
    "\n",
    "            ### Code: Specificity  \n",
    "            **Definition:** Refers to feedback or information that is detailed, concrete, and precise rather than vague or generic.  \n",
    "\n",
    "            ### Code: In-depth  \n",
    "            **Definition:** Captures the extent to which feedback is comprehensive, nuanced, and layered. It contrasts with broad or superficial responses by offering thorough explanations or contextual depth.  \n",
    "\n",
    "            ### Code: Understandable  \n",
    "            **Definition:** Information is communicated in a way that is clear, simple, and easy to grasp. This includes structuring content so that it is digestible and accessible to the learner.  \n",
    "\n",
    "            ### Code: Relevance  \n",
    "            **Definition:** Feedback or information aligns closely with the student’s needs, topic, or task requirements, avoiding off-topic or tangential content.  \n",
    "\n",
    "            ### Code: Contextualised  \n",
    "            **Definition:** Feedback is adapted to the specific assignment, discipline, or criteria. It demonstrates awareness of situational requirements rather than offering generic guidance.  \n",
    "\n",
    "            ### Code: Utility  \n",
    "            **Definition:** Information is practical, usable, and directly helpful in solving problems, advancing tasks, or exploring new ideas.  \n",
    "\n",
    "            ### Code: Reliable  \n",
    "            **Definition:** Feedback is characterised by trustworthiness, accuracy, and precision. It avoids misleading or erroneous information.  \n",
    "\n",
    "            ### Code: Objective  \n",
    "            **Definition:** Feedback is impartial and free of personal bias. It is grounded in factual or consistent standards rather than subjective judgments or preferences.  \n",
    "\n",
    "            ## Sub-theme: Tone  \n",
    "\n",
    "            ### Code: Positivity  \n",
    "            **Definition:** Feedback is encouraging, affirming, or expressed in a supportive tone. It creates a positive interpersonal dynamic, often aligning with a people-pleasing or agreeable style.  \n",
    "\n",
    "            ### Code: Negativity  \n",
    "            **Definition:** Feedback is expressed in a critical or discouraging tone, sometimes perceived as dismissive, harsh, or uncaring.  \n",
    "\n",
    "            ---\n",
    "\n",
    "            # Theme: Feeling  \n",
    "\n",
    "            ## Sub-theme: Feeling  \n",
    "\n",
    "            ### Code: Positive  \n",
    "            **Definition:** Feedback evokes feelings of encouragement, motivation, or appreciation. It creates a sense of being supported, valued, or cared for.  \n",
    "\n",
    "            ### Code: Negative  \n",
    "            **Definition:** Feedback generates negative emotions such as frustration, discouragement, or shame. It may undermine confidence or self-worth.  \n",
    "\n",
    "            ### Code: No impact  \n",
    "            **Definition:** Feedback is emotionally neutral, leaving the student indifferent. It does not trigger any significant positive or negative emotional response.  \n",
    "\n",
    "            ---\n",
    "\n",
    "            # Theme: Relational  \n",
    "\n",
    "            ## Sub-theme: Relational  \n",
    "\n",
    "            ### Code: Personal   \n",
    "            **Definition:** Feedback reflects personalisation and relational support. It demonstrates awareness of individual needs, progress, or preferences, fostering a sense of connection or tailored guidance.  \n",
    "\n",
    "            ### Code: Risky  \n",
    "            **Definition:** Feedback situations evoke vulnerability or fear of judgment. It reflects perceived risks to self-esteem, identity, or safety in the learning relationship.  \n",
    "\n",
    "            ### Code: Expert  \n",
    "            **Definition:** Feedback is grounded in knowledge, authority, and subject expertise. It reflects the credibility and informed position of the source.  \n",
    "\n",
    "            ---\n",
    "\n",
    "            # Theme: Value  \n",
    "\n",
    "            ## Sub-theme: Value  \n",
    "\n",
    "            ### Code: Importance \n",
    "            **Definition:** Captures the perceived significance or weight given to feedback. It reflects judgments about which sources of feedback are most valuable or influential in shaping learning outcomes.  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "                        \n",
    "CODING_STRATEGY = \"\"\"\n",
    "    When coding student responses:\n",
    "\n",
    "    1. **Surface-Level Understanding**  \n",
    "    - Do not over-interpret student responses.  \n",
    "    - Work from the most direct, surface-level meaning of the text.  \n",
    "    - Avoid reading beyond what is explicitly written.\n",
    "\n",
    "    2. **Chunk-Based Coding**  \n",
    "    - Divide each response into meaningful chunks (a sentence or a significant phrase).  \n",
    "    - A chunk should only be coded once, even if it could theoretically fit multiple codes.\n",
    "\n",
    "    3. **Focus on Comparison**  \n",
    "    - Prioritize identifying any comparison between AI feedback and teacher feedback.  \n",
    "    - Look for explicit or implicit comparative language such as *more, less, better, worse, easier, harder, similar*.  \n",
    "\n",
    "    4. **Actor + Comparator + Characteristic Logic**  \n",
    "    - For each usable chunk, identify three components:  \n",
    "        **Actor** – Who or what the comment refers to (A = AI, T = Teacher, B = Both).  \n",
    "        **Comparator** – The relative position (e.g., more, less, similar, better, worse).  \n",
    "        **Characteristic** – The feedback property being described (e.g., clarity, accuracy, relevance, timeliness, emotional safety).  \n",
    "    - A valid coded chunk must include all three components.  \n",
    "\n",
    "    5. **Handling Unusable Responses**  \n",
    "    - If a response is unintelligible or does not appear to answer the question, code it as **UNUSABLE**.  \n",
    "    - If a chunk is missing **any one** of the three required components (Actor, Comparator, Characteristic), code it as **UNUSABLE**.  \n",
    "    - Example of unusable: \"It was better\" – we don’t know *which actor* it refers to.  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "CODING_STRATEGY_V2 = \"\"\"\n",
    "\n",
    "    When coding student responses:\n",
    "    1. **Surface-Level Understanding**  \n",
    "    - Keep interpretations minimal: code *only* what is directly and explicitly stated.  \n",
    "    - Do not infer hidden meanings, motivations, or consequences.  \n",
    "\n",
    "    2. **Chunk-Based Coding (Restrained)**  \n",
    "    - Divide a response only if there are **clear shifts in meaning** (e.g., “while,” “but,” “however”).  \n",
    "    - Avoid splitting into too many micro-chunks. A whole sentence is usually a single chunk.  \n",
    "    - **Max 2 chunks per sentence** unless multiple actors (AI vs Teacher) are explicitly compared.\n",
    "\n",
    "    3. **Salience over Exhaustiveness**  \n",
    "    - Prioritize **main comparisons** or feelings.  \n",
    "    - Do not code every possible nuance if it dilutes the focus.  \n",
    "    - Example: If a chunk has both a tone (“neutral”) and an efficiency descriptor (“efficient”), select the **dominant characteristic** (in this case, tone/feeling = “No impact”).\n",
    "\n",
    "    4. **Actor + Comparator + Characteristic Rule**  \n",
    "    - A valid code requires all three: Actor (A/T/B), Comparator (more/less/similar), and Characteristic (e.g., clarity, personal, timeliness).  \n",
    "    - If multiple characteristics appear but relate to the *same actor/comparator*, treat them as **one code**.  \n",
    "    - Example: “Teacher’s feedback was personal and encouraging” → single code: Actor = Teacher, Comparator = More, Characteristic = Personal/Positive.  \n",
    "\n",
    "    5. **Dominant Coding Principle**  \n",
    "    - When multiple possible codes exist in the same chunk, select the **most prominent or emotionally central one**.  \n",
    "    - Example: “GenAI felt neutral and efficient” → dominant code = “No impact” (feeling tone). “Efficient” is secondary and not coded separately.\n",
    "\n",
    "    6. **Handling Unusable Responses**  \n",
    "    - If actor, comparator, or characteristic is missing, mark as **UNUSABLE**.  \n",
    "    - Example: “It was better” → UNUSABLE.  \n",
    "    - Example: “Feedback was neutral” (no comparison between actors) → UNUSABLE.  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OUTPUT_FORMAT = \"\"\"\n",
    "    {\n",
    "        \"codes\": [\n",
    "            {   \n",
    "                \"actor\": \"...\",\n",
    "                \"comparator\": \"...\",\n",
    "                \"theme\": \"...\",\n",
    "                \"sub_theme\": \"...\",\n",
    "                \"code\": \"...\",\n",
    "                \"reasoning\": \"...\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "SHOTS = \"\"\"\n",
    "\n",
    "    Examples of a good output are the next ones:\n",
    "\n",
    "    Example 1:\n",
    "\n",
    "    Question: \"Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?\"\n",
    "\n",
    "    Student response: \"AI tends to be more uplifting or supportive than teachers, so when I ask for its opinion on something I’ve written it’ll compliment whereas my teacher will have edits to my work. Both are useful and important.\"\n",
    "\n",
    "    GOOD OUTPUT:\n",
    "\n",
    "    {\n",
    "        \"codes\": [\n",
    "            {   \n",
    "                \"actor\": \"A\",\n",
    "                \"comparator\": \"More\",\n",
    "                \"theme\": \"Information\",\n",
    "                \"sub_theme\": \"Tone\",\n",
    "                \"code\": \"Positivity\",\n",
    "                \"reasoning\": \"The phrases 'more uplifting or supportive' and 'it’ll compliment' directly indicate positive affective framing. By definition, the Positivity code captures feedback that is polite, supportive, or 'people-pleasing', which matches the student’s description of AI’s tone relative to teachers.\"\n",
    "            },\n",
    "            {   \n",
    "                \"actor\": \"T\",\n",
    "                \"comparator\": \"More\",\n",
    "                \"theme\": \"Information\",\n",
    "                \"sub_theme\": \"Quality\",\n",
    "                \"code\": \"Utility\",\n",
    "                \"reasoning\": \"The contrast 'AI will compliment whereas my teacher will have edits' signals that teacher feedback contains actionable, text-level changes. This aligns with the Utility code which captures feedback that is practical and useful for making concrete improvements, as evidenced by the teacher providing specific edits rather than just praise.\"\n",
    "            },\n",
    "            {\n",
    "                \"actor\": \"B\",\n",
    "                \"comparator\": \"Similar\",\n",
    "                \"theme\": \"Value\",\n",
    "                \"sub_theme\": \"Value\",\n",
    "                \"code\": \"Importance\",\n",
    "                \"reasoning\": \"The closing statement 'Both are useful and important' is an explicit equivalence claim about value. The Importance code captures perceived significance; here the student assigns comparable importance to both AI and teacher feedback.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Example 2:\n",
    "\n",
    "    Question: \"Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?\"\n",
    "\n",
    "    Student response: \"Provides more immediate feedback while working on assignments when the teacher wasn't yet able to.\"\n",
    "\n",
    "    GOOD OUTPUT:\n",
    "\n",
    "    {\n",
    "        \"codes\": [\n",
    "            {   \n",
    "                \"actor\": \"A\",\n",
    "                \"comparator\": \"More\",\n",
    "                \"theme\": \"Processes\",\n",
    "                \"sub_theme\": \"Access\",\n",
    "                \"code\": \"Speed\",\n",
    "                \"reasoning\": \"The term 'more immediate' directly maps to the Speed code (immediate/instant/time-efficient). The temporal clause 'while working on assignments' highlights availability during production (pre‑submission), reinforcing that AI’s response time outpaces the teacher’s in this context.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Example 3:\n",
    "\n",
    "    Question: \"Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?\"\n",
    "\n",
    "    Student response: \"AI made me feel good and teachers make me feel bad and dumb.\"\n",
    "\n",
    "    GOOD OUTPUT:\n",
    "\n",
    "    {\n",
    "        \"codes\": [\n",
    "            {   \n",
    "                \"actor\": \"A\",\n",
    "                \"comparator\": \"More\",\n",
    "                \"theme\": \"Feeling\",\n",
    "                \"sub_theme\": \"Feeling\",\n",
    "                \"code\": \"Positive\",\n",
    "                \"reasoning\": \"The literal statement 'AI made me feel good' is a direct indicator of positive emotional impact. The Positive code captures encouraging or motivating feelings, which the student explicitly attributes to AI in contrast to teachers.\"\n",
    "            },\n",
    "            {   \n",
    "                \"actor\": \"T\",\n",
    "                \"comparator\": \"More\",\n",
    "                \"theme\": \"Feeling\",\n",
    "                \"sub_theme\": \"Feeling\",\n",
    "                \"code\": \"Negative\",\n",
    "                \"reasoning\": \"The student reports teachers 'make me feel bad and dumb', which is an explicit negative affective response. The Negative code covers discouraging or frustrating emotions, indicating a stronger negative impact from teacher feedback relative to AI.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "reasons_codes = \"\"\"\n",
    "\n",
    "                # Theme: Processes\n",
    "\n",
    "                ## Sub-theme: Access\n",
    "\n",
    "                ### Code: Unaware\n",
    "                **Definition:** Respondents didn’t know GenAI could provide feedback; or didn’t know how to use it; or didn’t think of using it.  \n",
    "\n",
    "                ## Sub-theme: Effort\n",
    "\n",
    "                ### Code: Effortful\n",
    "                **Definition:** Too much effort to use AI or learn how to use AI; don’t have time to use AI (e.g., last-minute assignments).  \n",
    "\n",
    "                ### Code: Less effort\n",
    "                **Definition:** Off-loads effort or experience of learning, which in this context is not desirable.  \n",
    "\n",
    "                ---\n",
    "\n",
    "                # Theme: Information\n",
    "\n",
    "                ## Sub-theme: Quality\n",
    "\n",
    "                ### Code: Specificity\n",
    "                **Definition:** Provides specific or detailed information. Antonyms: vague, generic.  \n",
    "\n",
    "                ### Code: In-depth\n",
    "                **Definition:** Not enough, or sometimes not useful because it offers too much depth or additional explanation than desired.  \n",
    "\n",
    "                ### Code: Contextualised\n",
    "                **Definition:** Information provided lacks the context of an assignment, rubrics, discipline or class.  \n",
    "\n",
    "                ### Code: Utility\n",
    "                **Definition:** Useful, usable, or helpful information.  \n",
    "\n",
    "                ### Code: Trustworthy\n",
    "                **Definition:** Respondent does not trust the information; it is not reliable, or the provider/source is not competent to provide trustworthy information.  \n",
    "\n",
    "                ## Sub-theme: Tone\n",
    "\n",
    "                ### Code: Positivity\n",
    "                **Definition:** Makes positive statements; people pleaser.  \n",
    "\n",
    "                ---\n",
    "\n",
    "                # Theme: Relational\n",
    "\n",
    "                ## Sub-theme: Relational\n",
    "\n",
    "                ### Code: Personal\n",
    "                **Definition:** Respondent values relationship or closer and embodied feedback; values the role or connection with humans.  \n",
    "\n",
    "                ### Code: Expert\n",
    "                **Definition:** Has a position of knowledge or expertise.  \n",
    "\n",
    "                ---\n",
    "\n",
    "                # Theme: Value\n",
    "\n",
    "                ## Sub-theme: Value\n",
    "\n",
    "                ### Code: Preference\n",
    "                **Definition:** Respondent preferred not using GenAI without specifying further reasons or expressing dislike.  \n",
    "\n",
    "                ### Code: Need\n",
    "                **Definition:** Does not want or need feedback; does not need feedback from AI (own skills or others are sufficient); no necessity to use AI for feedback.  \n",
    "\n",
    "                ### Code: Unsustainable\n",
    "                **Definition:** Respondent finds GenAI is not environmentally sustainable.  \n",
    "\n",
    "                ### Code: Privacy\n",
    "                **Definition:** Respondent reports concern regarding privacy.  \n",
    "\n",
    "                ### Code: Integrity\n",
    "                **Definition:** Respondent committed to the originality of own work and ethical behaviour in academic work.  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "reasons_codes_v2 = \"\"\"\n",
    "\n",
    "        # Theme: Processes  \n",
    "\n",
    "        ## Sub-theme: Access  \n",
    "\n",
    "        ### Code: Unaware  \n",
    "        **Definition:** Captures situations where students are unaware that GenAI can provide feedback, lack knowledge of how to use it, or simply do not consider using it. It reflects both unawareness of the tool’s potential and uncertainty about its operation.  \n",
    "\n",
    "        ## Sub-theme: Effort  \n",
    "\n",
    "        ### Code: Effortful  \n",
    "        **Definition:** Highlights the perception that using GenAI requires excessive time or energy, either in learning how to use it effectively or in applying it under time pressure. This effort outweighs perceived benefits, particularly in rushed academic contexts.  \n",
    "\n",
    "        ### Code: Less effort  \n",
    "        **Definition:** Reflects concerns that using GenAI reduces the necessary effort involved in learning. Students perceive that offloading work to AI undermines the personal challenge, skill-building, and intellectual growth required for academic and professional development.  \n",
    "\n",
    "        ---\n",
    "\n",
    "        # Theme: Information  \n",
    "\n",
    "        ## Sub-theme: Quality  \n",
    "\n",
    "        ### Code: Specificity  \n",
    "        **Definition:** Emphasises the need for feedback that is detailed and tailored to the student’s work. AI-generated responses are perceived as too generic or vague compared to the specific input students seek.  \n",
    "\n",
    "        ### Code: In-depth  \n",
    "        **Definition:** Reflects dissatisfaction with the quality of feedback when AI provides overly broad or superficial input, lacking nuance, or alternatively giving excessive depth that is not practical or useful for the task.  \n",
    "\n",
    "        ### Code: Contextualised  \n",
    "        **Definition:** Highlights the limitation of AI feedback when it lacks alignment with assignment instructions, rubrics, or disciplinary expectations. Students value feedback that is situated in the academic context, which AI cannot fully replicate.  \n",
    "\n",
    "        ### Code: Utility  \n",
    "        **Definition:** Concerns the practical usefulness of AI-generated feedback. Students report that AI often fails to provide relevant or actionable guidance, limiting its effectiveness for improving their work.  \n",
    "\n",
    "        ### Code: Trustworthy  \n",
    "        **Definition:** Reflects doubts about the accuracy, reliability, and legitimacy of AI feedback. Students question the competence of AI as a source of evaluation and express distrust due to perceived biases or lack of accountability.  \n",
    "\n",
    "        ## Sub-theme: Tone  \n",
    "\n",
    "        ### Code: Positivity  \n",
    "        **Definition:** Identifies AI’s tendency to adopt an overly agreeable or affirming tone. Feedback is seen as flattering or “people-pleasing,” potentially at the expense of critical or constructive input.  \n",
    "\n",
    "        ---\n",
    "\n",
    "        # Theme: Relational  \n",
    "\n",
    "        ## Sub-theme: Relational  \n",
    "\n",
    "        ### Code: Personal  \n",
    "        **Definition:** Emphasises the value students place on human interaction and relational qualities in feedback. They view feedback as more meaningful when it comes from people who understand them personally, can express emotion, and provide embodied, human connection.  \n",
    "\n",
    "        ### Code: Expert  \n",
    "        **Definition:** Reflects the importance of feedback coming from recognised experts, such as tutors or lecturers. Students perceive human expertise as superior to AI, due to its grounding in disciplinary knowledge and professional experience.  \n",
    "\n",
    "        ---\n",
    "\n",
    "        # Theme: Value  \n",
    "\n",
    "        ## Sub-theme: Value  \n",
    "\n",
    "        ### Code: Preference  \n",
    "        **Definition:** Expresses a general preference for not using AI for feedback, often without detailed justification. Students report personal dislike or lack of interest in AI as a feedback source.  \n",
    "\n",
    "        ### Code: Need  \n",
    "        **Definition:** Indicates that students feel no necessity for AI feedback, either because their existing human feedback sources are sufficient or because they are confident in their own skills.  \n",
    "\n",
    "        ### Code: Unsustainable  \n",
    "        **Definition:** Reflects ethical or environmental concerns about the use of AI. Students reject AI feedback due to its perceived ecological cost or association with unsustainable and unethical practices.  \n",
    "\n",
    "        ### Code: Privacy  \n",
    "        **Definition:** Concerns about the security and confidentiality of student work when submitted to AI platforms. Students fear loss of control over their data, possible misuse, or breaches of academic confidentiality.  \n",
    "\n",
    "        ### Code: Integrity  \n",
    "        **Definition:** Highlights a strong commitment to academic honesty and originality. Students reject AI feedback to avoid compromising their learning, breaking institutional rules, or engaging in behaviour perceived as unethical or academically dishonest.  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "                \n",
    "OUTPUT_FORMAT_43 =  \"\"\"\n",
    "\n",
    "    {\n",
    "        \"reasons\": [\n",
    "            {   \n",
    "                \"theme\": \"...\",\n",
    "                \"sub_theme\": \"...\",\n",
    "                \"code\": \"...\",\n",
    "                \"reasoning\": \"...\"\n",
    "            }\n",
    "        ]\n",
    "    }                        \n",
    "                    \n",
    "                    \n",
    "                    \"\"\"\n",
    "                    \n",
    "SHOTS_43 = \"\"\"\n",
    "\n",
    "Examples of good output:\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Question: \"Why didn’t you use GenAI for feedback on your work?\"\n",
    "\n",
    "Student response: \"I didn’t even know that this could be done. I also prefer to use my brain more to have creativity and originality in my work, studies and personal life.\"\n",
    "\n",
    "Good output:\n",
    "\n",
    "{\n",
    "    \"reasons\": [\n",
    "        {   \n",
    "            \"theme\": \"Processes\",\n",
    "            \"sub_theme\": \"Access\",\n",
    "            \"code\": \"Unaware\",\n",
    "            \"reasoning\": \"The clause 'I didn’t even know that this could be done' is a direct admission of not knowing GenAI can provide feedback. The Unaware code explicitly covers respondents who did not know GenAI could do this or how to use it, so the statement maps precisely to Processes → Access → Unaware.\"\n",
    "        },\n",
    "        {\n",
    "            \"theme\": \"Value\",\n",
    "            \"sub_theme\": \"Value\",\n",
    "            \"code\": \"Preference\",\n",
    "            \"reasoning\": \"The student states a normative stance—'I prefer to use my brain… for creativity and originality'—which indicates an intentional choice to avoid GenAI irrespective of its capabilities. This aligns with the Preference code, which captures a stated preference not to use GenAI without invoking a technical limitation.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Example 2:\n",
    "\n",
    "Question: \"Why didn’t you use GenAI for feedback on your work?\"\n",
    "Student response: \"I don't believe GenAI can provide more valuable feedback than I could get from a person proofreading it. I would rather ask a friend or family member to read what I've written.\"\n",
    "Good output:\n",
    "{\n",
    "    \"reasons\": [\n",
    "        {   \n",
    "            \"theme\": \"Information\",\n",
    "            \"sub_theme\": \"Quality\",\n",
    "            \"code\": \"Trustworthy\",\n",
    "            \"reasoning\": \"By asserting 'I don't believe GenAI can provide more valuable feedback' and preferring human proofreaders, the student signals skepticism about GenAI’s credibility and evaluative competence. The Trustworthy code captures doubts about accuracy/reliability of information or the source’s ability to provide sound feedback, which is exactly what this statement conveys.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "CODING_STRATEGY_43 = \"\"\"\n",
    "\n",
    "                        1) Scope & Principle\n",
    "\n",
    "                        Goal: Identify explicit reasons for not using GenAI.\n",
    "\n",
    "                        Surface-level only: Code the direct, literal meaning; do not infer beyond what is written.\n",
    "\n",
    "                        2) Chunking\n",
    "\n",
    "                        Split the response into meaningful chunks (sentence or key clause).\n",
    "\n",
    "                        Assign one code per chunk. If multiple codes could apply, choose the most specific.\n",
    "\n",
    "                        3) Required Fields\n",
    "\n",
    "                        For each usable chunk, produce one reason with:\n",
    "\n",
    "                        theme: Processes | Information | Tone | Relational | Value\n",
    "\n",
    "                        sub_theme: Use the correct sub-theme; if not stated, repeat the theme (i.e., sub_theme = theme).\n",
    "\n",
    "                        code: The specific characteristic (e.g., Unaware, Effortful, Less effort, Contextualised, Trustworthy, Privacy, Integrity, Unsustainable, Personal, Expert, Preference, Need, Positivity).\n",
    "\n",
    "                        reasoning: Brief justification that quotes or precisely references the triggering phrase(s) and ties them to the code definition.\n",
    "                        \n",
    "                        4) Usability Rules\n",
    "\n",
    "                        Usable: The chunk clearly states a reason for non-use (e.g., didn’t know, too hard/time, don’t trust, lacks context, not helpful, prefer human, no need, privacy, integrity, environmental concerns, style dislike).\n",
    "\n",
    "                        UNUSABLE: Unintelligible, off-topic, or no reason stated.\n",
    "\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "23c301de",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "\n",
    "    You're a expert qualitative researcher analyzing a student's response to a survey. Your task is to code the student's response following the coding strategy provided.\n",
    "\n",
    "    The aim of the research is {aim_research}\n",
    "\n",
    "    The coding strategy is {CODING_STRATEGY_V2}\n",
    "\n",
    "    The code for the actors is {actor_codes}\n",
    "\n",
    "    The code for the comparators is {comparator_codes}\n",
    "\n",
    "    The code for the characteristics is {characteristic_codes_v2}\n",
    "\n",
    "    The output format is {OUTPUT_FORMAT}\n",
    "\n",
    "    Some examples of good outputs are:\n",
    "\n",
    "    {SHOTS}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_43 = f\"\"\"\n",
    "\n",
    "    You're a expert qualitative researcher analyzing a student's response to a survey. Your task is to code the student's response following the coding strategy provided.\n",
    "\n",
    "    The aim of the research is {aim_research}\n",
    "\n",
    "    The coding strategy is {CODING_STRATEGY_43}\n",
    "\n",
    "    The code for the themes is {reasons_codes_v2}\n",
    "\n",
    "    The output format is {OUTPUT_FORMAT_43}\n",
    "\n",
    "    Some examples of good outputs are:\n",
    "\n",
    "    {SHOTS_43}\n",
    "\"\"\"\n",
    "\n",
    "initial_prompt = f\"\"\"\n",
    "\n",
    "    Based on the coding framework, the coding strategy, the output format, and the shots, analyse the student's response.\n",
    "    \n",
    "    Code all the responses, and output the results in the format {OUTPUT_FORMAT}.\n",
    "    \n",
    "    Keep the order of the chunks as they are in the student's response. If you code several chunks, keep the order of the chunks as they are in the student's response.\n",
    "    \n",
    "    JUST RETURN THE DESIRED OUTPUT, DO NOT ADD ANYTHING ELSE.\n",
    "    \"Return a single valid JSON object ONLY. \"\n",
    "    \"No markdown, no backticks, no prose. \"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "initial_prompt_43 = f\"\"\"\n",
    "\n",
    "    Based on the coding framework, the coding strategy, the output format, and the shots, analyse the student's response.\n",
    "    \n",
    "    Code all the responses, and output the results in the format {OUTPUT_FORMAT_43}.\n",
    "    \n",
    "    Keep the order of the chunks as they are in the student's response. If you code several chunks, keep the order of the chunks as they are in the student's response.\n",
    "    \n",
    "    JUST RETURN THE DESIRED OUTPUT, DO NOT ADD ANYTHING ELSE.\n",
    "    \"Return a single valid JSON object ONLY. \"\n",
    "    \"No markdown, no backticks, no prose. \"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03d3ad",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7924ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3bf911da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b9e0c",
   "metadata": {},
   "source": [
    "## 2. API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8f3bea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_SECRET_ACCESS_KEY = os.getenv(\"OPENAI_SECRET_ACCESS_KEY\")\n",
    "OPENAI_DEFAULT_REGION = \"australiaeast\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://cic-topic-modeling.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = \"chat\"\n",
    "SET_TEMP = 0.00000001\n",
    "\n",
    "\n",
    "model_azure = AzureChatOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    model = \"gpt-4-32k\", #gpt-4o model by default\n",
    "    temperature = SET_TEMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "709cac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call successful. Response:\n",
      "Hello there! 😊 How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Simple test to check if the Azure OpenAI API is working\n",
    "\n",
    "def test_openai_api(model):\n",
    "    try:\n",
    "        response = model.invoke([HumanMessage(content=\"Say hello!\")])\n",
    "        print(\"API call successful. Response:\")\n",
    "        print(response.content)\n",
    "    except Exception as e:\n",
    "        print(\"API call failed.\")\n",
    "        print(e)\n",
    "\n",
    "# Run the test\n",
    "test_openai_api(model_azure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031453ed",
   "metadata": {},
   "source": [
    "## 3. Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import json, re\n",
    "from typing import Tuple, Any\n",
    "\n",
    "_CODEFENCE_RE = re.compile(r\"^\\s*```(?:json)?\\s*(.*?)\\s*```\\s*$\", re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "def _strip_codefences(s: str) -> str:\n",
    "    m = _CODEFENCE_RE.match(s)\n",
    "    return m.group(1).strip() if m else s\n",
    "\n",
    "def _extract_json_segment(s: str) -> str:\n",
    "    \"\"\"Grab the innermost JSON-looking block if extra text surrounds it.\"\"\"\n",
    "    s = s.strip()\n",
    "    # Prefer object\n",
    "    lo, ro = s.find(\"{\"), s.rfind(\"}\")\n",
    "    if 0 <= lo < ro:\n",
    "        return s[lo:ro+1]\n",
    "    # Fallback to array\n",
    "    la, ra = s.find(\"[\"), s.rfind(\"]\")\n",
    "    if 0 <= la < ra:\n",
    "        return s[la:ra+1]\n",
    "    return s  # last resort\n",
    "\n",
    "def _soft_fixes(s: str) -> str:\n",
    "    # Normalize smart quotes\n",
    "    s = s.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\")\n",
    "    # Remove trailing commas before } or ]\n",
    "    s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "    return s\n",
    "\n",
    "def parse_iteration_json(raw: str) -> Tuple[Any, str]:\n",
    "    \"\"\"\n",
    "    Returns (obj, error). If parsing fails, obj=None and error explains why.\n",
    "    Accepts outputs with code fences, pre/post text, or minor JSON slop.\n",
    "    \"\"\"\n",
    "    candidate = _strip_codefences(raw)\n",
    "    candidate = _extract_json_segment(candidate)\n",
    "    candidate = _soft_fixes(candidate)\n",
    "    try:\n",
    "        return json.loads(candidate), \"\"\n",
    "    except json.JSONDecodeError as e:\n",
    "        return None, f\"JSON parse error: {e}\"\n",
    "\n",
    "\n",
    "class IterationCoder:\n",
    "    def __init__(self, name: str, model):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "    \n",
    "    def code_response(self, question_key: str, question_data: Dict, is_question_43: bool = False):\n",
    "        \"\"\"Code a single question response\"\"\"\n",
    "        if is_question_43:\n",
    "            system_msg = system_prompt_43\n",
    "            user_msg = f\"{initial_prompt_43}\\n\\nQuestion: {question_data['Question']}\\n\\nStudent response: {question_data['Response']}\"\n",
    "        else:\n",
    "            system_msg = system_prompt\n",
    "            user_msg = f\"{initial_prompt}\\n\\nQuestion: {question_data['Question']}\\n\\nStudent response: {question_data['Response']}\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke([\n",
    "                HumanMessage(content=f\"System: {system_msg}\\n\\nUser: {user_msg}\")\n",
    "            ])\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "class Researcher:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def validate_coding(self, question_key: str, question_data: Dict, iteration_codings: List[str], is_question_43: bool = False):\n",
    "        \"\"\"Validate the coding from all iterations\"\"\"\n",
    "        validation_prompt = f\"\"\"As a senior researcher, you need to validate the coding of three iterations for the following question:\n",
    "\n",
    "    Question: {question_data['Question']}\n",
    "    Student Response: {question_data['Response']}\n",
    "\n",
    "    Iteration 1 coding: {iteration_codings[0]}\n",
    "    Iteration 2 coding: {iteration_codings[1]}\n",
    "    Iteration 3 coding: {iteration_codings[2]}\n",
    "\n",
    "    Please provide:\n",
    "    1. A brief assessment of coding quality (1-5 scale)\n",
    "    2. Any major discrepancies between iterations\n",
    "    3. Recommendations for improvement\n",
    "\n",
    "    Format your response as JSON:\n",
    "    {{\n",
    "        \"quality_score\": 1-5,\n",
    "        \"discrepancies\": [\"list of major differences\"],\n",
    "        \"recommendations\": [\"list of suggestions\"]\n",
    "    }}\"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = self.model.invoke([HumanMessage(content=validation_prompt)])\n",
    "                return response.content\n",
    "            except Exception as e:\n",
    "                return f\"Error: {str(e)}\"\n",
    "\n",
    "class QuantitativeResearcher:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def calculate_metrics(self, all_results: List[Dict]):\n",
    "        \"\"\"Calculate various metrics from the coding results\"\"\"\n",
    "        metrics = {\n",
    "            \"total_responses\": len(all_results),\n",
    "            \"questions_coded\": {},\n",
    "            \"iteration_agreement\": {},\n",
    "            \"coding_quality\": {},\n",
    "            \"common_themes\": {},\n",
    "            \"actor_distribution\": {\"A\": 0, \"T\": 0, \"B\": 0},\n",
    "            \"comparator_distribution\": {\"More\": 0, \"Less\": 0, \"Similar\": 0}\n",
    "        }\n",
    "        \n",
    "        # Process each response\n",
    "        for result in all_results:\n",
    "            response_id = result[\"ResponseId\"]\n",
    "            \n",
    "            # Count questions coded\n",
    "            for key, value in result.items():\n",
    "                if key.startswith(\"Question \") and isinstance(value, dict) and \"iteration_codings\" in value:\n",
    "                    question_num = key.split(\" \")[1]\n",
    "                    if question_num not in metrics[\"questions_coded\"]:\n",
    "                        metrics[\"questions_coded\"][question_num] = 0\n",
    "                    metrics[\"questions_coded\"][question_num] += 1\n",
    "            \n",
    "                # Calculate iteration agreement for each question\n",
    "            for key, value in result.items():\n",
    "                if key.startswith(\"Question \") and isinstance(value, dict) and \"iteration_codings\" in value:\n",
    "                    question_num = key.split(\" \")[1]\n",
    "                    if question_num not in metrics[\"iteration_agreement\"]:\n",
    "                        metrics[\"iteration_agreement\"][question_num] = []\n",
    "                    \n",
    "                    # Simple agreement calculation (can be enhanced)\n",
    "                    iteration_codes = value[\"iteration_codings\"]\n",
    "                    if len(iteration_codes) == 3:\n",
    "                        # Count unique codes\n",
    "                        unique_codes = set()\n",
    "                        for iteration_code in iteration_codes:\n",
    "                            if isinstance(iteration_code, str) and \"codes\" in iteration_code:\n",
    "                                # Extract codes from JSON string (simplified)\n",
    "                                unique_codes.add(iteration_code[:100])  # Simplified for demo\n",
    "                        \n",
    "                        agreement_score = len(unique_codes) / 3  # Higher = less agreement\n",
    "                        metrics[\"iteration_agreement\"][question_num].append(agreement_score)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def _ensure_writable_dir(p: Path) -> Path:\n",
    "    try:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        return p\n",
    "    except OSError as e:\n",
    "        if e.errno in (EROFS, EACCES):\n",
    "            # fallback to a guaranteed-writable temp/home location\n",
    "            fallback = Path.cwd() / \"workflow_fallback\" / p.name\n",
    "            fallback.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"[warn] '{p}' not writable ({e}). Using '{fallback}' instead.\")\n",
    "            return fallback\n",
    "        raise\n",
    "\n",
    "\n",
    "def process_survey_files_iterations_only(\n",
    "    survey_dir: str = \"temp_survey\",\n",
    "    output_dir: str = \"first_coding\",\n",
    "    model_for_iterations=None  # if you want to inject/override\n",
    "):\n",
    "    \"\"\"\n",
    "    Iterations-only workflow:\n",
    "    - Loads each survey JSON\n",
    "    - For every 'Question N' with an Response, calls three IterationCoders\n",
    "    - Saves per-response files and one combined file\n",
    "    - Skips researcher validation and quantitative metrics\n",
    "    \"\"\"\n",
    "    # Make sure dirs exist\n",
    "    survey_dir = Path(survey_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    if output_dir.is_absolute():\n",
    "        # prevent writing to /\n",
    "        output_dir = Path.cwd() / output_dir.name\n",
    "    else:\n",
    "        output_dir = Path.cwd() / output_dir\n",
    "\n",
    "    output_dir = _ensure_writable_dir(output_dir)\n",
    "\n",
    "    # Init iterations\n",
    "    iteration1 = IterationCoder(\"Iteration1\", model_for_iterations or model_azure)\n",
    "    iteration2 = IterationCoder(\"Iteration2\", model_for_iterations or model_azure)\n",
    "    iteration3 = IterationCoder(\"Iteration3\", model_for_iterations or model_azure)\n",
    "\n",
    "    # Collect survey files\n",
    "    survey_files = [f for f in survey_dir.glob(\"*.json\") if f.name != \".DS_Store\"]\n",
    "    all_results = []\n",
    "\n",
    "    for survey_file in survey_files:\n",
    "        print(f\"Processing {survey_file.name}...\")\n",
    "        with open(survey_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            survey_data = json.load(f)\n",
    "\n",
    "        result = {\"ResponseId\": survey_data.get(\"ResponseId\", \"\")}\n",
    "\n",
    "        # Iterate questions\n",
    "        for key, value in survey_data.items():\n",
    "            if key.startswith(\"Question \") and isinstance(value, dict) and \"Response\" in value:\n",
    "                question_num = key.split(\" \")[1]\n",
    "                is_question_43 = (question_num == \"43\")\n",
    "\n",
    "                print(f\"  Coding {key}...\")\n",
    "                e1_raw = iteration1.code_response(key, value, is_question_43)\n",
    "                e2_raw = iteration2.code_response(key, value, is_question_43)\n",
    "                e3_raw = iteration3.code_response(key, value, is_question_43)\n",
    "\n",
    "                e1_obj, e1_err = parse_iteration_json(e1_raw)\n",
    "                e2_obj, e2_err = parse_iteration_json(e2_raw)\n",
    "                e3_obj, e3_err = parse_iteration_json(e3_raw)\n",
    "\n",
    "                result[key] = {\n",
    "                    \"Question\": value.get(\"Question\", \"\"),\n",
    "                    \"Response\": value.get(\"Response\", \"\"),\n",
    "                    \"iteration_codings\": {\n",
    "                        \"Iteration1\": e1_obj if e1_obj is not None else {\"_raw\": e1_raw, \"_error\": e1_err},\n",
    "                        \"Iteration2\": e2_obj if e2_obj is not None else {\"_raw\": e2_raw, \"_error\": e2_err},\n",
    "                        \"Iteration3\": e3_obj if e3_obj is not None else {\"_raw\": e3_raw, \"_error\": e3_err},\n",
    "                    }\n",
    "                }\n",
    "\n",
    "        # Save individual result\n",
    "        out_file = output_dir / f\"{result['ResponseId'] or survey_file.stem}_coded.json\"\n",
    "        with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "        all_results.append(result)\n",
    "        print(f\"  Saved to {out_file}\")\n",
    "\n",
    "    # Save combined results only (no metrics, no validation)\n",
    "    combined_file = output_dir / \"all_coded_responses.json\"\n",
    "    with open(combined_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"\\nWorkflow completed (iterations-only)!\")\n",
    "    print(f\"Processed {len(survey_files)} survey files\")\n",
    "    print(f\"Combined results saved to: {combined_file}\")\n",
    "\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8529a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing R_4C4j4KNUq9N3VGC.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4C4j4KNUq9N3VGC_coded.json\n",
      "Processing R_4CKOoHgU8hp01rg.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4CKOoHgU8hp01rg_coded.json\n",
      "Processing R_43e00PZDT3YYIZ2.json...\n",
      "  Coding Question 43...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_43e00PZDT3YYIZ2_coded.json\n",
      "Processing R_4P0PnRK3k4DjAxR.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4P0PnRK3k4DjAxR_coded.json\n",
      "Processing R_4Ka5vRl3NuBJ1Af.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4Ka5vRl3NuBJ1Af_coded.json\n",
      "Processing R_4AYVtTmMd0q7vte.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4AYVtTmMd0q7vte_coded.json\n",
      "Processing R_1gTNWbmwxtRxrf8.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_1gTNWbmwxtRxrf8_coded.json\n",
      "Processing R_4sn9pI5HdvhV5gI.json...\n",
      "  Coding Question 43...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4sn9pI5HdvhV5gI_coded.json\n",
      "Processing R_1VQ5hmwtdpRmnmu.json...\n",
      "  Coding Question 40...\n",
      "  Coding Question 41...\n",
      "  Coding Question 42...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_1VQ5hmwtdpRmnmu_coded.json\n",
      "Processing R_4aRLJoWmhKsYLOF.json...\n",
      "  Coding Question 43...\n",
      "  Saved to /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/R_4aRLJoWmhKsYLOF_coded.json\n",
      "\n",
      "Workflow completed (iterations-only)!\n",
      "Processed 10 survey files\n",
      "Combined results saved to: /Users/brayampineda/Library/CloudStorage/OneDrive-UTS/Research Project/workflow/first_coding/all_coded_responses.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseId': 'R_4C4j4KNUq9N3VGC',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': 'GenAI gives instant answers anytime. while a teacher offers personalized feedback and better interaction for deeper understanding.',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'gives instant answers anytime' directly maps to the Speed code, highlighting the immediacy and time-efficient nature of GenAI feedback compared to teachers.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'offers personalized feedback' explicitly indicates that teacher feedback is tailored to the individual, aligning with the Personal code under the Relational theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The phrase 'better interaction for deeper understanding' suggests that teacher feedback facilitates comprehension and clarity, which aligns with the Understanding code under the Sense-making theme.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'gives instant answers anytime' directly maps to the Speed code, highlighting the immediacy and time-efficient nature of GenAI feedback compared to teachers.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'offers personalized feedback' explicitly indicates that teacher feedback is tailored to the individual, aligning with the Personal code under the Relational theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The phrase 'better interaction for deeper understanding' suggests that teacher feedback facilitates comprehension and clarity, which aligns with the Understanding code under the Sense-making theme.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'gives instant answers anytime' directly maps to the Speed code, highlighting the immediacy and time-efficient nature of GenAI feedback compared to teachers.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'offers personalized feedback' explicitly indicates that teacher feedback is tailored to the individual, aligning with the Personal code under the Relational theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The phrase 'better interaction for deeper understanding' suggests that teacher feedback facilitates comprehension and clarity, which aligns with the Understanding code under the Sense-making theme.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': \"The feedback from GenAI felt more neutral and efficient while my teacher's feedback was more personal and encouraging.\",\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The phrase 'felt more neutral' directly indicates an emotionally indifferent response to GenAI feedback. The No impact code captures this lack of significant emotional reaction.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The term 'efficient' suggests that GenAI feedback required less effort or was more streamlined. The Less effort code captures this reduction in cognitive or procedural load.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'more personal' explicitly highlights the relational quality of teacher feedback. The Personal code captures this sense of tailored or individualised support.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The term 'encouraging' directly indicates a positive emotional impact from teacher feedback. The Positive code captures this sense of motivation and affirmation.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The phrase 'felt more neutral' directly indicates an emotionally neutral response to GenAI feedback. The No impact code captures this lack of significant emotional response.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The term 'efficient' suggests that GenAI feedback required less effort or cognitive load to process. The Less effort code captures this reduction in work or energy.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'more personal' explicitly highlights the relational quality of teacher feedback. The Personal code captures this sense of tailored or individualised support.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Tone',\n",
       "       'code': 'Positivity',\n",
       "       'reasoning': \"The term 'encouraging' directly indicates a positive tone in teacher feedback. The Positivity code captures this supportive and affirming quality.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The phrase 'felt more neutral' indicates an emotionally indifferent response to GenAI feedback. The No impact code captures this lack of significant emotional reaction.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The term 'efficient' suggests that GenAI feedback required less effort or was more streamlined. The Less effort code captures this reduction in cognitive or procedural load.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'more personal' directly indicates a relational quality in teacher feedback. The Personal code captures this sense of tailored or individualised support.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Tone',\n",
       "       'code': 'Positivity',\n",
       "       'reasoning': \"The term 'encouraging' explicitly describes a positive tone in teacher feedback. The Positivity code captures this supportive and affirming emotional quality.\"}]}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': 'GenAI feedback was quicker and focused on facts while my teacher provided more detailed explanations and emotional support.',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'GenAI feedback was quicker' directly indicates a faster response time, which aligns with the Speed code under the Access sub-theme.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Objective',\n",
       "       'reasoning': \"The phrase 'focused on facts' suggests impartiality and a fact-based approach, which aligns with the Objective code under the Quality sub-theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'provided more detailed explanations' directly indicates comprehensive and nuanced feedback, which aligns with the In-depth code under the Quality sub-theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The phrase 'emotional support' reflects relational and personalised feedback, which aligns with the Personal code under the Relational sub-theme.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'GenAI feedback was quicker' directly maps to the Speed code, as it highlights the immediacy and time-saving aspect of AI feedback compared to the teacher.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Objective',\n",
       "       'reasoning': \"The phrase 'focused on facts' suggests that GenAI feedback is impartial and grounded in factual information, aligning with the Objective code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'provided more detailed explanations' indicates that teacher feedback is comprehensive and nuanced, which aligns with the In-depth code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The mention of 'emotional support' reflects a relational and personalised aspect of teacher feedback, aligning with the Personal code.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'GenAI feedback was quicker' directly maps to the Speed code, as it highlights the immediacy and time-saving nature of AI feedback compared to the teacher.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Objective',\n",
       "       'reasoning': \"The phrase 'focused on facts' indicates that GenAI feedback is impartial and grounded in factual information, aligning with the Objective code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'provided more detailed explanations' explicitly points to the teacher offering comprehensive and nuanced feedback, which aligns with the In-depth code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The mention of 'emotional support' reflects a relational and personalised aspect of teacher feedback, aligning with the Personal code as it demonstrates awareness of the student's emotional needs.\"}]}}}},\n",
       " {'ResponseId': 'R_4CKOoHgU8hp01rg',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': 'Immediate Accessibility vs. Depth of Understanding:\\nGenAI: Provides instant feedback, which is great for quick answers, revision, or clarification of simple concepts. This immediate response helps with surface-level learning and understanding new topics quickly. However, it may not delve deeply into why something is correct or incorrect, which can limit deeper conceptual learning.\\nTeacher: While teacher feedback might take longer, it often fosters a deeper understanding. Teachers provide context, explain thought processes, and focus on correcting misunderstandings in a more thorough manner. This depth helps with mastering difficult topics and long-term retention.\\nAdaptability to Learning Styles:\\nGenAI: Can adapt to different inputs and provide general explanations, but lacks the nuanced understanding of your individual learning preferences. It often presents information in a neutral, one-size-fits-all manner, which might not always align with your learning style.\\nTeacher: Can tailor feedback to your personal learning preferences and adjust explanations based on your strengths and weaknesses. This personalized guidance can be more effective in addressing gaps in your knowledge.\\nSelf-Learning vs. Guided Learning:\\nGenAI: Encourages a degree of self-learning and exploration. Since you often have to interpret and apply the feedback yourself, it can build self-reliance and problem-solving skills. However, this may sometimes leave you without the clarity or support you need for more complex issues.\\nTeacher: Offers a more guided learning experience, ensuring you understand each step of the process. They can break down complicated problems, helping you connect concepts in ways you might not have thought of independently.\\nMotivation and Confidence:\\nGenAI: Provides neutral, objective feedback, which can be helpful, but it lacks emotional encouragement or personalized support. While it may clarify doubts, it doesn’t necessarily boost motivation or confidence as much.\\nTeacher:',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'Provides instant feedback' directly maps to the Speed code, highlighting the immediacy of GenAI's responses compared to teachers.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The statement 'it may not delve deeply into why something is correct or incorrect' indicates a limitation in GenAI's ability to foster deeper conceptual understanding, which aligns with the Understanding code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The description 'fosters a deeper understanding' and 'provides context, explains thought processes' highlights the teacher's ability to enhance comprehension, aligning with the Understanding code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'focus on correcting misunderstandings in a more thorough manner' reflects the teacher's ability to provide comprehensive and nuanced feedback, aligning with the In-depth code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The statement 'lacks the nuanced understanding of your individual learning preferences' indicates that GenAI feedback is less personalized, aligning with the Personal code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The description 'tailor feedback to your personal learning preferences' highlights the teacher's ability to provide personalized guidance, aligning with the Personal code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The statement 'encourages a degree of self-learning and exploration' suggests that GenAI reduces the effort required for independent problem-solving, aligning with the Less effort code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'More effort',\n",
       "       'reasoning': \"The description 'offers a more guided learning experience' implies that teacher feedback requires more effort from the teacher to ensure understanding, aligning with the More effort code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'lacks emotional encouragement or personalized support' indicates that GenAI feedback is less likely to evoke positive feelings, aligning with the Positive code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The implication that teachers provide 'personalized support' suggests that teacher feedback is more likely to evoke positive feelings, aligning with the Positive code.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'Provides instant feedback' directly maps to the Speed code, highlighting the immediacy of GenAI's responses compared to teachers.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The statement 'it may not delve deeply into why something is correct or incorrect' indicates a limitation in GenAI's ability to foster deeper conceptual understanding, aligning with the Understanding code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The description 'fosters a deeper understanding' and 'provides context, explains thought processes' highlights the teacher's ability to enhance conceptual understanding, aligning with the Understanding code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'focus on correcting misunderstandings in a more thorough manner' reflects the teacher's ability to provide comprehensive and nuanced feedback, aligning with the In-depth code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The statement 'lacks the nuanced understanding of your individual learning preferences' indicates that GenAI feedback is less personalized, aligning with the Personal code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The description 'tailor feedback to your personal learning preferences' highlights the teacher's ability to provide personalized guidance, aligning with the Personal code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Value',\n",
       "       'sub_theme': 'Value',\n",
       "       'code': 'Importance',\n",
       "       'reasoning': \"The statement 'encourages a degree of self-learning and exploration' reflects the value GenAI provides in fostering independence, aligning with the Importance code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The phrase 'you often have to interpret and apply the feedback yourself' suggests that while GenAI promotes self-reliance, it may lack the depth needed for reflective learning, aligning with the Reflection code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The statement 'ensuring you understand each step of the process' indicates that teacher feedback supports reflective and guided learning, aligning with the Reflection code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'lacks emotional encouragement or personalized support' indicates that GenAI feedback does not evoke strong positive emotions, aligning with the Positive code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The description 'personalized support' implies that teacher feedback is more likely to boost motivation and confidence, aligning with the Positive code.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'Provides instant feedback' directly maps to the Speed code, highlighting the immediacy of GenAI's responses compared to teachers.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The statement 'it may not delve deeply into why something is correct or incorrect' explicitly indicates that GenAI lacks depth in its feedback, aligning with the In-depth code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The description 'fosters a deeper understanding' and 'provides context, explain thought processes' highlights the thoroughness of teacher feedback, which aligns with the In-depth code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The phrase 'provides context' explicitly refers to feedback being adapted to the specific situation, which matches the Contextualised code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The statement 'lacks the nuanced understanding of your individual learning preferences' indicates that GenAI feedback is less personalized, aligning with the Personal code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The statement 'Can tailor feedback to your personal learning preferences' explicitly highlights the personalized nature of teacher feedback, aligning with the Personal code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The statement 'Encourages a degree of self-learning and exploration' implies that GenAI reduces the effort required for independent learning, aligning with the Less effort code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'More effort',\n",
       "       'reasoning': \"The statement 'Offers a more guided learning experience' suggests that teacher feedback requires more effort to engage with, aligning with the More effort code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'lacks emotional encouragement or personalized support' indicates that GenAI feedback is less likely to evoke positive feelings, aligning with the Positive code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'personalized guidance can be more effective' implies that teacher feedback fosters positive feelings through tailored support, aligning with the Positive code.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': 'No',\n",
       "   'iteration_codings': {'Iteration1': {'codes': []},\n",
       "    'Iteration2': {'codes': []},\n",
       "    'Iteration3': {'codes': []}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': 'Depth of Feedback:\\nGenAI: Provides general and broad feedback based on the information it has been trained on, with a focus on a variety of subjects and technical accuracy. It may offer suggestions for improving clarity, structure, and logic, but sometimes lacks detailed, personalized insight.\\nTeacher: Offers more specific, individualized feedback. A teacher can pinpoint exactly where your misunderstandings lie and offer tailored advice based on your learning history, class discussions, and personal strengths/weaknesses.\\nInteraction and Clarification:\\nGenAI: While it can provide immediate responses, any clarification requests might lead to further iterations that don’t fully address specific nuances or educational standards.\\nTeacher: Can provide real-time interaction, and their feedback can evolve during a conversation. Teachers can adapt their feedback based on your immediate questions and guide you through complex concepts interactively.\\nPersonal Context:\\nGenAI: Offers neutral and objective responses, not necessarily aware of your personal goals, context, or progress unless you provide that background explicitly.\\nTeacher: Knows your academic history, learning style, and class performance, allowing them to give feedback that aligns with your personal development and educational goals.\\nFocus on Practical Application:\\nGenAI: May provide theoretical advice and focus on ideal answers. It doesn’t always account for real-world applications or specific academic contexts unless explicitly prompted.\\nTeacher: Can emphasize the practical application of knowledge, often linking feedback to how concepts will be tested, used in projects, or applied in professional settings.',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The student states that GenAI 'sometimes lacks detailed, personalized insight,' which directly contrasts with the depth and personalization of teacher feedback. This aligns with the In-depth code, as it highlights a lack of comprehensive and nuanced feedback from GenAI.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The student describes teacher feedback as 'more specific, individualized feedback' and notes that teachers can 'pinpoint exactly where your misunderstandings lie.' This directly maps to the Specificity code, which captures detailed and precise feedback.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The student mentions that GenAI 'can provide immediate responses,' which directly aligns with the Speed code, highlighting the immediacy and time-saving nature of GenAI feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The student notes that teachers can 'adapt their feedback based on your immediate questions and guide you through complex concepts interactively,' which reflects the Ease code by emphasizing the convenience and adaptability of teacher feedback in real-time interactions.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Objective',\n",
       "       'reasoning': \"The student describes GenAI feedback as 'neutral and objective,' which directly aligns with the Objective code, emphasizing impartiality and freedom from personal bias.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The student highlights that teachers 'know your academic history, learning style, and class performance,' which allows them to provide feedback that is tailored to the individual. This aligns with the Personal code, reflecting relational support and personalization.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The student notes that GenAI 'doesn't always account for real-world applications or specific academic contexts unless explicitly prompted,' which indicates a lack of contextual adaptation. This aligns with the Contextualised code, as it highlights the absence of situational awareness in GenAI feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The student states that teachers 'link feedback to how concepts will be tested, used in projects, or applied in professional settings,' which demonstrates a strong alignment with the Contextualised code, as it reflects feedback tailored to specific academic and real-world contexts.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The student states that GenAI 'sometimes lacks detailed, personalized insight,' which directly contrasts with the teacher's feedback being more specific and individualized. This indicates that GenAI provides less in-depth feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The student describes teacher feedback as 'more specific, individualized feedback' and highlights the ability to 'pinpoint exactly where your misunderstandings lie,' which aligns with the Specificity code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The student notes that GenAI 'can provide immediate responses,' which directly maps to the Speed code, emphasizing the immediacy of feedback compared to teachers.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The student highlights that teachers 'can provide real-time interaction' and adapt feedback during a conversation, which reflects the Ease code as it emphasizes the convenience and adaptability of teacher feedback.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Objective',\n",
       "       'reasoning': \"The student describes GenAI as offering 'neutral and objective responses,' which directly aligns with the Objective code, emphasizing impartiality in feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The student states that teachers 'know your academic history, learning style, and class performance,' which allows them to provide feedback that is personalized and tailored to the individual, aligning with the Personal code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The student notes that GenAI 'doesn't always account for real-world applications or specific academic contexts unless explicitly prompted,' indicating that it provides less contextualized feedback compared to teachers.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The student explains that teachers 'emphasize the practical application of knowledge' and link feedback to 'how concepts will be tested, used in projects, or applied in professional settings,' which aligns with the Contextualised code.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The student states that GenAI 'sometimes lacks detailed, personalized insight,' which directly contrasts with the depth and specificity of teacher feedback. This aligns with the In-depth code, as it highlights a limitation in the comprehensiveness of GenAI feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The student describes teacher feedback as 'more specific, individualized,' which directly maps to the Specificity code. Teachers are noted for pinpointing misunderstandings and tailoring advice, emphasizing their ability to provide precise and detailed feedback.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The student mentions that GenAI 'can provide immediate responses,' which directly aligns with the Speed code, highlighting the efficiency and immediacy of GenAI feedback compared to teachers.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The student notes that teachers 'can provide real-time interaction' and adapt feedback during conversations, which reflects the Ease code. This highlights the convenience and adaptability of teacher feedback in interactive settings.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Objective',\n",
       "       'reasoning': \"The student describes GenAI feedback as 'neutral and objective,' which directly aligns with the Objective code. This highlights the impartial and unbiased nature of GenAI feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The student states that teachers 'know your academic history, learning style, and class performance,' which allows them to provide personalized feedback. This directly maps to the Personal code, emphasizing the relational and tailored nature of teacher feedback.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The student notes that GenAI 'doesn't always account for real-world applications or specific academic contexts unless explicitly prompted,' which highlights a limitation in contextual adaptation. This aligns with the Contextualised code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Relevance',\n",
       "       'reasoning': \"The student mentions that teachers 'emphasize the practical application of knowledge' and link feedback to real-world or academic contexts. This aligns with the Relevance code, as it highlights the alignment of teacher feedback with practical and situational needs.\"}]}}}},\n",
       " {'ResponseId': 'R_43e00PZDT3YYIZ2',\n",
       "  'Question 43': {'Question': 'Why didn’t you use GenAI for feedback on your work?',\n",
       "   'Response': \"I didn't know how / if gen AI would know about how to improve my work from a Nursign perspective. I m also very new to this so i Didn't even think about it\",\n",
       "   'iteration_codings': {'Iteration1': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The student states 'I didn't know how / if gen AI would know about how to improve my work' and 'I didn't even think about it,' which indicates a lack of awareness about GenAI's capabilities and its potential application. This aligns with the Unaware code, which captures uncertainty or lack of knowledge about using GenAI.\"},\n",
       "      {'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The phrase 'how / if gen AI would know about how to improve my work from a Nursing perspective' reflects a concern about the alignment of GenAI feedback with the specific academic and disciplinary context. This aligns with the Contextualised code, which highlights limitations in AI feedback when it lacks alignment with disciplinary expectations.\"}]},\n",
       "    'Iteration2': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The student states 'I didn't know how / if gen AI would know about how to improve my work' and 'I m also very new to this so i Didn't even think about it,' which indicates a lack of awareness about GenAI's capabilities and its potential application. This aligns with the Unaware code, which captures uncertainty or lack of knowledge about using GenAI for feedback.\"},\n",
       "      {'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The phrase 'if gen AI would know about how to improve my work from a Nursign perspective' reflects a concern about the alignment of GenAI feedback with the specific academic and disciplinary context. This aligns with the Contextualised code, which highlights limitations in AI feedback when it lacks alignment with disciplinary expectations.\"}]},\n",
       "    'Iteration3': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The student states 'I didn't know how / if gen AI would know about how to improve my work,' indicating a lack of understanding about GenAI's capabilities. This aligns with the Unaware code, which captures uncertainty about how to use GenAI or its potential.\"},\n",
       "      {'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'I'm also very new to this so I didn't even think about it' reflects a lack of familiarity and consideration of GenAI for feedback. This directly maps to the Unaware code, as it highlights the student's inexperience and unawareness of the tool.\"}]}}}},\n",
       " {'ResponseId': 'R_4P0PnRK3k4DjAxR',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': \"I find that it's more convenient/timely to get feedback from AI. I also found that often if it's feedback that the teacher is required to give, then sometimes it feels lackluster or copy-pasted from student to student. This applied more to high school than it does at uni, but the sentiment still remains.\",\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The phrase 'more convenient/timely to get feedback from AI' directly indicates ease of access. The Ease code captures the convenience of obtaining feedback, which the student explicitly attributes to AI.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The statement 'it feels lackluster or copy-pasted from student to student' suggests a lack of personalisation in teacher feedback. The Personal code reflects feedback that is tailored or individualised, which the student implies is less present in teacher feedback.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'more convenient/timely to get feedback from AI' directly indicates that AI feedback is faster and more accessible compared to teacher feedback. This aligns with the Speed code, which captures immediacy and time-saving aspects.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The statement 'it feels lackluster or copy-pasted from student to student' suggests that teacher feedback lacks personalisation and is generic. This aligns with the Personal code, which reflects tailored or individualised feedback.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'more convenient/timely to get feedback from AI' directly indicates that AI feedback is faster and more accessible compared to teacher feedback. This aligns with the Speed code, which captures immediacy and time-saving aspects.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Relevance',\n",
       "       'reasoning': \"The statement 'it feels lackluster or copy-pasted from student to student' suggests that teacher feedback lacks personalisation and specificity, making it less relevant to individual students. This aligns with the Relevance code, which captures alignment with the student's needs or task.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': 'Not really. Just that you can ask the AI to explain in a way that makes sense to you.',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The statement 'you can ask the AI to explain in a way that makes sense to you' directly indicates that AI facilitates better comprehension. This aligns with the Understanding code, which captures the ability to clarify and make content more digestible.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The statement 'you can ask the AI to explain in a way that makes sense to you' directly indicates that AI facilitates better comprehension. This aligns with the Understanding code, which captures the ability to clarify and make content more digestible.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Understanding',\n",
       "       'reasoning': \"The statement 'you can ask the AI to explain in a way that makes sense to you' directly indicates that AI facilitates better comprehension. This aligns with the Understanding code, which captures the ability to clarify and make content more digestible.\"}]}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': 'Nothing that comes to mind.',\n",
       "   'iteration_codings': {'Iteration1': {'codes': []},\n",
       "    'Iteration2': {'codes': []},\n",
       "    'Iteration3': {'codes': []}}}},\n",
       " {'ResponseId': 'R_4Ka5vRl3NuBJ1Af',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': 'Feedbacks from Gen AI are generic but broader in persepctives which may further spur more thoughts. Feedbacks from teacher are personalized and more specific',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'broader in perspectives' suggests that GenAI feedback provides a wider range of ideas or considerations, aligning with the In-depth code which captures comprehensive and nuanced feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The term 'personalized' directly indicates that teacher feedback is tailored to the individual, which aligns with the Personal code capturing relational and individualised support.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The phrase 'more specific' explicitly highlights that teacher feedback is detailed and concrete, which matches the Specificity code capturing precise and focused feedback.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'broader in perspectives' suggests that GenAI feedback provides a wider range of ideas or insights, aligning with the In-depth code, which captures comprehensive and nuanced feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The term 'personalized' directly indicates that teacher feedback is tailored to the individual, which aligns with the Personal code under the Relational theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The phrase 'more specific' explicitly highlights that teacher feedback is detailed and precise, which matches the Specificity code under the Quality sub-theme.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'broader in perspectives' suggests that GenAI feedback provides a wider range of ideas or considerations, aligning with the In-depth code, which captures comprehensive and nuanced feedback.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Personal',\n",
       "       'reasoning': \"The term 'personalized' directly indicates that teacher feedback is tailored to the individual, which aligns with the Personal code under the Relational theme.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The phrase 'more specific' explicitly highlights that teacher feedback is detailed and precise, which matches the Specificity code under the Quality sub-theme.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': 'both are equally useful and can be combined to achieve better outcomes',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'B',\n",
       "       'comparator': 'Similar',\n",
       "       'theme': 'Value',\n",
       "       'sub_theme': 'Value',\n",
       "       'code': 'Importance',\n",
       "       'reasoning': \"The phrase 'both are equally useful' explicitly indicates a similarity in the perceived value of feedback from both AI and teachers. The Importance code captures the significance attributed to both sources of feedback.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'B',\n",
       "       'comparator': 'Similar',\n",
       "       'theme': 'Value',\n",
       "       'sub_theme': 'Value',\n",
       "       'code': 'Importance',\n",
       "       'reasoning': \"The phrase 'both are equally useful' explicitly indicates that the student perceives both GenAI and teacher feedback as having comparable value. The Importance code captures the perceived significance of feedback, which the student assigns equally to both sources.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'B',\n",
       "       'comparator': 'Similar',\n",
       "       'theme': 'Value',\n",
       "       'sub_theme': 'Value',\n",
       "       'code': 'Importance',\n",
       "       'reasoning': \"The phrase 'both are equally useful' explicitly indicates that the student perceives both GenAI and teacher feedback as having comparable value. The Importance code captures the perceived significance of feedback, which the student assigns equally to both sources.\"}]}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': \"Gen AI allowed me to take my time to ask for feedbacks and any follow-up quesitons, while from teachers, sometimes there's an unspoken pressure to keep the question/answer process to be efficient (as quick and as precise as possible)\",\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The phrase 'allowed me to take my time to ask for feedbacks and any follow-up questions' indicates a reduction in cognitive or time-related effort when interacting with GenAI. This aligns with the Less effort code, as the student perceives the process as more relaxed and less constrained.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Risky',\n",
       "       'code': 'Risky',\n",
       "       'reasoning': \"The mention of 'unspoken pressure to keep the question/answer process to be efficient' suggests a sense of vulnerability or fear of judgment when interacting with teachers. This aligns with the Risky code, as the student perceives the interaction as more constrained and potentially intimidating.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The phrase 'allowed me to take my time to ask for feedbacks and any follow-up questions' suggests a reduction in cognitive or time-related pressure when interacting with GenAI. This aligns with the Less effort code, as the student perceives the process as more relaxed and less demanding.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Relational',\n",
       "       'code': 'Risky',\n",
       "       'reasoning': \"The mention of 'unspoken pressure to keep the question/answer process to be efficient' indicates a sense of vulnerability or fear of judgment when interacting with teachers. This aligns with the Risky code, as the student perceives the interaction as more constrained and potentially intimidating.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Effort',\n",
       "       'code': 'Less effort',\n",
       "       'reasoning': \"The phrase 'allowed me to take my time to ask for feedbacks and any follow-up questions' suggests a reduction in cognitive or time-related pressure when interacting with GenAI. This aligns with the Less effort code, as the student perceives the process as more relaxed and less demanding.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Relational',\n",
       "       'sub_theme': 'Risky',\n",
       "       'code': 'Risky',\n",
       "       'reasoning': \"The statement 'sometimes there's an unspoken pressure to keep the question/answer process to be efficient' indicates a sense of vulnerability or fear of judgment when interacting with teachers. This aligns with the Risky code, as the student perceives the interaction as carrying a higher relational or emotional risk.\"}]}}}},\n",
       " {'ResponseId': 'R_4AYVtTmMd0q7vte',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': 'GenAI is available 24/7 and responds instantly whereas teachers take a while or never respond so there was n',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The phrase 'GenAI is available 24/7' directly indicates convenience and lack of barriers in accessing feedback, which aligns with the Ease code under Access.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The term 'responds instantly' explicitly highlights the immediacy of feedback, which maps directly to the Speed code under Access.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The statement 'teachers take a while or never respond' suggests significant barriers or delays in accessing feedback, which contrasts with the ease of access provided by GenAI.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The phrase 'GenAI is available 24/7' directly indicates convenience and lack of barriers in accessing feedback, which aligns with the Ease code.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The term 'responds instantly' explicitly highlights the immediacy of feedback, which maps directly to the Speed code.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The statement 'teachers take a while or never respond' suggests barriers or delays in accessing teacher feedback, which contrasts with the ease of accessing GenAI feedback.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Ease',\n",
       "       'reasoning': \"The phrase 'GenAI is available 24/7' directly indicates convenience and lack of barriers in accessing feedback, which aligns with the Ease code under Access.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The phrase 'responds instantly' explicitly highlights the immediacy of GenAI feedback, which maps directly to the Speed code under Access.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'Less',\n",
       "       'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Speed',\n",
       "       'reasoning': \"The statement 'teachers take a while or never respond' contrasts with GenAI's instant responses, indicating slower or absent feedback from teachers, which aligns with the Speed code under Access.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': 'No',\n",
       "   'iteration_codings': {'Iteration1': {'codes': []},\n",
       "    'Iteration2': {'codes': []},\n",
       "    'Iteration3': {'codes': []}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': 'No',\n",
       "   'iteration_codings': {'Iteration1': {'codes': []},\n",
       "    'Iteration2': {'codes': []},\n",
       "    'Iteration3': {'codes': []}}}},\n",
       " {'ResponseId': 'R_1gTNWbmwxtRxrf8',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': \"between AI and a teacher, the teacher is always going to be the more trustworthy source, however AI's ability to collate large amounts of information into a digestible chunk is useful\",\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Reliable',\n",
       "       'reasoning': \"The phrase 'the teacher is always going to be the more trustworthy source' explicitly highlights the teacher's reliability as a stronger characteristic compared to AI.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Understandable',\n",
       "       'reasoning': \"The statement 'AI's ability to collate large amounts of information into a digestible chunk' directly refers to AI's capacity to present information in a clear and accessible manner, aligning with the Understandable code.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Reliable',\n",
       "       'reasoning': \"The phrase 'the teacher is always going to be the more trustworthy source' explicitly highlights the teacher's reliability as a stronger characteristic compared to AI.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Understandable',\n",
       "       'reasoning': \"The statement 'AI's ability to collate large amounts of information into a digestible chunk' directly refers to AI's capacity to present information in a clear and accessible manner, aligning with the Understandable code.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Reliable',\n",
       "       'reasoning': \"The phrase 'the teacher is always going to be the more trustworthy source' explicitly highlights the teacher's reliability as a stronger characteristic compared to AI.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Understandable',\n",
       "       'reasoning': \"The statement 'AI's ability to collate large amounts of information into a digestible chunk' directly refers to AI making information easier to grasp, aligning with the Understandable code.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': 'no, teachers and ai are usually fairly similar in feedback delivery style',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'B',\n",
       "       'comparator': 'Similar',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Tone',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The student explicitly states 'teachers and AI are usually fairly similar in feedback delivery style,' which suggests an emotionally neutral response to both sources. The 'No impact' code captures this lack of significant emotional difference.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'B',\n",
       "       'comparator': 'Similar',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Tone',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The student states 'teachers and AI are usually fairly similar in feedback delivery style,' which implies no significant emotional or stylistic difference in tone. The 'No impact' code captures the neutral emotional response and lack of differentiation in tone between the two actors.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'B',\n",
       "       'comparator': 'Similar',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Tone',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The student explicitly states that 'teachers and AI are usually fairly similar in feedback delivery style,' indicating no significant emotional or stylistic difference in tone. This aligns with the 'No impact' code under Tone, as the feedback delivery style does not evoke a distinct emotional response.\"}]}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': 'nil',\n",
       "   'iteration_codings': {'Iteration1': {'codes': []},\n",
       "    'Iteration2': {'codes': []},\n",
       "    'Iteration3': {'codes': []}}}},\n",
       " {'ResponseId': 'R_4sn9pI5HdvhV5gI',\n",
       "  'Question 43': {'Question': 'Why didn’t you use GenAI for feedback on your work?',\n",
       "   'Response': 'Have not thought to use it and unsure on trusting AI',\n",
       "   'iteration_codings': {'Iteration1': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'Have not thought to use it' indicates a lack of consideration or awareness about using GenAI for feedback. This aligns with the Unaware code, which captures situations where students do not consider using GenAI or lack knowledge of its potential.\"},\n",
       "      {'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Trustworthy',\n",
       "       'reasoning': \"The phrase 'unsure on trusting AI' directly expresses doubt about the reliability or credibility of GenAI feedback. This aligns with the Trustworthy code, which captures skepticism about the accuracy or legitimacy of AI feedback.\"}]},\n",
       "    'Iteration2': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'Have not thought to use it' indicates a lack of consideration or awareness about using GenAI for feedback. This aligns with the Unaware code, which captures situations where students do not consider using GenAI or lack knowledge of its potential.\"},\n",
       "      {'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Trustworthy',\n",
       "       'reasoning': \"The phrase 'unsure on trusting AI' directly expresses doubt about the reliability or credibility of AI-generated feedback. This aligns with the Trustworthy code, which captures skepticism about the accuracy or legitimacy of AI feedback.\"}]},\n",
       "    'Iteration3': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'Have not thought to use it' indicates a lack of consideration or awareness about using GenAI for feedback. This aligns with the Unaware code, which captures situations where students do not consider using GenAI or lack knowledge of its potential.\"},\n",
       "      {'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Trustworthy',\n",
       "       'reasoning': \"The phrase 'unsure on trusting AI' directly reflects doubts about the reliability and credibility of GenAI feedback. This aligns with the Trustworthy code, which captures skepticism about the accuracy or legitimacy of AI-generated feedback.\"}]}}}},\n",
       " {'ResponseId': 'R_1VQ5hmwtdpRmnmu',\n",
       "  'Question 40': {'Question': 'Please describe any differences in how it impacted your learning (comparing GenAI and your teacher)?',\n",
       "   'Response': 'GenAI is helpful for finding technical errors and finding understandable overvies of specific topics. Teachers on the other hand search for more implicit reasonigns when providing feedback',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The phrase 'helpful for finding technical errors and finding understandable overviews of specific topics' indicates that GenAI provides detailed and precise feedback. This aligns with the Specificity code, which captures concrete and precise information.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The statement 'Teachers on the other hand search for more implicit reasonings when providing feedback' suggests that teachers encourage deeper thinking and self-examination. This aligns with the Reflection code, which involves critical thinking and deeper consideration of reasoning.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The phrase 'helpful for finding technical errors and finding understandable overviews of specific topics' indicates that GenAI provides detailed and precise feedback. This aligns with the Specificity code, which captures concrete and precise information.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The statement 'Teachers on the other hand search for more implicit reasonings when providing feedback' suggests that teachers encourage deeper thinking and self-examination. This aligns with the Reflection code, which involves critical thinking and deeper consideration of reasoning.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Specificity',\n",
       "       'reasoning': \"The phrase 'helpful for finding technical errors and finding understandable overviews of specific topics' indicates that GenAI provides detailed and precise feedback. This aligns with the Specificity code, which captures concrete and precise information.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Sense-making',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The statement 'Teachers on the other hand search for more implicit reasonings when providing feedback' suggests that teachers encourage deeper thinking and self-examination. This aligns with the Reflection code, which involves critical thinking and deeper consideration of reasoning.\"}]}}},\n",
       "  'Question 41': {'Question': 'Were there any differences in how the feedback made you feel (comparing GenAI and your teacher)?',\n",
       "   'Response': 'A teachers feedback will impact you more than an AI as GenAI is designed to be neutral, and provides code generated feedback, however, a teachers feedback is far more impactful as it is a human makign judgements on your work, thus your feelings of reward and disappointment will be greater',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'a teacher's feedback is far more impactful' and 'your feelings of reward... will be greater' directly indicate that teacher feedback evokes stronger positive emotions compared to GenAI.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Negative',\n",
       "       'reasoning': \"The phrase 'your feelings of... disappointment will be greater' explicitly highlights that teacher feedback also elicits stronger negative emotions compared to GenAI.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The description 'GenAI is designed to be neutral' implies that AI feedback does not evoke significant emotional responses, aligning with the 'No impact' code.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'a teacher's feedback will impact you more' and 'your feelings of reward... will be greater' explicitly indicate a stronger positive emotional impact from teacher feedback compared to AI.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Negative',\n",
       "       'reasoning': \"The phrase 'your feelings of... disappointment will be greater' directly signals a stronger negative emotional impact from teacher feedback compared to AI.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The description 'GenAI is designed to be neutral' implies an emotionally neutral response, aligning with the No impact code for AI feedback.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Positive',\n",
       "       'reasoning': \"The statement 'a teacher's feedback is far more impactful' and 'your feelings of reward... will be greater' directly indicate a stronger positive emotional response to teacher feedback compared to AI.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'Negative',\n",
       "       'reasoning': \"The phrase 'your feelings of... disappointment will be greater' explicitly highlights a stronger negative emotional response to teacher feedback compared to AI.\"},\n",
       "      {'actor': 'A',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Feeling',\n",
       "       'sub_theme': 'Feeling',\n",
       "       'code': 'No impact',\n",
       "       'reasoning': \"The description 'GenAI is designed to be neutral' suggests that AI feedback evokes minimal emotional response, aligning with the No impact code.\"}]}}},\n",
       "  'Question 42': {'Question': 'Describe any other differences between the feedback you received from GenAI and your teacher.',\n",
       "   'Response': 'teachers search more for the greater meaning of a piece of work, and attempt to understand the ideology and thought process behind the work',\n",
       "   'iteration_codings': {'Iteration1': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'In-depth',\n",
       "       'reasoning': \"The phrase 'search more for the greater meaning of a piece of work' indicates a focus on comprehensive and nuanced understanding, which aligns with the In-depth code. This suggests that teachers provide more layered and thorough feedback compared to other sources.\"},\n",
       "      {'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Information',\n",
       "       'sub_theme': 'Quality',\n",
       "       'code': 'Contextualised',\n",
       "       'reasoning': \"The statement 'attempt to understand the ideology and thought process behind the work' reflects an effort to adapt feedback to the specific intellectual and creative context of the student's work. This aligns with the Contextualised code, as it demonstrates awareness of situational and individual requirements.\"}]},\n",
       "    'Iteration2': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Reflection',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The phrase 'teachers search more for the greater meaning of a piece of work' and 'attempt to understand the ideology and thought process behind the work' directly aligns with the Reflection code. This captures the teacher's focus on deeper self-examination and critical thinking about the student's work, which is explicitly stated as a distinguishing characteristic.\"}]},\n",
       "    'Iteration3': {'codes': [{'actor': 'T',\n",
       "       'comparator': 'More',\n",
       "       'theme': 'Sense-making',\n",
       "       'sub_theme': 'Reflection',\n",
       "       'code': 'Reflection',\n",
       "       'reasoning': \"The phrase 'teachers search more for the greater meaning of a piece of work' and 'attempt to understand the ideology and thought process behind the work' directly aligns with the Reflection code, as it involves deeper consideration and critical thinking about the student's work and thought process.\"}]}}}},\n",
       " {'ResponseId': 'R_4aRLJoWmhKsYLOF',\n",
       "  'Question 43': {'Question': 'Why didn’t you use GenAI for feedback on your work?',\n",
       "   'Response': 'Did not know that it could be used like that.',\n",
       "   'iteration_codings': {'Iteration1': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'Did not know that it could be used like that' directly indicates a lack of awareness about GenAI's capability to provide feedback. This aligns with the Unaware code, which captures situations where students are unaware of the tool's potential or operation.\"}]},\n",
       "    'Iteration2': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'Did not know that it could be used like that' directly indicates a lack of awareness about GenAI's capability to provide feedback. This aligns with the Unaware code, which captures situations where students are unaware of GenAI's potential or operation.\"}]},\n",
       "    'Iteration3': {'reasons': [{'theme': 'Processes',\n",
       "       'sub_theme': 'Access',\n",
       "       'code': 'Unaware',\n",
       "       'reasoning': \"The phrase 'Did not know that it could be used like that' directly indicates a lack of awareness about GenAI's capability to provide feedback. This aligns with the Unaware code, which captures situations where students are unaware of GenAI's potential or operation.\"}]}}}}]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_survey_files_iterations_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf54a4",
   "metadata": {},
   "source": [
    "## 4. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6fa1400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick access function\n",
    "def quick_get_coding(response_id, question_key):\n",
    "    \"\"\"Quick access to coding data\"\"\"\n",
    "    with open(\"first_coding/all_coded_responses.json\", 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for response in data:\n",
    "        if response[\"ResponseId\"] == response_id:\n",
    "            if question_key in response:\n",
    "                return response[question_key]\n",
    "            else:\n",
    "                print(f\"Question {question_key} not found in {response_id}\")\n",
    "                return None\n",
    "    print(f\"Response ID {response_id} not found\")\n",
    "    return None\n",
    "\n",
    "# Usage example:\n",
    "coding = quick_get_coding(\"R_1VQ5hmwtdpRmnmu\", \"Question 40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "538bb9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actor': 'A',\n",
       "  'comparator': 'More',\n",
       "  'theme': 'Information',\n",
       "  'sub_theme': 'Quality',\n",
       "  'code': 'Specificity',\n",
       "  'reasoning': \"The phrase 'helpful for finding technical errors and finding understandable overviews of specific topics' indicates that GenAI provides detailed and specific information. This aligns with the Specificity code, which captures feedback that is precise and detailed.\"},\n",
       " {'actor': 'T',\n",
       "  'comparator': 'More',\n",
       "  'theme': 'Information',\n",
       "  'sub_theme': 'Quality',\n",
       "  'code': 'In-depth',\n",
       "  'reasoning': \"The statement 'search for more implicit reasonings when providing feedback' suggests that teachers focus on deeper, more nuanced aspects of reasoning. This aligns with the In-depth code, which captures feedback that is thorough and nuanced.\"}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coding['iteration_codings']['Iteration3']['codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e2837c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "def compare_human_model_codings(all_coded_responses_path: str, temp_survey_folder: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare human-coded responses with model-coded responses.\n",
    "    \n",
    "    Args:\n",
    "        all_coded_responses_path: Path to the all_coded_responses.json file\n",
    "        temp_survey_folder: Path to the temp_survey folder containing human-coded files\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with comparison of human vs model codings\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the model responses\n",
    "    with open(all_coded_responses_path, 'r', encoding='utf-8') as f:\n",
    "        model_responses = json.load(f)\n",
    "    \n",
    "    # Create a dictionary for quick lookup\n",
    "    model_lookup = {resp['ResponseId']: resp for resp in model_responses}\n",
    "    \n",
    "    # Get list of human-coded files\n",
    "    human_files = [f for f in os.listdir(temp_survey_folder) if f.endswith('.json')]\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for human_file in human_files:\n",
    "        response_id = human_file.replace('.json', '')\n",
    "        \n",
    "        # Skip if this response ID is not in the model responses\n",
    "        if response_id not in model_lookup:\n",
    "            continue\n",
    "            \n",
    "        # Load human-coded response\n",
    "        human_file_path = os.path.join(temp_survey_folder, human_file)\n",
    "        with open(human_file_path, 'r', encoding='utf-8') as f:\n",
    "            human_response = json.load(f)\n",
    "        \n",
    "        model_response = model_lookup[response_id]\n",
    "        \n",
    "        # Process each question\n",
    "        for question_key in human_response:\n",
    "            if not question_key.startswith('Question'):\n",
    "                continue\n",
    "                \n",
    "            # Skip if question doesn't exist in model response\n",
    "            if question_key not in model_response:\n",
    "                continue\n",
    "            \n",
    "            human_codes = human_response[question_key].get('Codes', [])\n",
    "            model_iteration_codings = model_response[question_key].get('iteration_codings', {})\n",
    "            \n",
    "            # Format human codes\n",
    "            human_actor_comparator = []\n",
    "            human_characteristics = []\n",
    "            for code in human_codes:\n",
    "                if code.get('Actor', '') not in ['nil', 'Nil', '']:\n",
    "                    human_actor_comparator.append(f\"{code.get('Actor', '')}-{code.get('Comparator', '').lower()}\")\n",
    "                    human_characteristics.append(code.get('Characteristic', ''))\n",
    "            \n",
    "            # Format model codes for each iteration\n",
    "            iteration_data = {}\n",
    "            for iteration_name in ['Iteration1', 'Iteration2', 'Iteration3']:\n",
    "                iteration_codes = model_iteration_codings.get(iteration_name, {}).get('codes', [])\n",
    "                \n",
    "                actor_comparator = []\n",
    "                characteristics = []\n",
    "                themes = []\n",
    "                sub_themes = []\n",
    "                reasonings = []\n",
    "                \n",
    "                for code in iteration_codes:\n",
    "                    actor_comparator.append(f\"{code.get('actor', '')}-{code.get('comparator', '').lower()}\")\n",
    "                    characteristics.append(code.get('code', ''))\n",
    "                    themes.append(code.get('theme', ''))\n",
    "                    sub_themes.append(code.get('sub_theme', ''))\n",
    "                    reasonings.append(code.get('reasoning', ''))\n",
    "                \n",
    "                iteration_data[iteration_name] = {\n",
    "                    'actor_comparator': actor_comparator,\n",
    "                    'characteristics': characteristics,\n",
    "                    'themes': themes,\n",
    "                    'sub_themes': sub_themes,\n",
    "                    'reasonings': reasonings\n",
    "                }\n",
    "            \n",
    "            # Create comparison row\n",
    "            comparison_data.append({\n",
    "                'ResponseId': response_id,\n",
    "                'Question': question_key,\n",
    "                'Question_Text': model_response[question_key].get('Question', ''),\n",
    "                'Response_Text': model_response[question_key].get('Response', ''),\n",
    "                'Human_Actor_Comparator': human_actor_comparator,\n",
    "                'Human_Characteristics': human_characteristics,\n",
    "                **{f\"{iter_name}_Actor_Comparator\": data['actor_comparator'] for iter_name, data in iteration_data.items()},\n",
    "                **{f\"{iter_name}_Characteristics\": data['characteristics'] for iter_name, data in iteration_data.items()},\n",
    "                **{f\"{iter_name}_Themes\": data['themes'] for iter_name, data in iteration_data.items()},\n",
    "                **{f\"{iter_name}_SubThemes\": data['sub_themes'] for iter_name, data in iteration_data.items()},\n",
    "                **{f\"{iter_name}_Reasonings\": data['reasonings'] for iter_name, data in iteration_data.items()}\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Reorder columns for better readability\n",
    "    if not df.empty:\n",
    "        base_cols = ['ResponseId', 'Question', 'Question_Text', 'Response_Text', \n",
    "                    'Human_Actor_Comparator', 'Human_Characteristics']\n",
    "        iteration_cols = []\n",
    "        for iteration in ['Iteration1', 'Iteration2', 'Iteration3']:\n",
    "            iteration_cols.extend([\n",
    "                f'{iteration}_Actor_Comparator',\n",
    "                f'{iteration}_Characteristics',\n",
    "                f'{iteration}_Themes',\n",
    "                f'{iteration}_SubThemes',\n",
    "                f'{iteration}_Reasonings'\n",
    "            ])\n",
    "        \n",
    "        df = df[base_cols + iteration_cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_question_summary(comparison_df: pd.DataFrame, question: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get summary for a specific question.\n",
    "    \n",
    "    Args:\n",
    "        comparison_df: DataFrame from compare_human_model_codings\n",
    "        question: Question key (e.g., 'Question 40')\n",
    "    \n",
    "    Returns:\n",
    "        Filtered DataFrame for the specific question\n",
    "    \"\"\"\n",
    "    return comparison_df[comparison_df['Question'] == question]\n",
    "\n",
    "def get_actor_comparator_summary(comparison_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get summary of Actor-Comparator patterns.\n",
    "    \n",
    "    Args:\n",
    "        comparison_df: DataFrame from compare_human_model_codings\n",
    "    \n",
    "    Returns:\n",
    "        Summary DataFrame with Actor-Comparator counts\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    # Human coding summary\n",
    "    human_summary = comparison_df.groupby(['Human_Actor', 'Human_Comparator']).size().reset_index(name='Human_Count')\n",
    "    summary_data.append(human_summary)\n",
    "    \n",
    "    # Model coding summary for each iteration\n",
    "    for iteration in ['Iteration1', 'Iteration2', 'Iteration3']:\n",
    "        actor_col = f'{iteration}_Actor'\n",
    "        comparator_col = f'{iteration}_Comparator'\n",
    "        \n",
    "        if actor_col in comparison_df.columns:\n",
    "            iteration_summary = comparison_df.groupby([actor_col, comparator_col]).size().reset_index(name=f'{iteration}_Count')\n",
    "            summary_data.append(iteration_summary)\n",
    "    \n",
    "    # Merge all summaries\n",
    "    if summary_data:\n",
    "        final_summary = summary_data[0]\n",
    "        for summary in summary_data[1:]:\n",
    "            final_summary = final_summary.merge(summary, on=['Human_Actor', 'Human_Comparator'], how='outer')\n",
    "        \n",
    "        # Fill NaN values with 0\n",
    "        final_summary = final_summary.fillna(0)\n",
    "        \n",
    "        return final_summary\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "11672921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "comparison_df = compare_human_model_codings(\n",
    "    'first_coding/all_coded_responses.json',\n",
    "    'temp_survey'\n",
    ")\n",
    "\n",
    "# # Get summary for specific question\n",
    "# question_40_summary = get_question_summary(comparison_df, 'Question 40')\n",
    "\n",
    "# # Get Actor-Comparator summary\n",
    "# actor_comparator_summary = get_actor_comparator_summary(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a7b92e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>Question</th>\n",
       "      <th>Question_Text</th>\n",
       "      <th>Response_Text</th>\n",
       "      <th>Human_Actor_Comparator</th>\n",
       "      <th>Human_Characteristics</th>\n",
       "      <th>Iteration1_Actor_Comparator</th>\n",
       "      <th>Iteration1_Characteristics</th>\n",
       "      <th>Iteration1_Themes</th>\n",
       "      <th>Iteration1_SubThemes</th>\n",
       "      <th>...</th>\n",
       "      <th>Iteration2_Actor_Comparator</th>\n",
       "      <th>Iteration2_Characteristics</th>\n",
       "      <th>Iteration2_Themes</th>\n",
       "      <th>Iteration2_SubThemes</th>\n",
       "      <th>Iteration2_Reasonings</th>\n",
       "      <th>Iteration3_Actor_Comparator</th>\n",
       "      <th>Iteration3_Characteristics</th>\n",
       "      <th>Iteration3_Themes</th>\n",
       "      <th>Iteration3_SubThemes</th>\n",
       "      <th>Iteration3_Reasonings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>R_1gTNWbmwxtRxrf8</td>\n",
       "      <td>Question 40</td>\n",
       "      <td>Please describe any differences in how it impa...</td>\n",
       "      <td>between AI and a teacher, the teacher is alway...</td>\n",
       "      <td>[T-more, A-more]</td>\n",
       "      <td>[Reliable, Understandable]</td>\n",
       "      <td>[T-more, A-more, A-more]</td>\n",
       "      <td>[Reliable, Understandable, Utility]</td>\n",
       "      <td>[Information, Information, Information]</td>\n",
       "      <td>[Quality, Quality, Quality]</td>\n",
       "      <td>...</td>\n",
       "      <td>[T-more, A-more, A-more]</td>\n",
       "      <td>[Reliable, Understandable, Utility]</td>\n",
       "      <td>[Information, Information, Information]</td>\n",
       "      <td>[Quality, Quality, Quality]</td>\n",
       "      <td>[The phrase 'the teacher is always going to be...</td>\n",
       "      <td>[T-more, A-more, A-more]</td>\n",
       "      <td>[Reliable, Understandable, Volume]</td>\n",
       "      <td>[Information, Information, Processes]</td>\n",
       "      <td>[Quality, Quality, Access]</td>\n",
       "      <td>[The phrase 'the teacher is always going to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R_43e00PZDT3YYIZ2</td>\n",
       "      <td>Question 43</td>\n",
       "      <td>Why didn’t you use GenAI for feedback on your ...</td>\n",
       "      <td>I didn't know how / if gen AI would know about...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>R_1gTNWbmwxtRxrf8</td>\n",
       "      <td>Question 42</td>\n",
       "      <td>Describe any other differences between the fee...</td>\n",
       "      <td>nil</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ResponseId     Question  \\\n",
       "16  R_1gTNWbmwxtRxrf8  Question 40   \n",
       "6   R_43e00PZDT3YYIZ2  Question 43   \n",
       "18  R_1gTNWbmwxtRxrf8  Question 42   \n",
       "\n",
       "                                        Question_Text  \\\n",
       "16  Please describe any differences in how it impa...   \n",
       "6   Why didn’t you use GenAI for feedback on your ...   \n",
       "18  Describe any other differences between the fee...   \n",
       "\n",
       "                                        Response_Text Human_Actor_Comparator  \\\n",
       "16  between AI and a teacher, the teacher is alway...       [T-more, A-more]   \n",
       "6   I didn't know how / if gen AI would know about...                     []   \n",
       "18                                                nil                     []   \n",
       "\n",
       "         Human_Characteristics Iteration1_Actor_Comparator  \\\n",
       "16  [Reliable, Understandable]    [T-more, A-more, A-more]   \n",
       "6                           []                          []   \n",
       "18                          []                          []   \n",
       "\n",
       "             Iteration1_Characteristics  \\\n",
       "16  [Reliable, Understandable, Utility]   \n",
       "6                                    []   \n",
       "18                                   []   \n",
       "\n",
       "                          Iteration1_Themes         Iteration1_SubThemes  ...  \\\n",
       "16  [Information, Information, Information]  [Quality, Quality, Quality]  ...   \n",
       "6                                        []                           []  ...   \n",
       "18                                       []                           []  ...   \n",
       "\n",
       "   Iteration2_Actor_Comparator           Iteration2_Characteristics  \\\n",
       "16    [T-more, A-more, A-more]  [Reliable, Understandable, Utility]   \n",
       "6                           []                                   []   \n",
       "18                          []                                   []   \n",
       "\n",
       "                          Iteration2_Themes         Iteration2_SubThemes  \\\n",
       "16  [Information, Information, Information]  [Quality, Quality, Quality]   \n",
       "6                                        []                           []   \n",
       "18                                       []                           []   \n",
       "\n",
       "                                Iteration2_Reasonings  \\\n",
       "16  [The phrase 'the teacher is always going to be...   \n",
       "6                                                  []   \n",
       "18                                                 []   \n",
       "\n",
       "   Iteration3_Actor_Comparator          Iteration3_Characteristics  \\\n",
       "16    [T-more, A-more, A-more]  [Reliable, Understandable, Volume]   \n",
       "6                           []                                  []   \n",
       "18                          []                                  []   \n",
       "\n",
       "                        Iteration3_Themes        Iteration3_SubThemes  \\\n",
       "16  [Information, Information, Processes]  [Quality, Quality, Access]   \n",
       "6                                      []                          []   \n",
       "18                                     []                          []   \n",
       "\n",
       "                                Iteration3_Reasonings  \n",
       "16  [The phrase 'the teacher is always going to be...  \n",
       "6                                                  []  \n",
       "18                                                 []  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "17d355d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 21)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b0f4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comparison results to CSV\n",
    "# Convert list values to strings before exporting\n",
    "comparison_df.map(lambda x: str(x) if isinstance(x, list) else x).to_csv('comparison_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8ef81c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "def compare_human_model_codings(all_coded_responses_path: str, temp_survey_folder: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare human-coded responses with model-coded responses.\n",
    "    \n",
    "    Args:\n",
    "        all_coded_responses_path: Path to the all_coded_responses.json file\n",
    "        temp_survey_folder: Path to the temp_survey folder containing human-coded files\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with comparison of human vs model codings\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the model responses\n",
    "    with open(all_coded_responses_path, 'r', encoding='utf-8') as f:\n",
    "        model_responses = json.load(f)\n",
    "    \n",
    "    # Create a dictionary for quick lookup\n",
    "    model_lookup = {resp['ResponseId']: resp for resp in model_responses}\n",
    "    \n",
    "    # Get list of human-coded files\n",
    "    human_files = [f for f in os.listdir(temp_survey_folder) if f.endswith('.json')]\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for human_file in human_files:\n",
    "        response_id = human_file.replace('.json', '')\n",
    "        \n",
    "        # Skip if this response ID is not in the model responses\n",
    "        if response_id not in model_lookup:\n",
    "            continue\n",
    "            \n",
    "        # Load human-coded response\n",
    "        human_file_path = os.path.join(temp_survey_folder, human_file)\n",
    "        with open(human_file_path, 'r', encoding='utf-8') as f:\n",
    "            human_response = json.load(f)\n",
    "        \n",
    "        model_response = model_lookup[response_id]\n",
    "        \n",
    "        # Process each question\n",
    "        for question_key in human_response:\n",
    "            if not question_key.startswith('Question'):\n",
    "                continue\n",
    "                \n",
    "            # Skip if question doesn't exist in model response\n",
    "            if question_key not in model_response:\n",
    "                continue\n",
    "            \n",
    "            # Handle different structures for different questions\n",
    "            if question_key == \"Question 43\":\n",
    "                # For Question 43: Human has \"Reasons\" list, Model has \"iteration_codings\" with \"reasons\"\n",
    "                human_codes = human_response[question_key].get('Reasons', [])\n",
    "                model_iteration_codings = model_response[question_key].get('iteration_codings', {})\n",
    "                \n",
    "                # Extract human coding information as lists (for Question 43, these are just reasons)\n",
    "                human_characteristics = human_codes if isinstance(human_codes, list) else []\n",
    "                human_actor_comparators = []  # Not applicable for Question 43\n",
    "                \n",
    "                # Process model codes for each iteration\n",
    "                iteration_data_dict = {}\n",
    "                for iteration_name, iteration_data in model_iteration_codings.items():\n",
    "                    iteration_reasons = iteration_data.get('reasons', [])\n",
    "                    \n",
    "                    iteration_themes = []\n",
    "                    iteration_subthemes = []\n",
    "                    iteration_codes_list = []\n",
    "                    iteration_reasonings = []\n",
    "                    \n",
    "                    for model_reason in iteration_reasons:\n",
    "                        theme = model_reason.get('theme', '')\n",
    "                        sub_theme = model_reason.get('sub_theme', '')\n",
    "                        code = model_reason.get('code', '')\n",
    "                        reasoning = model_reason.get('reasoning', '')\n",
    "                        \n",
    "                        iteration_themes.append(theme)\n",
    "                        iteration_subthemes.append(sub_theme)\n",
    "                        iteration_codes_list.append(code)\n",
    "                        iteration_reasonings.append(reasoning)\n",
    "                    \n",
    "                    iteration_data_dict[iteration_name] = {\n",
    "                        'themes': iteration_themes,\n",
    "                        'subthemes': iteration_subthemes,\n",
    "                        'codes': iteration_codes_list,\n",
    "                        'reasonings': iteration_reasonings\n",
    "                    }\n",
    "                \n",
    "                # Create comparison row for Question 43\n",
    "                comparison_data.append({\n",
    "                    'ResponseId': response_id,\n",
    "                    'Question': question_key,\n",
    "                    'Human_Actor_Comparator': human_actor_comparators,\n",
    "                    'Human_Characteristics': human_characteristics,\n",
    "                    'Iteration1_Actor_Comparator': [],\n",
    "                    'Iteration1_Characteristics': iteration_data_dict.get('Iteration1', {}).get('codes', []),\n",
    "                    'Iteration1_Themes': iteration_data_dict.get('Iteration1', {}).get('themes', []),\n",
    "                    'Iteration1_SubThemes': iteration_data_dict.get('Iteration1', {}).get('subthemes', []),\n",
    "                    'Iteration1_Reasonings': iteration_data_dict.get('Iteration1', {}).get('reasonings', []),\n",
    "                    'Iteration2_Actor_Comparator': [],\n",
    "                    'Iteration2_Characteristics': iteration_data_dict.get('Iteration2', {}).get('codes', []),\n",
    "                    'Iteration2_Themes': iteration_data_dict.get('Iteration2', {}).get('themes', []),\n",
    "                    'Iteration2_SubThemes': iteration_data_dict.get('Iteration2', {}).get('subthemes', []),\n",
    "                    'Iteration2_Reasonings': iteration_data_dict.get('Iteration2', {}).get('reasonings', []),\n",
    "                    'Iteration3_Actor_Comparator': [],\n",
    "                    'Iteration3_Characteristics': iteration_data_dict.get('Iteration3', {}).get('codes', []),\n",
    "                    'Iteration3_Themes': iteration_data_dict.get('Iteration3', {}).get('themes', []),\n",
    "                    'Iteration3_SubThemes': iteration_data_dict.get('Iteration3', {}).get('subthemes', []),\n",
    "                    'Iteration3_Reasonings': iteration_data_dict.get('Iteration3', {}).get('reasonings', [])\n",
    "                })\n",
    "                \n",
    "            else:\n",
    "                # For Questions 40, 41, 42: Original structure with Actor-Comparator-Characteristic\n",
    "                human_codes = human_response[question_key].get('Codes', [])\n",
    "                model_iteration_codings = model_response[question_key].get('iteration_codings', {})\n",
    "                \n",
    "                # Extract human coding information as lists\n",
    "                human_actors = []\n",
    "                human_comparators = []\n",
    "                human_characteristics = []\n",
    "                human_actor_comparators = []\n",
    "                \n",
    "                for human_code in human_codes:\n",
    "                    actor = human_code.get('Actor', '')\n",
    "                    comparator = human_code.get('Comparator', '')\n",
    "                    characteristic = human_code.get('Characteristic', '')\n",
    "                    \n",
    "                    # Skip if no meaningful coding\n",
    "                    if actor in ['nil', 'Nil', '']:\n",
    "                        continue\n",
    "                    \n",
    "                    human_actors.append(actor)\n",
    "                    human_comparators.append(comparator)\n",
    "                    human_characteristics.append(characteristic)\n",
    "                    human_actor_comparators.append(f\"{actor}-{comparator}\")\n",
    "                \n",
    "                # Process model codes for each iteration\n",
    "                iteration_data_dict = {}\n",
    "                for iteration_name, iteration_data in model_iteration_codings.items():\n",
    "                    iteration_codes = iteration_data.get('codes', [])\n",
    "                    \n",
    "                    iteration_actors = []\n",
    "                    iteration_comparators = []\n",
    "                    iteration_themes = []\n",
    "                    iteration_subthemes = []\n",
    "                    iteration_codes_list = []\n",
    "                    iteration_reasonings = []\n",
    "                    iteration_actor_comparators = []\n",
    "                    \n",
    "                    for model_code in iteration_codes:\n",
    "                        actor = model_code.get('actor', '')\n",
    "                        comparator = model_code.get('comparator', '')\n",
    "                        theme = model_code.get('theme', '')\n",
    "                        sub_theme = model_code.get('sub_theme', '')\n",
    "                        code = model_code.get('code', '')\n",
    "                        reasoning = model_code.get('reasoning', '')\n",
    "                        \n",
    "                        iteration_actors.append(actor)\n",
    "                        iteration_comparators.append(comparator)\n",
    "                        iteration_themes.append(theme)\n",
    "                        iteration_subthemes.append(sub_theme)\n",
    "                        iteration_codes_list.append(code)\n",
    "                        iteration_reasonings.append(reasoning)\n",
    "                        iteration_actor_comparators.append(f\"{actor}-{comparator}\")\n",
    "                    \n",
    "                    iteration_data_dict[iteration_name] = {\n",
    "                        'actors': iteration_actors,\n",
    "                        'comparators': iteration_comparators,\n",
    "                        'themes': iteration_themes,\n",
    "                        'subthemes': iteration_subthemes,\n",
    "                        'codes': iteration_codes_list,\n",
    "                        'reasonings': iteration_reasonings,\n",
    "                        'actor_comparators': iteration_actor_comparators\n",
    "                    }\n",
    "                \n",
    "                # Create comparison row for Questions 40-42\n",
    "                comparison_data.append({\n",
    "                    'ResponseId': response_id,\n",
    "                    'Question': question_key,\n",
    "                    'Human_Actor_Comparator': human_actor_comparators,\n",
    "                    'Human_Characteristics': human_characteristics,\n",
    "                    'Iteration1_Actor_Comparator': iteration_data_dict.get('Iteration1', {}).get('actor_comparators', []),\n",
    "                    'Iteration1_Characteristics': iteration_data_dict.get('Iteration1', {}).get('codes', []),\n",
    "                    'Iteration1_Themes': iteration_data_dict.get('Iteration1', {}).get('themes', []),\n",
    "                    'Iteration1_SubThemes': iteration_data_dict.get('Iteration1', {}).get('subthemes', []),\n",
    "                    'Iteration1_Reasonings': iteration_data_dict.get('Iteration1', {}).get('reasonings', []),\n",
    "                    'Iteration2_Actor_Comparator': iteration_data_dict.get('Iteration2', {}).get('actor_comparators', []),\n",
    "                    'Iteration2_Characteristics': iteration_data_dict.get('Iteration2', {}).get('codes', []),\n",
    "                    'Iteration2_Themes': iteration_data_dict.get('Iteration2', {}).get('themes', []),\n",
    "                    'Iteration2_SubThemes': iteration_data_dict.get('Iteration2', {}).get('subthemes', []),\n",
    "                    'Iteration2_Reasonings': iteration_data_dict.get('Iteration2', {}).get('reasonings', []),\n",
    "                    'Iteration3_Actor_Comparator': iteration_data_dict.get('Iteration3', {}).get('actor_comparators', []),\n",
    "                    'Iteration3_Characteristics': iteration_data_dict.get('Iteration3', {}).get('codes', []),\n",
    "                    'Iteration3_Themes': iteration_data_dict.get('Iteration3', {}).get('themes', []),\n",
    "                    'Iteration3_SubThemes': iteration_data_dict.get('Iteration3', {}).get('subthemes', []),\n",
    "                    'Iteration3_Reasonings': iteration_data_dict.get('Iteration3', {}).get('reasonings', [])\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_question_summary(comparison_df: pd.DataFrame, question: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get summary for a specific question.\n",
    "    \n",
    "    Args:\n",
    "        comparison_df: DataFrame from compare_human_model_codings\n",
    "        question: Question key (e.g., 'Question 40')\n",
    "    \n",
    "    Returns:\n",
    "        Filtered DataFrame for the specific question\n",
    "    \"\"\"\n",
    "    return comparison_df[comparison_df['Question'] == question]\n",
    "\n",
    "def get_actor_comparator_summary(comparison_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get summary of Actor-Comparator patterns.\n",
    "    \n",
    "    Args:\n",
    "        comparison_df: DataFrame from compare_human_model_codings\n",
    "    \n",
    "    Returns:\n",
    "        Summary DataFrame with Actor-Comparator counts\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    # Human coding summary\n",
    "    human_actor_comparators = []\n",
    "    for actor_comparators in comparison_df['Human_Actor_Comparator']:\n",
    "        human_actor_comparators.extend(actor_comparators)\n",
    "    \n",
    "    human_summary = pd.Series(human_actor_comparators).value_counts().reset_index()\n",
    "    human_summary.columns = ['Actor_Comparator', 'Human_Count']\n",
    "    summary_data.append(human_summary)\n",
    "    \n",
    "    # Model coding summary for each iteration\n",
    "    for iteration in ['Iteration1', 'Iteration2', 'Iteration3']:\n",
    "        actor_comparator_col = f'{iteration}_Actor_Comparator'\n",
    "        \n",
    "        if actor_comparator_col in comparison_df.columns:\n",
    "            iteration_actor_comparators = []\n",
    "            for actor_comparators in comparison_df[actor_comparator_col]:\n",
    "                iteration_actor_comparators.extend(actor_comparators)\n",
    "            \n",
    "            iteration_summary = pd.Series(iteration_actor_comparators).value_counts().reset_index()\n",
    "            iteration_summary.columns = ['Actor_Comparator', f'{iteration}_Count']\n",
    "            summary_data.append(iteration_summary)\n",
    "    \n",
    "    # Merge all summaries\n",
    "    if summary_data:\n",
    "        final_summary = summary_data[0]\n",
    "        for summary in summary_data[1:]:\n",
    "            final_summary = final_summary.merge(summary, on='Actor_Comparator', how='outer')\n",
    "        \n",
    "        # Fill NaN values with 0\n",
    "        final_summary = final_summary.fillna(0)\n",
    "        \n",
    "        return final_summary\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "def get_characteristics_summary(comparison_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get summary of characteristics/codes used.\n",
    "    \n",
    "    Args:\n",
    "        comparison_df: DataFrame from compare_human_model_codings\n",
    "    \n",
    "    Returns:\n",
    "        Summary DataFrame with characteristics counts\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    # Human characteristics summary\n",
    "    human_characteristics = []\n",
    "    for characteristics in comparison_df['Human_Characteristics']:\n",
    "        human_characteristics.extend(characteristics)\n",
    "    \n",
    "    human_summary = pd.Series(human_characteristics).value_counts().reset_index()\n",
    "    human_summary.columns = ['Characteristic', 'Human_Count']\n",
    "    summary_data.append(human_summary)\n",
    "    \n",
    "    # Model characteristics summary for each iteration\n",
    "    for iteration in ['Iteration1', 'Iteration2', 'Iteration3']:\n",
    "        characteristics_col = f'{iteration}_Characteristics'\n",
    "        \n",
    "        if characteristics_col in comparison_df.columns:\n",
    "            iteration_characteristics = []\n",
    "            for characteristics in comparison_df[characteristics_col]:\n",
    "                iteration_characteristics.extend(characteristics)\n",
    "            \n",
    "            iteration_summary = pd.Series(iteration_characteristics).value_counts().reset_index()\n",
    "            iteration_summary.columns = ['Characteristic', f'{iteration}_Count']\n",
    "            summary_data.append(iteration_summary)\n",
    "    \n",
    "    # Merge all summaries\n",
    "    if summary_data:\n",
    "        final_summary = summary_data[0]\n",
    "        for summary in summary_data[1:]:\n",
    "            final_summary = final_summary.merge(summary, on='Characteristic', how='outer')\n",
    "        \n",
    "        # Fill NaN values with 0\n",
    "        final_summary = final_summary.fillna(0)\n",
    "        \n",
    "        return final_summary\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6eba8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "comparison_df = compare_human_model_codings(\n",
    "    'first_coding/all_coded_responses.json',\n",
    "    'temp_survey'\n",
    ")\n",
    "\n",
    "# # Get summary for specific question\n",
    "# question_40_summary = get_question_summary(comparison_df, 'Question 40')\n",
    "\n",
    "# # Get Actor-Comparator summary\n",
    "# actor_comparator_summary = get_actor_comparator_summary(comparison_df)\n",
    "\n",
    "# # Get Characteristics summary\n",
    "# characteristics_summary = get_characteristics_summary(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "235b8997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 19 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   ResponseId                   24 non-null     object\n",
      " 1   Question                     24 non-null     object\n",
      " 2   Human_Actor_Comparator       24 non-null     object\n",
      " 3   Human_Characteristics        24 non-null     object\n",
      " 4   Iteration1_Actor_Comparator  24 non-null     object\n",
      " 5   Iteration1_Characteristics   24 non-null     object\n",
      " 6   Iteration1_Themes            24 non-null     object\n",
      " 7   Iteration1_SubThemes         24 non-null     object\n",
      " 8   Iteration1_Reasonings        24 non-null     object\n",
      " 9   Iteration2_Actor_Comparator  24 non-null     object\n",
      " 10  Iteration2_Characteristics   24 non-null     object\n",
      " 11  Iteration2_Themes            24 non-null     object\n",
      " 12  Iteration2_SubThemes         24 non-null     object\n",
      " 13  Iteration2_Reasonings        24 non-null     object\n",
      " 14  Iteration3_Actor_Comparator  24 non-null     object\n",
      " 15  Iteration3_Characteristics   24 non-null     object\n",
      " 16  Iteration3_Themes            24 non-null     object\n",
      " 17  Iteration3_SubThemes         24 non-null     object\n",
      " 18  Iteration3_Reasonings        24 non-null     object\n",
      "dtypes: object(19)\n",
      "memory usage: 3.7+ KB\n"
     ]
    }
   ],
   "source": [
    "comparison_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b3273d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Question 40', 'Question 41', 'Question 42', 'Question 43'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df['Question'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a55f52bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Question  Agreement\n",
      "0  Question 40   0.827249\n",
      "1  Question 41   0.961905\n",
      "2  Question 42   0.892857\n",
      "3  Question 43   0.888889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from itertools import combinations\n",
    "\n",
    "def safe_eval_list(x):\n",
    "    \"\"\"\n",
    "    Ensures that string values like \"['a','b']\" \n",
    "    are converted into Python lists.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except:\n",
    "            return [x]\n",
    "    return []\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    if not set1 and not set2:\n",
    "        return 1.0  # both empty → perfect agreement\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def compute_agreement(df, question_col=\"Question\"):\n",
    "    iteration_cols = [\n",
    "        \"Iteration1_Characteristics\",\n",
    "        \"Iteration2_Characteristics\",\n",
    "        \"Iteration3_Characteristics\"\n",
    "    ]\n",
    "    \n",
    "    # Ensure lists\n",
    "    for col in iteration_cols:\n",
    "        df[col] = df[col].apply(safe_eval_list)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for q, group in df.groupby(question_col):\n",
    "        pair_scores = []\n",
    "        for _, row in group.iterrows():\n",
    "            for col1, col2 in combinations(iteration_cols, 2):\n",
    "                score = jaccard_similarity(row[col1], row[col2])\n",
    "                pair_scores.append(score)\n",
    "        avg_score = sum(pair_scores) / len(pair_scores) if pair_scores else 0\n",
    "        results.append({\"Question\": q, \"Agreement\": avg_score})\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "agreement_df = compute_agreement(comparison_df)\n",
    "print(agreement_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Question   Iteration  Agreement_with_Human\n",
      "0   Question 40  Iteration1              0.505102\n",
      "1   Question 40  Iteration2              0.433673\n",
      "2   Question 40  Iteration3              0.433673\n",
      "3   Question 41  Iteration1              0.535714\n",
      "4   Question 41  Iteration2              0.492857\n",
      "5   Question 41  Iteration3              0.492857\n",
      "6   Question 42  Iteration1              0.586905\n",
      "7   Question 42  Iteration2              0.586905\n",
      "8   Question 42  Iteration3              0.604762\n",
      "9   Question 43  Iteration1              1.000000\n",
      "10  Question 43  Iteration2              1.000000\n",
      "11  Question 43  Iteration3              0.833333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def safe_eval_list(x):\n",
    "    \"\"\"Converts stringified lists into Python lists safely.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except:\n",
    "            return [x]\n",
    "    return []\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    if not set1 and not set2:\n",
    "        return 1.0  # both empty = perfect agreement\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def compute_human_iteration_agreement(df, question_col=\"Question\"):\n",
    "    human_col = \"Human_Characteristics\"\n",
    "    iteration_cols = [\n",
    "        \"Iteration1_Characteristics\",\n",
    "        \"Iteration2_Characteristics\",\n",
    "        \"Iteration3_Characteristics\"\n",
    "    ]\n",
    "    \n",
    "    # Ensure all are lists\n",
    "    df[human_col] = df[human_col].apply(safe_eval_list)\n",
    "    for col in iteration_cols:\n",
    "        df[col] = df[col].apply(safe_eval_list)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for q, group in df.groupby(question_col):\n",
    "        for iteration_col in iteration_cols:\n",
    "            scores = []\n",
    "            for _, row in group.iterrows():\n",
    "                score = jaccard_similarity(row[human_col], row[iteration_col])\n",
    "                scores.append(score)\n",
    "            avg_score = sum(scores) / len(scores) if scores else 0\n",
    "            results.append({\n",
    "                \"Question\": q,\n",
    "                \"Iteration\": iteration_col.replace(\"_Characteristics\", \"\"),\n",
    "                \"Agreement_with_Human\": avg_score\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "agreement_human_df = compute_human_iteration_agreement(comparison_df)\n",
    "print(agreement_human_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "93a7b795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['R_4C4j4KNUq9N3VGC', 'Question 41', list(['A-more', 'T-more']),\n",
       "        list(['No impact', 'Positive']),\n",
       "        list(['A-More', 'A-More', 'T-More', 'T-More']),\n",
       "        list(['No impact', 'Less effort', 'Personal', 'Positive']),\n",
       "        list(['Feeling', 'Processes', 'Relational', 'Feeling']),\n",
       "        list(['Feeling', 'Effort', 'Relational', 'Feeling']),\n",
       "        list([\"The phrase 'felt more neutral' indicates an emotionally indifferent response to GenAI feedback. The No impact code captures feedback that does not evoke significant positive or negative emotions, which aligns with the student's description of GenAI feedback.\", \"The term 'efficient' suggests that GenAI feedback required less effort or cognitive load to process. The Less effort code captures reduced work or energy demands, which matches the student's description of GenAI feedback.\", \"The phrase 'more personal' directly indicates a relational quality of teacher feedback. The Personal code captures feedback that demonstrates awareness of individual needs or fosters a sense of connection, which aligns with the student's description of teacher feedback.\", \"The term 'encouraging' explicitly signals a positive emotional impact from teacher feedback. The Positive code captures feelings of motivation or support, which the student attributes to teacher feedback.\"]),\n",
       "        list(['A-More', 'A-More', 'T-More', 'T-More']),\n",
       "        list(['No impact', 'Speed', 'Personal', 'Positive']),\n",
       "        list(['Feeling', 'Processes', 'Relational', 'Feeling']),\n",
       "        list(['Feeling', 'Access', 'Relational', 'Feeling']),\n",
       "        list([\"The phrase 'felt more neutral' indicates an emotionally indifferent response to GenAI feedback. The No impact code captures feedback that does not evoke significant positive or negative emotions, which aligns with the student's description of GenAI feedback.\", \"The term 'efficient' suggests that GenAI feedback is delivered in a time-saving manner. The Speed code captures immediacy and efficiency, which matches the student's description of GenAI feedback.\", \"The phrase 'more personal' directly indicates a relational quality in the teacher's feedback. The Personal code captures feedback that demonstrates awareness of individual needs or fosters a sense of connection, which aligns with the student's description of teacher feedback.\", \"The term 'encouraging' explicitly conveys a positive emotional impact from the teacher's feedback. The Positive code captures feelings of motivation or support, which matches the student's description of teacher feedback.\"]),\n",
       "        list(['A-More', 'A-More', 'T-More', 'T-More']),\n",
       "        list(['No impact', 'Speed', 'Personal', 'Positive']),\n",
       "        list(['Feeling', 'Processes', 'Relational', 'Feeling']),\n",
       "        list(['Feeling', 'Access', 'Relational', 'Feeling']),\n",
       "        list([\"The phrase 'felt more neutral' indicates an emotionally indifferent response to GenAI feedback. The No impact code captures feedback that does not evoke significant positive or negative emotions, which aligns with the student's description of GenAI feedback.\", \"The term 'efficient' suggests that GenAI feedback is delivered in a time-saving manner. The Speed code captures immediacy and efficiency, which matches the student's description of GenAI feedback.\", \"The phrase 'more personal' directly indicates a relational quality in teacher feedback. The Personal code captures feedback that demonstrates awareness of individual needs or fosters a sense of connection, which aligns with the student's description of teacher feedback.\", \"The term 'encouraging' explicitly conveys a positive emotional impact from teacher feedback. The Positive code captures feelings of motivation or support, which matches the student's description of teacher feedback.\"])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.sample(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd546a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd268039",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quali_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
