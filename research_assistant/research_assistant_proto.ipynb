{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PDF Processing\n",
    "import PyPDF2\n",
    "import fitz  # PyMuPDF for better text extraction\n",
    "import re\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# OpenAI Integration\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Vector Database (we'll use Chroma for local development)\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 12:13:00,468 - INFO - Directory created/verified: ..\\output\n",
      "2025-06-19 12:13:00,470 - INFO - Directory created/verified: ..\\cache\n",
      "2025-06-19 12:13:00,475 - INFO - Directory created/verified: ..\\vector_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Configuration initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 12:13:02,367 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 12:13:02,383 - INFO - âœ… OpenAI API connection successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup validation passed!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Configuration and Setup\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the research assistant pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # API Configuration\n",
    "        self.openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "        self.openai_model = \"gpt-4o\"  \n",
    "        \n",
    "        # File paths\n",
    "        self.files_dir = Path(\"../files\")\n",
    "        self.output_dir = Path(\"../output\")\n",
    "        self.cache_dir = Path(\"../cache\")\n",
    "        \n",
    "        # Vector Database\n",
    "        self.vector_db_path = Path(\"../vector_db\")\n",
    "        self.embedding_model_name = \"all-MiniLM-L6-v2\"  # Fast and effective\n",
    "        \n",
    "        # Processing settings\n",
    "        self.max_chunk_size = 1000  # characters per chunk\n",
    "        self.chunk_overlap = 200    # characters overlap between chunks\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        self._create_directories()\n",
    "    \n",
    "    def _create_directories(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        for directory in [self.output_dir, self.cache_dir, self.vector_db_path]:\n",
    "            directory.mkdir(exist_ok=True)\n",
    "            logger.info(f\"Directory created/verified: {directory}\")\n",
    "    \n",
    "    def validate_setup(self):\n",
    "        \"\"\"Validate that all required components are properly configured\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        # Check OpenAI API key\n",
    "        if not self.openai_api_key:\n",
    "            issues.append(\"OpenAI API key not found. Please set OPENAI_API_KEY in your .env file.\")\n",
    "        \n",
    "        # Check if files directory exists\n",
    "        if not self.files_dir.exists():\n",
    "            issues.append(f\"Files directory not found: {self.files_dir}\")\n",
    "        \n",
    "        # Check if we can access OpenAI\n",
    "        if self.openai_api_key:\n",
    "            try:\n",
    "                client = OpenAI(api_key=self.openai_api_key)\n",
    "                # Simple test call\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                    max_tokens=5\n",
    "                )\n",
    "                logger.info(\"âœ… OpenAI API connection successful\")\n",
    "            except Exception as e:\n",
    "                issues.append(f\"OpenAI API connection failed: {str(e)}\")\n",
    "        \n",
    "        return issues\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "print(\"ðŸ”§ Configuration initialized\")\n",
    "\n",
    "# Validate setup\n",
    "issues = config.validate_setup()\n",
    "if issues:\n",
    "    print(\"âŒ Setup issues found:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(\"âœ… Setup validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PDF Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ PDF Processor initialized\n"
     ]
    }
   ],
   "source": [
    "# PDF Processing Utilities\n",
    "class PDFProcessor:\n",
    "    \"\"\"Handles PDF text extraction and processing\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path: Path) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract text from PDF with page information and metadata\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing text, pages, and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Use PyMuPDF for better text extraction\n",
    "            doc = fitz.open(pdf_path)\n",
    "            \n",
    "            total_pages = len(doc)\n",
    "            \n",
    "            extracted_data = {\n",
    "                'file_path': str(pdf_path),\n",
    "                'file_name': pdf_path.name,\n",
    "                'total_pages': len(doc),\n",
    "                'pages': [],\n",
    "                'full_text': \"\",\n",
    "                'metadata': doc.metadata,\n",
    "                'extraction_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Extract text from each page\n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc.load_page(page_num)\n",
    "                text = page.get_text()\n",
    "                \n",
    "                page_data = {\n",
    "                    'page_number': page_num + 1,\n",
    "                    'text': text,\n",
    "                    'text_length': len(text)\n",
    "                }\n",
    "                \n",
    "                extracted_data['pages'].append(page_data)\n",
    "                extracted_data['full_text'] += f\"\\n--- Page {page_num + 1} ---\\n{text}\"\n",
    "            \n",
    "            doc.close()\n",
    "            logger.info(f\"Successfully extracted text from {pdf_path.name} ({total_pages} pages)\")\n",
    "            return extracted_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting text from {pdf_path}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def detect_titles_and_sections(self, text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Detect titles and sections in the text using regex patterns\n",
    "        \n",
    "        Args:\n",
    "            text: Full text of the document\n",
    "            \n",
    "        Returns:\n",
    "            List of detected sections with their titles and content\n",
    "        \"\"\"\n",
    "        # Common title patterns\n",
    "        title_patterns = [\n",
    "            r'^(\\d+\\.\\s+[A-Z][^.\\n]+)',  # 1. Title\n",
    "            r'^([A-Z][A-Z\\s]{3,}[A-Z])',  # ALL CAPS TITLES\n",
    "            r'^(\\d+\\.\\d+\\s+[A-Z][^.\\n]+)',  # 1.1. Subtitle\n",
    "            r'^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\s*:)',  # Title:\n",
    "        ]\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        sections = []\n",
    "        current_section = None\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Check if line matches any title pattern\n",
    "            is_title = False\n",
    "            title_level = 0\n",
    "            \n",
    "            for pattern in title_patterns:\n",
    "                match = re.match(pattern, line)\n",
    "                if match:\n",
    "                    is_title = True\n",
    "                    title_level = len(pattern.split('\\\\d+')) - 1  # Rough level estimation\n",
    "                    break\n",
    "            \n",
    "            if is_title:\n",
    "                # Save previous section if exists\n",
    "                if current_section:\n",
    "                    sections.append(current_section)\n",
    "                \n",
    "                # Start new section\n",
    "                current_section = {\n",
    "                    'title': line,\n",
    "                    'title_level': title_level,\n",
    "                    'content': line + '\\n',\n",
    "                    'start_line': line_num,\n",
    "                    'end_line': line_num\n",
    "                }\n",
    "            elif current_section:\n",
    "                # Add line to current section\n",
    "                current_section['content'] += line + '\\n'\n",
    "                current_section['end_line'] = line_num\n",
    "        \n",
    "        # Add the last section\n",
    "        if current_section:\n",
    "            sections.append(current_section)\n",
    "        \n",
    "        # If no sections detected, create one section with all content\n",
    "        if not sections:\n",
    "            sections = [{\n",
    "                'title': 'Document Content',\n",
    "                'title_level': 0,\n",
    "                'content': text,\n",
    "                'start_line': 0,\n",
    "                'end_line': len(lines) - 1\n",
    "            }]\n",
    "        \n",
    "        logger.info(f\"Detected {len(sections)} sections in the document\")\n",
    "        return sections\n",
    "    \n",
    "    def create_chunks(self, text: str, max_size: int = None, overlap: int = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Create overlapping chunks from text for embedding\n",
    "        \n",
    "        Args:\n",
    "            text: Text to chunk\n",
    "            max_size: Maximum chunk size in characters\n",
    "            overlap: Overlap size in characters\n",
    "            \n",
    "        Returns:\n",
    "            List of text chunks\n",
    "        \"\"\"\n",
    "        max_size = max_size or self.config.max_chunk_size\n",
    "        overlap = overlap or self.config.chunk_overlap\n",
    "        \n",
    "        chunks = []\n",
    "        start = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = start + max_size\n",
    "            \n",
    "            # Try to break at sentence boundary\n",
    "            if end < len(text):\n",
    "                # Look for sentence endings\n",
    "                for i in range(end, max(start, end - 100), -1):\n",
    "                    if text[i] in '.!?':\n",
    "                        end = i + 1\n",
    "                        break\n",
    "            \n",
    "            chunk = text[start:end].strip()\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "            \n",
    "            start = end - overlap\n",
    "            if start >= len(text):\n",
    "                break\n",
    "        \n",
    "        logger.info(f\"Created {len(chunks)} chunks from text\")\n",
    "        return chunks\n",
    "\n",
    "# Initialize PDF processor\n",
    "pdf_processor = PDFProcessor(config)\n",
    "print(\"ðŸ“„ PDF Processor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 12:06:34,340 - INFO - Successfully extracted text from extracted_pages_134_149.pdf (16 pages)\n",
      "2025-06-19 12:06:34,348 - INFO - Detected 86 sections in the document\n",
      "2025-06-19 12:06:34,350 - INFO - Created 59 chunks from text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– Processing: ..\\files\\extracted_pages_134_149.pdf\n",
      "âœ… Extracted 16 pages\n",
      "ï¿½ï¿½ Total text length: 44942 characters\n",
      "ðŸ“‹ Detected 86 sections:\n",
      "  1. Keywords: Large Language Models Â· ChatGPT Â· Induct...\n",
      "  2. 1. Assistance...\n",
      "  3. 2. Encouragement...\n",
      "  4. 3. Checking in/concern...\n",
      "  5. 4. Comfort/consolation...\n",
      "ðŸ”— Created 59 chunks for embedding\n"
     ]
    }
   ],
   "source": [
    "# Test the PDF processing with your extracted pages\n",
    "def test_pdf_processing():\n",
    "    \"\"\"Test the PDF processing pipeline with the extracted pages\"\"\"\n",
    "    \n",
    "    # Path to the extracted pages PDF\n",
    "    extracted_pdf_path = config.files_dir / \"extracted_pages_134_149.pdf\"\n",
    "    \n",
    "    if not extracted_pdf_path.exists():\n",
    "        print(f\"âŒ Extracted PDF not found: {extracted_pdf_path}\")\n",
    "        print(\"Please run the extract_pdf_pages.py script first to create the extracted pages.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ðŸ“– Processing: {extracted_pdf_path}\")\n",
    "    \n",
    "    # Extract text\n",
    "    extracted_data = pdf_processor.extract_text_from_pdf(extracted_pdf_path)\n",
    "    \n",
    "    print(f\"âœ… Extracted {extracted_data['total_pages']} pages\")\n",
    "    print(f\"ï¿½ï¿½ Total text length: {len(extracted_data['full_text'])} characters\")\n",
    "    \n",
    "    # Detect sections\n",
    "    sections = pdf_processor.detect_titles_and_sections(extracted_data['full_text'])\n",
    "    \n",
    "    print(f\"ðŸ“‹ Detected {len(sections)} sections:\")\n",
    "    for i, section in enumerate(sections[:5]):  # Show first 5 sections\n",
    "        print(f\"  {i+1}. {section['title'][:50]}...\")\n",
    "    \n",
    "    # Create chunks\n",
    "    chunks = pdf_processor.create_chunks(extracted_data['full_text'])\n",
    "    \n",
    "    print(f\"ðŸ”— Created {len(chunks)} chunks for embedding\")\n",
    "    \n",
    "    return {\n",
    "        'extracted_data': extracted_data,\n",
    "        'sections': sections,\n",
    "        'chunks': chunks\n",
    "    }\n",
    "\n",
    "# Run the test\n",
    "test_results = test_pdf_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 12:08:48,101 - INFO - Use pytorch device_name: cpu\n",
      "2025-06-19 12:08:48,101 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-06-19 12:08:53,513 - INFO - âœ… Vector database initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—„ï¸ Vector Database initialized\n"
     ]
    }
   ],
   "source": [
    "# Vector Database Setup\n",
    "class VectorDatabase:\n",
    "    \"\"\"Handles vector database operations for document embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self.embedding_model = None\n",
    "        self._initialize()\n",
    "    \n",
    "    def _initialize(self):\n",
    "        \"\"\"Initialize the vector database and embedding model\"\"\"\n",
    "        try:\n",
    "            # Initialize ChromaDB\n",
    "            self.client = chromadb.PersistentClient(\n",
    "                path=str(self.config.vector_db_path),\n",
    "                settings=Settings(anonymized_telemetry=False)\n",
    "            )\n",
    "            \n",
    "            # Initialize embedding model\n",
    "            self.embedding_model = SentenceTransformer(self.config.embedding_model_name)\n",
    "            \n",
    "            # Create or get collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=\"research_documents\",\n",
    "                metadata={\"description\": \"Research document embeddings\"}\n",
    "            )\n",
    "            \n",
    "            logger.info(\"âœ… Vector database initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing vector database: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def add_documents(self, documents: List[Dict[str, Any]], collection_name: str = None) -> bool:\n",
    "        \"\"\"\n",
    "        Add documents to the vector database\n",
    "        \n",
    "        Args:\n",
    "            documents: List of document dictionaries with 'text' and 'metadata' keys\n",
    "            collection_name: Optional collection name\n",
    "            \n",
    "        Returns:\n",
    "            Success status\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not documents:\n",
    "                logger.warning(\"No documents to add\")\n",
    "                return False\n",
    "            \n",
    "            # Prepare documents for embedding\n",
    "            texts = [doc['text'] for doc in documents]\n",
    "            metadatas = [doc.get('metadata', {}) for doc in documents]\n",
    "            ids = [doc.get('id', f\"doc_{i}\") for i, doc in enumerate(documents)]\n",
    "            \n",
    "            # Generate embeddings\n",
    "            embeddings = self.embedding_model.encode(texts).tolist()\n",
    "            \n",
    "            # Add to collection\n",
    "            collection = self.collection if collection_name is None else self.client.get_or_create_collection(collection_name)\n",
    "            collection.add(\n",
    "                embeddings=embeddings,\n",
    "                documents=texts,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"âœ… Added {len(documents)} documents to vector database\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error adding documents to vector database: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def search_similar(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Search for similar documents\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            n_results: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of similar documents with scores\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate query embedding\n",
    "            query_embedding = self.embedding_model.encode([query]).tolist()\n",
    "            \n",
    "            # Search in collection\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=query_embedding,\n",
    "                n_results=n_results\n",
    "            )\n",
    "            \n",
    "            # Format results\n",
    "            formatted_results = []\n",
    "            for i in range(len(results['documents'][0])):\n",
    "                formatted_results.append({\n",
    "                    'document': results['documents'][0][i],\n",
    "                    'metadata': results['metadatas'][0][i],\n",
    "                    'distance': results['distances'][0][i],\n",
    "                    'id': results['ids'][0][i]\n",
    "                })\n",
    "            \n",
    "            return formatted_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching vector database: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "# Initialize vector database\n",
    "vector_db = VectorDatabase(config)\n",
    "print(\"ðŸ—„ï¸ Vector Database initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OpenAI Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– OpenAI Client initialized\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Integration Setup\n",
    "class OpenAIClient:\n",
    "    \"\"\"Handles OpenAI API interactions for document processing\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.client = OpenAI(api_key=config.openai_api_key)\n",
    "    \n",
    "    def extract_information(self, text: str, schema: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract structured information from text using OpenAI\n",
    "        \n",
    "        Args:\n",
    "            text: Text to analyze\n",
    "            schema: Schema defining what to extract\n",
    "            \n",
    "        Returns:\n",
    "            Extracted information in structured format\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create prompt for information extraction\n",
    "            schema_description = json.dumps(schema, indent=2)\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            Please analyze the following text and extract information according to this schema:\n",
    "            \n",
    "            {schema_description}\n",
    "            \n",
    "            Text to analyze:\n",
    "            {text[:4000]}  # Limit text length for API efficiency\n",
    "            \n",
    "            Please return the extracted information in valid JSON format matching the schema.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.openai_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a research assistant that extracts structured information from academic documents. Always respond with valid JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.1,  # Low temperature for consistent extraction\n",
    "                max_tokens=10000\n",
    "            )\n",
    "            \n",
    "            # Parse response\n",
    "            extracted_data = json.loads(response.choices[0].message.content)\n",
    "            logger.info(\"âœ… Information extraction completed\")\n",
    "            return extracted_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting information: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def answer_question(self, question: str, context: str) -> str:\n",
    "        \"\"\"\n",
    "        Answer a question based on provided context\n",
    "        \n",
    "        Args:\n",
    "            question: User question\n",
    "            context: Relevant context from documents\n",
    "            \n",
    "        Returns:\n",
    "            Answer to the question\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            Based on the following context, please answer the question. If the context doesn't contain enough information to answer the question, say so.\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Answer:\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.openai_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Answer questions based on the provided context.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=500\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error answering question: {str(e)}\")\n",
    "            return \"Sorry, I encountered an error while processing your question.\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAIClient(config)\n",
    "print(\"ðŸ¤– OpenAI Client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Pipeline Class\n",
    "class ResearchAssistantPipeline:\n",
    "    \"\"\"Main pipeline that orchestrates document processing and AI interactions\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.pdf_processor = PDFProcessor(config)\n",
    "        self.vector_db = VectorDatabase(config)\n",
    "        self.openai_client = OpenAIClient(config)\n",
    "    \n",
    "    def process_document(self, pdf_path: Path) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a document through the complete pipeline\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to the PDF document\n",
    "            \n",
    "        Returns:\n",
    "            Processing results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"ðŸš€ Starting pipeline for: {pdf_path.name}\")\n",
    "            \n",
    "            # Step 1: Extract text from PDF\n",
    "            extracted_data = self.pdf_processor.extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            # Step 2: Detect sections\n",
    "            sections = self.pdf_processor.detect_titles_and_sections(extracted_data['full_text'])\n",
    "            \n",
    "            # Step 3: Create chunks for embedding\n",
    "            chunks = self.pdf_processor.create_chunks(extracted_data['full_text'])\n",
    "            \n",
    "            # Step 4: Prepare documents for vector database\n",
    "            documents_for_embedding = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                doc_id = f\"{pdf_path.stem}_chunk_{i}\"\n",
    "                documents_for_embedding.append({\n",
    "                    'id': doc_id,\n",
    "                    'text': chunk,\n",
    "                    'metadata': {\n",
    "                        'source_file': pdf_path.name,\n",
    "                        'chunk_index': i,\n",
    "                        'total_chunks': len(chunks),\n",
    "                        'processing_timestamp': datetime.now().isoformat()\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # Step 5: Add to vector database\n",
    "            self.vector_db.add_documents(documents_for_embedding)\n",
    "            \n",
    "            # Step 6: Extract structured information (placeholder for now)\n",
    "            # We'll implement this when we define the schema\n",
    "            \n",
    "            results = {\n",
    "                'file_name': pdf_path.name,\n",
    "                'total_pages': extracted_data['total_pages'],\n",
    "                'sections_detected': len(sections),\n",
    "                'chunks_created': len(chunks),\n",
    "                'embeddings_stored': len(documents_for_embedding),\n",
    "                'processing_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"âœ… Pipeline completed for {pdf_path.name}\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in pipeline: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def ask_question(self, question: str, n_context_chunks: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Ask a question about the processed documents\n",
    "        \n",
    "        Args:\n",
    "            question: User question\n",
    "            n_context_chunks: Number of context chunks to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            Answer to the question\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Search for relevant context\n",
    "            similar_docs = self.vector_db.search_similar(question, n_context_chunks)\n",
    "            \n",
    "            if not similar_docs:\n",
    "                return \"I couldn't find any relevant information in the processed documents.\"\n",
    "            \n",
    "            # Combine context\n",
    "            context = \"\\n\\n\".join([doc['document'] for doc in similar_docs])\n",
    "            \n",
    "            # Get answer from OpenAI\n",
    "            answer = self.openai_client.answer_question(question, context)\n",
    "            \n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error answering question: {str(e)}\")\n",
    "            return \"Sorry, I encountered an error while processing your question.\"\n",
    "\n",
    "# Initialize the main pipeline\n",
    "pipeline = ResearchAssistantPipeline(config)\n",
    "print(\"ðŸŽ¯ Research Assistant Pipeline initialized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quali_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
