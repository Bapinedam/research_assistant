{
  "bibliographic_metadata": {
    "paper_id": "16094069241231168",
    "title": "An Examination of the Use of Large Language Models to Aid Analysis of Textual Data",
    "authors": [
      "Robert H. Tai",
      "Lillian R. Bentley",
      "Xin Xia",
      "Jason M. Sitt",
      "Sarah C. Fankhauser",
      "Ana M. Chicas-Mosier",
      "Barnas G. Monteith"
    ],
    "publication_year": 2024,
    "venue": "International Journal of Qualitative Methods",
    "doi_url": "https://doi.org/10.1177/16094069241231168",
    "research_domain": "qualitative research methodology, computational text analysis, large language models"
  },
  "methodological_framework": {
    "analysis_type": "deductive qualitative coding using large language models (LLMs) as analytic instruments, with comparison to traditional human coding",
    "theoretical_framework": "codebook-driven deductive analysis based on pre-defined conceptual codes derived from prior inductive work; codes are linked to theoretical constructs relevant to researcher identity and scientific career development",
    "sample_characteristics": {
      "interview_count": 125,
      "participant_demographics": "chemistry, physics, and chemical engineering graduate students, postdocs, scientists, research engineers, and individuals who had left scientific research; drawn from Project Crossover: A Study of the Transition from Student to Scientist",
      "data_collection_method": "semi-structured interviews; interviews were recorded and transcribed"
    }
  },
  "technical_pipeline": {
    "automation_level": "semi-automated (human-in-the-loop, LLM-assisted deductive coding)",
    "software_tools": [
      "ChatGPT 3.5 (OpenAI)",
      "Dedoose (qualitative analysis software)"
    ],
    "computational_methods": [
      "Large Language Model (LLM)-assisted deductive coding",
      "Iterative prompt-based code detection",
      "Pseudo-random number generator (PRNG) for response variation",
      "Calculation of Large Language Model Quotient (LLMq) as an outcome metric"
    ],
    "workflow_architecture": {
      "preprocessing_steps": [
        "Selection and transcription of interview excerpts",
        "Development of a codebook with clear definitions and examples",
        "Design of contextually relevant, structured prompts for LLM input"
      ],
      "analysis_pipeline": [
        "Input of codebook and interview text into LLM (ChatGPT 3.5)",
        "Prompting LLM to identify presence/absence of predefined codes (binary query)",
        "Requesting supporting evidence (quotes) for each code detected",
        "Iterative submission of the same prompt and text (logging out/in between iterations to reset LLM state)",
        "Recording LLM responses for each iteration (160 per text sample)",
        "Binary coding of LLM outputs (1 = code present, 0 = code absent)",
        "Calculation of LLMq (proportion of positive responses per code per text across iterations)"
      ],
      "postprocessing_steps": [
        "Comparison of LLM coding results to traditional human coding",
        "Resolution of discrepancies through group discussion among human coders",
        "Interpretation of LLMq stability and convergence across iterations",
        "Use of LLMq as a validation and reliability metric for code identification"
      ]
    },
    "coding_framework": "Deductive coding using a codebook with five predefined conceptual codes (Autonomy, Persistence, Perception of Own Identity or Self, Novelty, STEM Interests); binary code presence/absence per excerpt; codebook-driven prompt design for LLM input"
  },
  "prompt_engineering": {
    "prompting_strategy": {
      "approach_type": "codebook-driven deductive binary prompting",
      "prompt_examples": [
        "Can you find the five characteristics in the transcript below, yes or no? If yes, give us the quote.\n[Text 1]",
        "We defined the characteristics below:\n1. Autonomy: is the ability to be self-driven in STEM research\n2. Persistence: is the continuance in a course of action in spite of difficulty\n3. 'Perception of own identity or self': is the internal recognition as an individual who can talk about research with an expert in the discipline or confidence\n4. Novelty: is the desire to create new knowledge or knowledge new to them\n5. STEM interests: is having an interest in a STEM field."
      ],
      "engineering_techniques": [
        "Use of a structured codebook with explicit definitions for each code",
        "Contextually relevant prompts to reduce LLM hallucinations",
        "Binary (yes/no) queries for each code per text excerpt",
        "Request for supporting evidence (quotes) for each code identified",
        "Consistent prompt structure across all iterations and texts",
        "Iterative prompting with session resets (log out/in) to induce response variability and simulate multiple coders",
        "Conservative coding: ambiguous or vague LLM responses coded as 'no'",
        "Limiting input text length to LLM token constraints (2048–4096 tokens for ChatGPT 3.5)"
      ],
      "model_specifications": "ChatGPT 3.5 (OpenAI), autoregressive LLM with >175B parameters, default randomness (temperature=1), accessed via web interface; methodology generalizable to other LLMs (e.g., BingChat, Bard AI, Claude 2, LLaMa 2, ErnieBOT); input limited to 2048–4096 tokens per prompt"
    }
  },
  "empirical_results": {
    "primary_findings": [
      "Large Language Models (LLMs), specifically ChatGPT 3.5, can be systematically used to support deductive qualitative coding of interview data.",
      "LLM-based coding, when provided with a clear codebook and contextually relevant prompts, produces results that are consistent with traditional human coding, especially when multiple iterations are performed.",
      "The study introduces the Large Language Model quotient (LLMq), a metric representing the proportion of positive code identifications across multiple LLM iterations, which stabilizes after approximately 40 iterations.",
      "LLM-based analysis can serve as a supplementary tool for validation, efficiency, and bias reduction in qualitative research, offering nearly unlimited inter-rater measures.",
      "Areas of misalignment between LLM and human coding can prompt valuable reflection and refinement of code definitions among researchers.",
      "LLMs are not intended to replace human coders but can augment traditional qualitative analysis by providing systematic, repeatable, and scalable coding support."
    ],
    "evaluation_framework": {
      "metrics_employed": [
        "Large Language Model quotient (LLMq): proportion of positive code identifications per total iterations",
        "Comparison of LLMq values to traditional human coder agreement",
        "Stability of LLMq values across increasing numbers of iterations",
        "Qualitative comparison of code presence/absence between LLM and human coders"
      ],
      "validation_methodology": "Three interview excerpts were coded for five deductive codes using both LLM (ChatGPT 3.5) and three independent human coders. For the LLM, each prompt (codebook + text) was entered 160 times (each time after logging out and back in to maximize stochasticity), and the presence/absence of each code was recorded per iteration. LLMq was calculated at multiple iteration thresholds (5, 10, 20, 40, 80, 160). Human coders worked independently and then resolved discrepancies through discussion. LLMq results were compared to human coding outcomes for alignment and divergence.",
      "performance_indicators": "LLMq values plateaued and stabilized after approximately 40 iterations, indicating consistent LLM coding. For texts where codes were clearly present, LLMq values exceeded 0.8–1.0, matching human coder consensus. For ambiguous texts, both LLM and human coders showed lower agreement. LLMq provided a nuanced, probabilistic measure of code presence, and a suggested cutoff of 0.95 (95% positive detection) was proposed for strong confirmation."
    },
    "methodological_limitations": [
      "LLMs rely on patterns in their training data; absence of specific linguistic nuances or subtleties may limit model understanding.",
      "Quality and structure of input data affect LLM output; noisy, unstructured, or biased data can lead to inaccuracies or hallucinations.",
      "LLMs have input length limitations (e.g., ChatGPT 3.5 default limit of 2048 tokens, extendable to 4096 with subscription), which may restrict analysis of longer texts or require segmentation.",
      "LLMs may generate hallucinations—nonsensical or illogical outputs—especially with adversarial or ambiguous prompts.",
      "LLM outputs are stochastic; single outputs are not reliable, necessitating multiple iterations for stable results.",
      "LLMs are not autonomous and require carefully designed, contextually relevant prompts to generate valuable data.",
      "Current LLMs are not domain-specific; future improvements in domain-specific training may enhance reliability and validity.",
      "LLM-based coding should not replace human judgment; interpretation and prompt design remain essential researcher responsibilities."
    ]
  },
  "quality_assurance": {
    "reliability_measures": [
      "Inter-rater reliability using Cohen’s kappa statistic",
      "Inter-rater reliability using Fleiss’ kappa statistic",
      "Calculation of Large Language Model Quotient (LLMq) across multiple iterations",
      "Comparison of LLM coding outputs to traditional human coding",
      "Stability of LLMq values across increasing iterations"
    ],
    "validity_approaches": [
      "Use of a detailed codebook with clear definitions and example quotes for deductive coding",
      "Contextually relevant and structured prompts to minimize LLM hallucinations",
      "Binary coding scheme (yes/no) with conservative interpretation for ambiguous responses",
      "Post-hoc comparison of LLM outputs with traditional coder results for confirmatory analysis",
      "Iterative refinement of code definitions based on discrepancies between LLM and human coding",
      "Thresholding LLMq values (e.g., 0.950 as a cutoff for strong confirmation, analogous to p-value < 0.05)"
    ],
    "bias_mitigation_strategies": [
      "Multiple coders independently coding and resolving disagreements through discussion",
      "Use of LLM as an additional rater to identify and avoid potential implicit bias from researchers",
      "Iterative application of codebooks and prompts to reduce subjectivity and increase alignment",
      "Human review of LLM outputs to assess and correct for hallucinations or misclassifications",
      "Conservative coding of ambiguous LLM responses as negative to avoid over-attribution",
      "Screening and careful selection of input data to avoid noisy or biased transcripts"
    ]
  },
  "research_impact": {
    "novel_contributions": [
      "Proposes a systematic methodology for using Large Language Models (LLMs) to support traditional deductive coding in qualitative research.",
      "Introduces the Large Language Model quotient (LLMq) as a quantitative measure representing the proportion of positive code identifications across multiple LLM iterations.",
      "Demonstrates a recursive, multi-iteration LLM analysis pipeline to assess the stability and reliability of deductive coding outputs.",
      "Provides empirical comparison between LLM-based coding and traditional human coding, highlighting areas of alignment and divergence.",
      "Establishes LLMs as a potential supplementary tool for validation and reliability assessment in qualitative data analysis."
    ],
    "practical_applications": [
      "LLMs can be used as an efficient screening tool to identify the presence of deductive codes in large volumes of interview data, reducing manual labor.",
      "LLMq enables researchers to quantify the consistency of code identification, supporting post-hoc validation of traditional coding results.",
      "LLMs can serve as an independent 'rater' to check for implicit bias and prompt codebook refinement through external review.",
      "Iterative LLM analysis can highlight ambiguous or contested coding areas, facilitating deeper team discussions and code definition adjustments.",
      "LLMs can be integrated into existing qualitative data analysis workflows (e.g., with software like Dedoose) to augment human analysis."
    ],
    "future_research_directions": [
      "Exploration of LLMs for inductive qualitative analysis, including theme and code generation from raw textual data.",
      "Development of domain-specific LLMs trained on refined, context-rich datasets to improve code identification accuracy and reduce iteration requirements.",
      "Investigation of optimal LLMq cutoff thresholds for code confirmation and their statistical justification.",
      "Assessment of LLM performance across diverse qualitative research domains and languages.",
      "Evaluation of LLM integration with other computational text analysis tools and mixed-methods research designs."
    ],
    "scalability_considerations": "LLMs offer high scalability for qualitative analysis by enabling rapid, repeated coding across large datasets with minimal human intervention. The iterative approach leverages LLM stochasticity to approximate population-level coding trends, and the LLMq metric stabilizes with sufficient iterations (typically beyond 40). However, scalability is constrained by input length limits (e.g., 2048–4096 tokens in ChatGPT 3.5), potential data quality issues, and the need for careful prompt engineering to mitigate hallucinations. As LLMs and training datasets expand, scalability and reliability are expected to improve, facilitating efficient large-scale qualitative analysis."
  }
}