bibliographic_metadata.paper_id,bibliographic_metadata.title,bibliographic_metadata.authors,bibliographic_metadata.publication_year,bibliographic_metadata.venue,bibliographic_metadata.doi_url,bibliographic_metadata.research_domain,methodological_framework.analysis_type,methodological_framework.theoretical_framework,methodological_framework.sample_characteristics.interview_count,methodological_framework.sample_characteristics.participant_demographics,methodological_framework.sample_characteristics.data_collection_method,technical_pipeline.automation_level,technical_pipeline.software_tools,technical_pipeline.computational_methods,technical_pipeline.workflow_architecture.preprocessing_steps,technical_pipeline.workflow_architecture.analysis_pipeline,technical_pipeline.workflow_architecture.postprocessing_steps,technical_pipeline.coding_framework,prompt_engineering.prompting_strategy.approach_type,prompt_engineering.prompting_strategy.prompt_examples,prompt_engineering.prompting_strategy.engineering_techniques,prompt_engineering.prompting_strategy.model_specifications,empirical_results.primary_findings,empirical_results.evaluation_framework.metrics_employed,empirical_results.evaluation_framework.validation_methodology,empirical_results.evaluation_framework.performance_indicators,empirical_results.methodological_limitations,quality_assurance.reliability_measures,quality_assurance.validity_approaches,quality_assurance.bias_mitigation_strategies,research_impact.novel_contributions,research_impact.practical_applications,research_impact.future_research_directions,research_impact.scalability_considerations,source_file
arXiv:2401.04122v3,From Prompt Engineering to Prompt Science With Human in the Loop,['Chirag Shah'],2023,Proceedings of ACM Conference (Conference’17),https://doi.org/10.1145/nnnnnnn.nnnnnnn,"Computational qualitative analysis, Human-centered computing, Large Language Models, Automated qualitative coding","deductive qualitative analysis with human-in-the-loop validation, inspired by qualitative codebook construction and coding","systematic, multi-phase prompt science methodology based on qualitative coding/codebook development; emphasizes transparency, objectivity, replicability, and removal of individual subjectivity; incorporates inter-coder reliability and iterative human validation",not_specified,"multiple researchers/assessors with sufficient familiarity with the task; no special qualifications required beyond task understanding and ability to discuss disagreements; in experiments, two researchers for coding/assessment, sometimes supervised by a senior researcher or expert",LLM-generated responses to prompts; human assessors independently label and evaluate LLM outputs using codebooks/criteria; iterative process with phases for prompt and criteria/codebook development and validation,"semi-automated (human-in-the-loop with LLMs for labeling, coding, and prompt generation; automation increases with validated prompts and codebooks, but human verification and iteration are integral throughout the process)","['GPT-4', 'Mistral', 'Hermes']","['Large Language Model (LLM)-based text labeling', 'Zero-shot and prompt-based taxonomy generation', 'Iterative prompt engineering with human validation', 'Inter-coder reliability measurement (e.g., Cohen’s kappa, Krippendorff’s alpha)', 'Human-in-the-loop qualitative coding', 'Multi-phase verification and validation']","['Selection or creation of initial prompt for LLM', 'Selection of input data (e.g., interview transcripts, user logs, question datasets)', 'Initial codebook or criteria definition (inspired by prior literature or domain knowledge)']","['Run LLM with initial prompt on sample data to generate responses (labels, taxonomies, probes, etc.)', 'Independent human assessment of LLM outputs using the codebook/criteria', 'Computation of inter-coder reliability (ICR) between assessors', 'Discussion and resolution of disagreements among assessors', 'Revision of codebook/criteria and/or prompt based on assessment outcomes', 'Iterative re-running of LLM with revised prompt and repeated human assessment until sufficient agreement is reached', 'Finalization of codebook/criteria and prompt when agreement threshold is met']","['Application of validated prompt and codebook to new/unseen data', 'Independent labeling by additional human assessors for validation', 'Computation of ICR between LLM and human labels, and among human assessors', 'Optional: Further prompt/codebook refinement based on validation results', 'Documentation of all deliberations, decisions, and pipeline steps for transparency and replicability']","Deductive qualitative coding with codebook construction and validation; codebook criteria include comprehensiveness, consistency, clarity, accuracy, conciseness (for taxonomy generation), and relevance and diversity (for probe generation); iterative human-in-the-loop process for codebook and prompt refinement; inter-coder reliability as evaluation metric","multi-phase, human-in-the-loop, codebook-inspired deductive prompt construction and validation","['Initial prompt for taxonomy generation: A simple and direct instruction to generate a user intent taxonomy from log data (zero-shot approach).', ""Prompt for LLM auditing: 'Generate five different questions for the following question that represent the same meaning, but are different.'""]","['Iterative prompt revision based on human assessor feedback', 'Establishment and validation of evaluation criteria (codebook) prior to prompt tuning', 'Independent and collaborative human assessment for inter-coder reliability (ICR)', 'Multi-phase pipeline: (1) Initial pipeline setup, (2) Criteria/codebook development and validation, (3) Iterative prompt development, (4) Pipeline validation with new assessors', 'Documentation of deliberations and decisions for transparency and replicability', 'Threshold-based acceptance (e.g., 75% agreement on criteria satisfaction)', 'Use of inter-coder reliability metrics (e.g., Cohen’s kappa, Krippendorff’s alpha)', 'Prompt generalization and readability improvements after validation']","LLMs used include GPT-4, Mistral, and Hermes; prompts are designed to be model-agnostic and validated across multiple LLMs for robustness and generalizability","['A multi-phase, human-in-the-loop methodology inspired by qualitative codebook construction increases the reliability, transparency, and generalizability of LLM-based qualitative analysis pipelines.', 'The proposed approach systematically removes individual subjectivity and biases from prompt engineering by involving multiple researchers in iterative assessment and documentation.', 'Empirical demonstrations in user intent taxonomy generation and LLM auditing show that the method yields robust, replicable, and trustworthy results, with high inter-coder reliability between human annotators and LLM outputs.', 'The methodology is generalizable across different LLMs (e.g., GPT-4, Mistral, Hermes) and maintains strong agreement between human and machine labeling.', 'The process incurs higher costs (estimated at least 3-fold increase) due to guided deliberations and documentation, but results in higher quality, consistency, and reliability of outputs.']","['Inter-coder reliability (ICR)', 'Cohen’s kappa', 'Krippendorff’s alpha', 'Percentage agreement', 'Task-specific criteria (e.g., comprehensiveness, consistency, clarity, accuracy, conciseness, relevance, diversity)']",Multi-phase human-in-the-loop process: (1) Initial pipeline setup; (2) Independent human assessment and iterative refinement of evaluation criteria (codebook); (3) Iterative prompt development with human assessment and agreement measurement; (4) Optional pipeline validation with new assessors and random sampling to confirm replicability and quality.,"High inter-coder reliability between human annotators and between humans and LLMs; achievement of predefined thresholds for agreement (e.g., 75% or higher); consistent generation of desired outcomes across different LLMs and datasets.","['Increased cost and resource requirements due to involvement of multiple researchers, guided deliberations, and detailed documentation.', 'Potential scalability challenges for large-scale or fully automated pipelines due to the need for human-in-the-loop verification.', 'Optional final validation phase adds continual cost to maintain pipeline quality and validity.', 'The process may require adaptation for different domains or tasks, as criteria and thresholds for agreement can vary by application.', 'not_specified']","['Involvement of at least two qualified researchers in the entire process', 'Independent application of criteria by multiple assessors', 'Measurement of inter-coder reliability (ICR) using methods such as Cohen’s kappa or Krippendorff’s alpha', 'Iterative rounds of assessment and discussion to reach sufficient agreement among assessors', 'Validation phase using a different set of assessors to independently label random samples and compute ICR']","['Establishment and iterative refinement of clear, objective, and community-validated criteria for assessment', 'Use of codebook development inspired by qualitative coding methods', 'Multi-phase verification process including both response and prompt validation', 'Operationalization of criteria through human-in-the-loop assessment and documentation', 'Final validation phase to ensure the pipeline yields quality results that can be independently and objectively validated']","['Involvement of multiple researchers to dissolve individual subjectivity and biases', 'Structured discussions of disagreements among assessors to root out individual biases', 'Documentation of deliberations and decisions to foster transparency and replicability', 'Revision of codebook and prompt based on collaborative assessment and feedback', 'Explicit focus on removing ad-hocness, subjectivity, and opaqueness through systematic checkpoints and validations']","['Proposes a multi-phase, human-in-the-loop methodology for transforming ad-hoc prompt engineering into a systematic, verifiable, and replicable process (prompt science) for qualitative analysis of text data using LLMs.', 'Introduces a workflow inspired by qualitative codebook construction, involving iterative development and validation of both evaluation criteria and prompts with multiple assessors.', 'Operationalizes inter-coder reliability (ICR) metrics (e.g., Cohen’s kappa, Krippendorff’s alpha) for both codebook and prompt validation phases in computational pipelines.', 'Demonstrates the methodology in two empirical applications: (1) generating and applying user intent taxonomies, and (2) auditing LLMs via multiprobe question generation.', 'Establishes a framework for documentation and transparency, enabling other researchers to replicate, validate, and extend the analysis pipelines.']","['Automated and semi-automated labeling of interview or behavioral data using LLMs with validated codebooks and prompts.', 'Construction and application of robust user intent taxonomies in information retrieval and recommender systems.', 'Auditing LLMs for consistency and robustness by generating and evaluating diverse probes/questions.', 'Development of quality assurance protocols for LLM-based qualitative data analysis pipelines in scientific research.', 'Facilitating open, documented, and replicable computational workflows for qualitative coding and prompt generation.']","['Exploring the automation of human-in-the-loop phases to further scale the methodology while maintaining rigor.', 'Adapting the multi-phase methodology to other qualitative research domains beyond text labeling, such as image or multimodal data analysis.', 'Investigating the integration of community-validated metrics and open-source documentation standards for broader adoption.', 'Evaluating the cost-benefit tradeoffs of increased human involvement versus automation in large-scale qualitative analysis pipelines.', 'Extending the framework to support continual validation and quality assurance in dynamic or evolving datasets.']","The methodology increases process cost by at least threefold compared to typical prompt engineering due to guided deliberations, multiple assessors, and detailed documentation. However, it allows for adjustable human involvement (from copilot to autopilot modes) depending on risk and quality requirements, supporting partial automation while maintaining scientific rigor. Scalability is further supported by the modular, phase-based structure, enabling selective human oversight and continual quality checks.",2401.04122v3
arXiv:2402.01386v1,Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis,"['Zeeshan Rasheed', 'Muhammad Waseem', 'Aakash Ahmad', 'Kai-Kristian Kemell', 'Wang Xiaofeng', 'Anh Nguyen Duc', 'Pekka Abrahamsson']",2018,Proceedings of ACM Conference (Conference’17),https://doi.org/XXXXXXX.XXXXXXX,"Software Engineering, Qualitative Data Analysis, Artificial Intelligence, Natural Language Processing",deductive_qualitative_analysis,"multi-agent LLM-based automation of qualitative data analysis (encompassing thematic analysis, grounded theory, content analysis, narrative analysis, and discourse analysis); no single named theory, but grounded in computational automation of established qualitative methods",10,"Practitioners from diverse professional backgrounds, including academia and industries; roles include researcher, ML/DL developer, big data analyst, UX designer, software engineer, software developer, ML developer, AI developer, content strategist, and senior software engineer; experience ranges from 3 to 15 years","Practitioner-based evaluation using structured feedback after integrating the LLM-based model into standard qualitative data analysis workflows; feedback collected via a systematic mechanism focusing on efficiency, user-friendliness, accuracy, and adaptability",fully_automated (autonomous execution of qualitative data analysis tasks by LLM-based multi-agent system with minimal manual intervention),"['OpenAI GPT', 'AutoGPT', 'API environment (custom multi-agent orchestration)', 'CSV/Doc/PDF output modules']","['Large Language Models (LLMs)', 'Multi-agent system (specialized LLM agents for sub-tasks)', 'Natural Language Processing (NLP)', 'Automated text summarization', 'Automated code generation (qualitative coding)', 'Pattern/theme extraction', 'Classification']","['Input data acquisition (links, prompts, file uploads: text, doc, pdf, audio)', 'Text summarization (by Analyzer agent)', 'Removal of unnecessary data']","['Task assignment to specialized LLM agents (e.g., Analyzer, Coder, Categorizer, Pattern Extractor, Context Interpreter)', 'Initial code generation (by Coder agent)', 'Categorization and sub-categorization of codes', 'Pattern and theme extraction', 'Contextual and discourse analysis (by dedicated agents)', 'Core coding/theory generation (for grounded theory)']","['Aggregation of agent outputs', 'Formatting results (CSV, output area, doc, PDF)', 'User feedback collection', 'Iterative refinement based on practitioner feedback']","Deductive coding using codebooks and user-specified qualitative analysis approaches (thematic analysis, content analysis, narrative analysis, discourse analysis, grounded theory); multi-method support with agent specialization for each analysis type","multi-agent, task-specialized prompting with user-specified qualitative analysis method","['Input GitHub links and select thematic analysis to prompt the system to identify issues from the text and perform thematic analysis.', 'Incorporate text extracted from Stack Overflow into the prompt and opt for thematic analysis to guide the system in identifying the cause from the provided text.', 'Upload text, document (doc), or PDF files as input and select the desired qualitative analysis approach (e.g., narrative analysis, content analysis, discourse analysis, grounded theory).']","['Task decomposition: Assigning specialized LLM agents to distinct qualitative analysis tasks (e.g., summarization, initial coding, categorization, pattern/theme extraction, core coding).', 'Sequential agent collaboration: Output from one agent (e.g., summarized text) is passed as input to the next agent (e.g., coder, categorizer).', 'User-driven method selection: Users specify the qualitative analysis approach, which dynamically configures the agent workflow.', 'Flexible input/output handling: Accepts links, raw datasets, textual prompts, file uploads (text, doc, pdf), and outputs in CSV, document, or output area formats.', 'API-based agent communication: Agents interact and exchange information via a text-only API environment.', 'Customization: Users can define and articulate specific analysis objectives in the prompt.']","LLM-based multi-agent system; each agent is a specialized instance of a Large Language Model (e.g., OpenAI GPT); agents are assigned to specific qualitative analysis tasks (summarization, coding, categorization, pattern/theme extraction, core coding); agents interact in a text-only API environment; supports multiple qualitative analysis methods (thematic analysis, content analysis, narrative analysis, discourse analysis, grounded theory); input/output flexibility (links, prompts, file uploads, CSV/doc/pdf outputs); model validated with practitioner feedback; no explicit mention of fine-tuning or specific LLM version.","['The LLM-based multi-agent model can autonomously perform various qualitative data analysis approaches, including thematic analysis, grounded theory, content analysis, narrative analysis, and discourse analysis.', 'The model significantly accelerates the qualitative data analysis process, enabling researchers to manage larger and more complex datasets more efficiently than traditional manual methods.', 'The model is adaptable to diverse data types and input formats (e.g., links, prompts, uploaded files, voice recordings), and outputs results in multiple formats (CSV, output area, documents, PDF).', '87% of practitioners involved in the evaluation expressed satisfaction with the model’s performance.', 'The model’s automation reduces the need for extensive manual intervention, streamlining the analysis workflow and enhancing scalability and accuracy in qualitative research.', 'The model is accessible to users with varying technical skills due to its user-friendly interface.']","['Practitioner satisfaction (Likert scale: Not Satisfied, Fair, Satisfactory, Good, Very Good, Excellent)', 'Qualitative feedback on efficiency, user-friendliness, accuracy, adaptability, and integration']","Practitioner-based evaluation involving 10 professionals from diverse backgrounds (academia and industry), who integrated the model into their standard qualitative data analysis workflows and provided structured feedback via a systematic mechanism.","87% practitioner satisfaction rate; positive qualitative feedback on analytical capabilities, multi-method support, and adaptability; suggestions for improvements in user interface, speed, language support, and integration.","['Limited sample size for practitioner evaluation (10 participants).', 'One practitioner (ML developer) reported dissatisfaction, indicating the model’s output did not meet expert expectations.', 'Feedback indicated areas for improvement, including user interface design, processing speed, support for additional languages, and better integration with existing coding platforms.', 'The evaluation relied primarily on subjective practitioner feedback rather than quantitative benchmarking against expert-coded datasets.', 'Scalability and performance in multilingual or highly specialized qualitative contexts remain to be validated.']","['Practitioner-based evaluation involving 10 practitioners from diverse professional backgrounds to assess model performance', 'Use of a comprehensive Likert scale (Not Satisfied, Fair, Satisfactory, Good, Very Good, Excellent) for systematic performance assessment', 'Iterative feedback loop with practitioners to refine model functionality and user experience']","['Engagement of practitioners from academia and industry to ensure evaluation across varied real-world scenarios', 'Structured feedback mechanism focusing on efficiency, user-friendliness, accuracy, and adaptability to different qualitative data types', 'Allowing practitioners to use any data source as input to test model applicability and generalizability']","['Selection of practitioners from diverse domains (Software Engineering, Qualitative Data Analysis, Machine Learning/Deep Learning Development, UX Design, Content Strategy) to minimize domain-specific bias', 'Inclusion of feedback from both satisfied and dissatisfied practitioners to identify and address limitations', 'Iterative development process guided by practitioner feedback to continuously improve model robustness and reduce bias']","['Introduction of an LLM-based multi-agent model that automates the entire qualitative data analysis pipeline, including thematic analysis, grounded theory, content analysis, narrative analysis, and discourse analysis.', 'Development of a collaborative multi-agent architecture where each agent (specialized LLM instance) autonomously executes distinct qualitative analysis tasks, enabling comprehensive and automated processing of large-scale textual and audio datasets.', ""Demonstration of the model's adaptability to diverse data sources and input formats (e.g., web links, raw datasets, textual prompts, uploaded files, audio recordings), with flexible output options (CSV, document, PDF, output area)."", ""Empirical validation of the model's performance and user satisfaction through practitioner-based evaluation involving ten experts from academia and industry, with 87% expressing satisfaction."", 'Extension of LLM-based qualitative analysis beyond initial code generation to full-spectrum, end-to-end automation of multiple qualitative methodologies.']","['Automated and expedited qualitative analysis of large and diverse datasets in software engineering research and practice.', 'Reduction of manual effort, time, and expertise required for coding, interpretation, and decision-making in qualitative research workflows.', 'Support for practitioners and researchers in handling complex and voluminous qualitative data, such as interview transcripts, user feedback, software documentation, and development logs.', 'Provision of a user-friendly interface and customizable workflow, allowing users to select analysis methods, input data in various formats, and receive structured outputs suitable for further analysis or reporting.', 'Potential integration with existing coding platforms and development environments through plugins and templates, as suggested by practitioner feedback.']","[""Exploration of the model's performance and adaptability in multilingual settings to broaden applicability in global research contexts."", 'Integration of more sophisticated natural language processing techniques to further enhance interpretive accuracy and methodological robustness.', 'Continuous refinement of user interface design and expansion of processing capabilities based on iterative feedback from domain experts.', 'Development of additional templates and support for diverse business scenarios and case studies.', 'Investigation of seamless integration with established developer ecosystems and qualitative analysis platforms.']","The multi-agent LLM-based model significantly enhances scalability by enabling rapid, autonomous analysis of large and complex qualitative datasets that would be infeasible for manual methods. The architecture supports diverse input types and formats, and its modular agent-based design allows for parallelization and extension to new qualitative methodologies. Practitioner feedback highlights the need for further improvements in tool scalability, processing speed, and support for additional languages to ensure robust performance in large-scale, real-world applications.",2402.01386v1
arXiv:2411.14473v4,Large Language Model for Qualitative Research: A Systematic Mapping Study,"['Cauã Ferreira Barros', 'Bruna Borges Azevedo', 'Valdemar Vicente Graciano Neto', 'Mohamad Kassab', 'Marcos Kalinowski', 'Hugo Alexandre D. do Nascimento', 'Michelle C.G.S.P. Bandeira']",2025,arXiv,https://arxiv.org/abs/2411.14473,"Qualitative Research Methodology, Computational Text Analysis, Artificial Intelligence, Large Language Models",deductive_qualitative_analysis,content_analysis; grounded_theory; thematic_analysis,3,"healthcare (patients), education (students), general/cultural (not_specified)",semi_structured_interviews; open_ended_survey_responses; documents; social_media; song_lyrics,"semi-automated to fully automated (depending on study and workflow; LLMs automate coding, theme extraction, and categorization, but human oversight and interpretation are often retained, especially for nuanced or ambiguous data)","['ChatGPT', 'GPT-4', 'LLaMA-2', 'ATLAS.TI', 'BERT', 'Sabiá-2 medium', 'BERTopic', 'Parsif.al', 'CollabCoder']","['prompt-based instruction', 'automated extraction', 'fine-tuning of LLMs', 'pseudo response generation', 'topic modeling', 'collaborative AI-assisted coding', 'manual content analysis (for validation)', 'zero-shot classification']","['data collection (interviews, documents, social media, song lyrics, book reviews)', 'data cleaning', 'translation (if needed, e.g., via ChatGPT)', 'prompt engineering (design and testing of prompts for LLMs)', 'model selection and configuration (e.g., fine-tuning, adaptation, or prompt-only use)']","['application of LLMs for open coding, axial coding, or deductive coding', 'theme extraction and categorization', 'topic modeling (e.g., with BERTopic or BERT)', 'automated code suggestion (e.g., CollabCoder)', 'collaborative codebook development (AI-assisted workflows)', 'integration of human review for ambiguous or nuanced cases', 'comparison with traditional/manual qualitative analysis']","['evaluation of coding outputs (accuracy, precision, recall, F1 score, agreement rates)', 'consensus building among coders (e.g., via CollabCoder discussions)', 'visualization (limited; some graphical representations require human intervention)', 'reporting and documentation of prompt engineering and workflow', 'manual review for validation and clarification']","Content analysis, Grounded Theory, Thematic Analysis, Deductive coding, Inductive coding (frameworks vary by study; prompt engineering is essential for reproducibility; human-in-the-loop recommended for interpretative validity)",structured prompt engineering with iterative refinement,"[""Prompts designed to extract specific data extraction criteria (DE1-DE16) mapped to research questions (RQ1-RQ5), e.g., 'Does the study primarily focus on analyzing the use of LLMs to support qualitative data analysis?'"", 'Prompts for coding open-ended responses using pseudo response generation by LLMs', 'Prompts for instructing LLMs to perform open coding, theme extraction, categorization, and topic modeling', 'Prompts for automating article screening in systematic reviews', 'Prompts for generating code suggestions and facilitating coder discussions in collaborative workflows']","['Iterative prompt refinement and testing for alignment with research objectives', 'Use of pre-defined response options to ensure consistency in data extraction', 'Manual review and validation of LLM outputs against full-text articles', 'Exclusion of studies not detailing prompt engineering to ensure reproducibility', 'Public sharing of prompt versions for transparency (e.g., via Zenodo)', 'Prompt-based instruction for qualitative coding tasks (open coding, theme extraction, categorization)', 'Integration of prompt engineering with automated extraction tools (e.g., BERT, ATLAS.TI)', 'Optimization of prompt design for AI-assisted code generation and collaborative workflows']","ChatGPT (including GPT-4), LLaMA-2, ATLAS.TI, BERT, Sabiá-2 medium; ChatGPT 4.0 (paid version) used for data extraction and translation; models used with and without fine-tuning, with a focus on prompt engineering for task adaptation","['LLMs, particularly ChatGPT and its variants, are increasingly used to automate and enhance qualitative analysis across domains such as healthcare, education, and cultural studies.', 'LLMs can automate open coding and theme extraction, providing consistent and reproducible outputs, and significantly reducing analysis time from weeks to hours.', 'Effectiveness of LLM-assisted qualitative analysis is generally equivalent to traditional manual methods, with some studies reporting superior performance and others noting lower effectiveness compared to human analysis.', 'Prompt engineering is critical for reproducibility and accuracy; studies that did not detail prompt engineering were excluded from the mapping.', 'LLMs are most effective for automation-friendly tasks (e.g., initial coding, theme identification), while interpretative and creative processes still require human oversight.', 'Collaborative workflows integrating LLMs (e.g., CollabCoder) can improve coder agreement, streamline discussions, and lower the learning curve compared to traditional tools.', 'Current LLMs struggle with complex integrations, visualizations, and nuanced contextual or emotional interpretation.']","['Comparison with human analysis', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Cohen’s Kappa', 'Agreement Rate']","LLM-assisted qualitative analyses were compared against traditional manual methods using both quantitative metrics (accuracy, precision, recall, F1 Score, Cohen’s Kappa, agreement rate) and qualitative assessments (user studies, coder consensus, workflow efficiency). Studies required detailed reporting of prompt engineering to ensure reproducibility. Manual review and consensus discussions were used to mitigate bias and validate extracted data.","LLMs demonstrated performance equivalent to or better than traditional methods in most studies, with high agreement rates and efficiency gains (e.g., coding time reduced from weeks to hours). Some studies reported lower effectiveness or challenges in nuanced interpretation. Collaborative LLM workflows improved coder consensus and reduced disagreement.","['Strong dependence on well-structured prompt engineering for accurate and reproducible results.', 'LLMs may generate hallucinations—fabricated responses not grounded in source data.', 'Inherent model biases, especially when handling sensitive or subjective information.', 'Difficulty in assigning topics to subjective or ambiguous expressions and lack of context sensitivity and emotional nuance.', 'Over-segmentation and over-categorization of responses by LLMs.', 'Challenges in maintaining coder independence and avoiding premature influence from LLM-generated suggestions in collaborative workflows.', 'Potential for loss of nuanced or detailed categorization important to human researchers.', 'Inconsistencies in zero-shot classification and risk of echo chamber effects (reproduction of pre-trained patterns).', 'Limited ability to perform complex integrations or visualizations required for advanced qualitative analysis.', 'Possible confirmation bias due to using LLMs both for data extraction and for evaluating LLM effectiveness.', 'Exclusion of studies lacking detailed prompt engineering may restrict the comprehensiveness of the mapping.', 'Absence of snowballing in the systematic mapping may have led to omission of relevant studies.', 'LLMs may lack deep contextual understanding, resulting in superficial or incomplete information extraction.']","['Comparison with human analysis', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Cohen’s Kappa', 'Agreement Rate', 'Manual review of extracted data', 'Standardized selection criteria for study inclusion', 'Iterative prompt engineering with validation using test articles']","['Manual review and full reading of articles to clarify doubts and ensure analytical depth', 'Inclusion of studies from diverse domains to enhance external validity', 'Iterative prompt engineering process with transparency (versions made available on Zenodo)', 'Validation of model outputs against known responses', 'Requirement for detailed prompt engineering descriptions to ensure reproducibility', 'Consensus discussions between researchers for study selection', 'Use of established qualitative analysis frameworks (e.g., Grounded Theory, Content Analysis, Thematic Analysis)', 'Comparison with traditional qualitative analysis methods']","['Human verification of LLM outputs and translations', 'Joint discussions between researchers to resolve inclusion uncertainties', 'Reliance on solid references from analyzed articles to avoid confirmation bias', 'Manual review to mitigate superficiality and incomplete extraction by LLMs', 'Requirement for studies to detail prompt engineering to ensure replicability and reduce methodological bias', 'Recommendations for LLMs to serve as aids rather than replacements for human analysts, with humans retaining interpretative authority', 'Emphasis on user control over AI-generated suggestions to prevent over-reliance and premature influence', 'Recognition and reporting of LLM limitations such as hallucinations, over-segmentation, and model bias']","['Systematic mapping of the state of the art on the use of Large Language Models (LLMs) in deductive and inductive qualitative analysis, with a focus on interview and textual data.', 'Identification and synthesis of application contexts, LLM configurations, methodologies, and evaluation metrics for automated and semi-automated qualitative analysis pipelines.', 'Establishment of a standardized data extraction protocol and inclusion/exclusion criteria emphasizing reproducibility through detailed prompt engineering documentation.', 'Empirical comparison of LLM-assisted qualitative analysis with traditional manual methods across multiple domains (healthcare, education, culture, technology).', 'Highlighting the effectiveness of LLMs (e.g., ChatGPT, LLaMA-2, BERT) in automating open coding, theme extraction, and categorization, with performance often equivalent or superior to human analysis.', 'Introduction of collaborative workflows (e.g., CollabCoder) integrating LLMs for code suggestion, coder discussion, and codebook development.']","['Automation of open and axial coding in qualitative research, drastically reducing analysis time from weeks to hours.', 'Integration of LLMs into collaborative qualitative analysis workflows to streamline coder discussions, decision-making, and codebook refinement.', 'Use of LLMs for rapid theme extraction and categorization in large-scale interview datasets and open-ended survey responses.', 'Application of LLMs in healthcare, education, and cultural studies for efficient processing of patient feedback, student surveys, and textual corpora.', 'Development of user-friendly interfaces and workflows (e.g., CollabCoder) to lower the barrier for non-AI experts in conducting rigorous qualitative analysis.']","['Refinement of prompt engineering techniques to enhance LLM accuracy, robustness, and flexibility in qualitative analysis tasks.', 'Exploration of advanced LLM architectures and fine-tuning strategies to improve semantic and subjective nuance capture.', 'Development of methods to mitigate LLM hallucinations and biases, including validation and filtering techniques.', 'Expansion of open-source LLMs and user-friendly tools to increase accessibility and reduce costs for qualitative researchers.', 'Establishment of standardized, robust evaluation metrics tailored to the complexity of qualitative analysis performed by LLMs.', 'Investigation of LLM integration in software engineering research, particularly for requirements engineering and user feedback analysis.', 'Optimization of AI-assisted collaborative workflows to balance coder independence and consensus, and to prevent premature influence from LLM-generated suggestions.', 'Incorporation of multimodal data and interaction models to further enhance coder collaboration and analysis depth.']","LLMs enable scalable qualitative analysis by automating coding and theme extraction across large unstructured datasets (e.g., hundreds of interviews, millions of social media posts), overcoming traditional bottlenecks of manual analysis. However, scalability is contingent on well-structured prompt engineering, model robustness, and the ability to maintain accuracy and contextual sensitivity at scale. Collaborative workflows and user-friendly interfaces further support scalability by lowering technical barriers and facilitating coder alignment in large research teams.",2411.14473v4
not_specified,Prompt-based and Fine-tuned GPT Models for Context-Dependent and -Independent Deductive Coding in Social Annotation,"['Chenyu Hou', 'Gaoxia Zhu', 'Juan Zheng', 'Lishan Zhang', 'Xiaoshan Huang', 'Tianlong Zhong', 'Shan Li', 'Hanxiang Du', 'Chin Lee Ker']",2024,"The 14th Learning Analytics and Knowledge Conference (LAK ’24), March 18–22, 2024, Kyoto, Japan",https://doi.org/10.1145/3636555.3636910,"Learning Analytics, Educational Technology, Computational Qualitative Analysis",deductive qualitative coding; automated and semi-automated content analysis using prompt-based and fine-tuned GPT models,"coding scheme based on cognitive, emotional, and social engagement dimensions; codebook adapted from Zhu et al. (2021, 2022) for cognitive (appraisal, theorizing, integration, questioning, reflection), social (peer/community interaction), and emotional (curiosity, surprise) aspects; context-dependent and context-independent coding distinction",7482,"93 undergraduate students (47 females, mean age 20.67) from a large North American university, enrolled in an elective learning media course","digital social annotation activity using Perusall platform over 7 weeks; students annotated assigned readings and commented/interacted online; 7,482 comments extracted from Perusall logs",semi-automated (prompt-based and fine-tuned GPT models for deductive coding; human-in-the-loop for codebook development and evaluation),"['OpenAI GPT-3.5-turbo', 'Perusall (for data collection)']","['prompt engineering', 'iterative prompt refinement', 'chain-of-thought prompting', 'multi-prompt learning', 'prompt decomposition', 'codebook-centered prompting', 'fine-tuning of GPT-3.5-turbo with labeled data']","['Extraction of annotation data from Perusall log files', 'Manual coding of a subset of comments by trained human raters', 'Development and refinement of a codebook for deductive coding dimensions', 'Splitting labeled data into training and validation sets']","['Iterative prompt engineering for each coding dimension using GPT-3.5-turbo', 'Application of chain-of-thought and step-based prompts for reasoning transparency', 'Multi-prompt and prompt decomposition for complex coding (e.g., Questioning dimension)', 'Application of codebook-centered prompts to guide model outputs', 'Evaluation of prompt-based GPT outputs against human-coded ground truth using Cohen’s Kappa', 'Fine-tuning GPT-3.5-turbo on 102 labeled examples per dimension with consistent prompts', 'Validation of fine-tuned models on held-out labeled data', 'Comparison of model performance (prompt-based vs. fine-tuned vs. human raters)']","['Calculation of inter-rater reliability (Cohen’s Kappa) for each coding dimension', 'Analysis and reporting of model agreement with human coders', 'Interpretation of model outputs for feedback and dashboarding in educational platforms']","Deductive coding using a codebook developed from prior research and theory, covering cognitive (Appraisal, Theorizing, Integration, Reflection, Questioning), social (Social), and emotional (Curiosity, Surprise) dimensions; context-dependent and context-independent categories; multi-level codes per dimension; operationalized with explicit prompt templates for each code.","iterative manual prompt engineering with codebook-centered, chain-of-thought, step-based, and multi-prompt techniques","[""You are a research assistant. You will be provided with an annotation, and you need to determine the integration level of the annotation, and then label the annotation '0', '1' or '2' based on the following three steps. Your response should only contain '0','1' or '2': Step 1 – determine if the annotation is building on another idea. The first sentence tends to be a response to another annotation using phrases such as 'This is true', 'you remind me of', 'Great addition', and/or including symbol '@'. The annotation will also explain why they build on the idea starting from the second sentence. If the annotation fits this format, label the annotation as '1', if not, label the annotation as '0'. Step 2 - You should re-evaluate the annotation you labeled as '1'. You should label the annotation as '2' if the annotation also has extended explanations on why they build on the idea. The explanations tend to contain specific examples (e.g., the name of songs/movies), be longer than average, and contain logical words such as 'thus', 'because', 'however', and 'but'. Step 3 - Ensure that your answer only has '0' or '1', or '2'."", ""You are a research assistant. You will be provided with an annotation. You need to evaluate the theorizing level of an annotation, and then label the annotation as '0', '1' or '2' based on the following rules. Your response should only contain '0', '1','2': Code '1' - The annotation has a sentence to make a claim, using words such as 'think,' 'believe', 'remember', and 'it is interesting'. Code '2' - In addition to making a claim, the annotation also supplements the argument with explanations, so that the annotation is long and contains logical words such as 'thus', 'because', 'however', and 'but'. Code '0' - All other cases. Make sure that your response only has '0', '1' or '2'."", ""You are a research assistant. You will be provided with an annotation, and you need to determine if the annotation includes a reflection, and then label it '0' or '1' based on the following rules. Your response should only contain '0' or '1': Code '1' - the annotation uses the first pronoun 'I' and reflect on one of the following things: 1) his or her personal experiences (e.g., ethnicity, childhood experience); 2) habits, personal preferences, personal interests (e.g., 'I like doing something'); 3) a social phenomenon (e.g., 'I remember something happened'). The annotation usually mentions specific details such as the names of songs/movies. Code '0' - all other cases. Make sure that your answer only has '0' or '1'."", ""You are a research assistant. You will be provided with an annotation, and you should label the annotation with '0', '1' or '2', following the three steps being provided: Step 1 - if the first sentence has a short phrase that very clearly indicates agreement or disagreement, such as 'I agree', 'I disagree', 'great', and 'that’s correct', you should label the annotation as '1'; if not, label it as '0'. Step 2 - You should re-evaluate the annotation you labeled as '1'. You should label the annotation as '2' if the annotation provides extended explanation with details and examples starting from the second sentence. The explanations tend to be longer than average and contain logical words such as 'thus', 'because', 'however', and 'but'. Step 3 - Ensure that your response only contains a numerical value '0', '1', or '2'."", ""You are a research assistant. Please evaluate the question level of students’ annotations, and only return numerical values '0', '1', '2'. Return '1' if the annotation has one sentence that is a question. Usually, the question ends with a question mark, or includes phrases such as 'I wonder' or 'I am curious'. Return '0' for all other situations."", ""a new rule applies to all the rows with returned value '1': Change to the label from '1' to '2' if the question is seeking explanations and cannot be answered with 'yes/no'. The question usually starts with 'how/what/when/which'. Please only return numerical values '0', '1', '2'.""]","['codebook-centered prompting', 'step-based instructions', 'chain-of-thought prompting (requiring reasoning/explanation in intermediate steps)', 'multi-prompt learning (prompt decomposition for sequential labeling)', ""persona-based instruction (e.g., 'You are a research assistant...')"", 'iterative prompt refinement based on empirical performance', 'explicit instruction to return only numerical codes', 'reducing ambiguity in instructions (avoiding pronouns, using explicit terms)']",OpenAI GPT-3.5-turbo; temperature set to 0 for reproducibility; fine-tuning performed on 102 expert-labeled examples per dimension for selected categories; validation on an additional 102 examples; prompt-based and fine-tuned models compared using Cohen’s Kappa agreement with human raters,"['Prompt engineering with GPT-3.5-turbo achieves fair to substantial agreement with expert-labeled data for context-independent deductive coding dimensions (e.g., Questioning, Social, Surprise) in social annotation.', 'Agreement is lower for context-dependent dimensions (e.g., Theorizing, Integration, Reflection) when using prompt-based approaches.', 'Fine-tuning GPT models with 102 expert-labeled examples per dimension improves performance, achieving substantial agreement for context-independent dimensions and moderate agreement for context-dependent dimensions.', 'Fine-tuned models can outperform human inter-rater reliability in some context-independent dimensions (e.g., Curiosity, Appraisal).', 'Prompt engineering strategies such as chain-of-thought, prompt decomposition, multi-prompt learning, and codebook-centered approaches enhance model performance.', 'Automated deductive coding with GPT models can significantly reduce human labor and time without sacrificing accuracy or reliability, especially for large unstructured datasets.']","[""Cohen's Kappa""]","Split-sample validation: 204 comments were coded by two human raters (with inter-rater reliability calculated), then divided into 102 for fine-tuning and 102 for validation of GPT-based models. Model outputs were compared to expert labels.","Cohen's Kappa scores for each coding dimension (e.g., .75 for Questioning, .67 for Social, .49 for Curiosity, .65 for Surprise, .33 for Appraisal in prompt-based; .86 for Curiosity, .69 for Appraisal in fine-tuned; .59 for Theorizing, .54 for Reflection, .45 for Integration in fine-tuned context-dependent dimensions).","['Limited size of expert-labeled dataset (204 comments), which may affect generalizability and robustness of model evaluation.', 'Training and validation data were drawn from a single article/topic, limiting assessment of model transferability across topics or domains.', 'Context-dependent coding did not include the original reading text or surrounding comments as input due to token limitations and risk of information loss, potentially constraining model performance for these dimensions.', 'Potential information loss or ambiguity in coding context-dependent dimensions due to lack of contextual input.', 'Generalizability to other types of qualitative data (e.g., discussion forums, essays) or other annotation platforms remains untested.', 'No exploration of automatic prompt-tuning or optimization beyond manual iterative engineering.']","['Cohen’s Kappa calculated between human raters for each coding dimension (e.g., .63 for Appraisal, .95 for Questioning, .80 for Theorizing, .83 for Reflection, .50 for Integration, .92 for Social, .87 for Surprise, .76 for Curiosity)', 'Cohen’s Kappa calculated between GPT-based approaches (prompt-based and fine-tuned) and expert-labeled data for each coding dimension', 'Inter-rater reliability assessment between two trained human coders on a subset of data (50 comments)']","['Expert-labeled data used as ground truth for model evaluation', 'Iterative codebook development and refinement through discussion and consensus among human coders', 'Validation of fine-tuned GPT models on a held-out set of expert-labeled data (102 cases for validation)', 'Comparison of model outputs (prompt-based and fine-tuned) with human coding to assess agreement']","['Iterative prompt engineering to reduce ambiguity and improve clarity in instructions (e.g., avoiding demonstrative pronouns, using explicit step-based instructions)', 'Chain-of-thought prompting to elicit model reasoning and enable prompt calibration', 'Codebook-centered approach to standardize coding definitions and examples across raters and models', 'Multi-prompt learning and prompt decomposition to handle complex or multi-level coding tasks', 'Temperature set to 0 in GPT models to ensure reproducibility and reduce stochastic output variance', 'Exclusion of low-frequency codes (e.g., confusion, referencing) to avoid unreliable model training and evaluation', 'Reporting of prompt, fine-tuning strategies, and model details to enhance transparency and replicability']","['First systematic evaluation of GPT-based prompt engineering and fine-tuning for both context-dependent and context-independent deductive coding in social annotation data.', 'Development and empirical validation of a codebook-centered, multi-level deductive coding scheme operationalized for automated and semi-automated analysis using LLMs.', 'Demonstration that prompt engineering (including prompt decomposition, chain-of-thought, and multi-prompt learning) can achieve fair to substantial agreement with expert human coders in several coding dimensions.', 'Empirical evidence that fine-tuning GPT-3.5-turbo with as few as 102 labeled examples can substantially improve inter-rater reliability, especially for context-dependent coding dimensions.', 'Identification of technical strategies (e.g., step-based prompts, reduction of ambiguity, exclusion of excessive context) that optimize LLM performance for qualitative coding tasks.']","['Automated or semi-automated deductive coding of large-scale social annotation datasets, reducing human labor and time without sacrificing accuracy or reliability.', 'Integration of LLM-based coding pipelines into social annotation platforms to provide immediate, tailored feedback to students and instructors, supporting deeper inquiry and collaborative knowledge construction.', 'Development of dashboards and annotation sorting features based on automated coding outputs to enhance navigation and engagement in educational platforms.', 'Potential extension of the pipeline to other qualitative data types, such as online discussion forums and written essays, for scalable qualitative analysis in educational research.']","['Expansion of expert-labeled datasets and validation of prompt engineering and fine-tuned models across diverse topics, courses, and annotation contexts to assess generalizability (near and far transfer).', 'Incorporation of original reading materials and surrounding comments as contextual input for context-dependent coding, addressing token limitations and information loss in LLMs.', 'Exploration of automatic prompt-tuning and optimization methods to further enhance prompt-based approaches.', 'Application and evaluation of the proposed deductive coding pipeline in other learning contexts and data structures beyond social annotation.', 'Standardization and transparent reporting of prompts, fine-tuning strategies, and model details in publications utilizing LLMs for qualitative coding.']","The pipeline is designed to be scalable to large unstructured datasets, leveraging prompt engineering for rapid deployment and fine-tuning for improved accuracy with limited labeled data. However, scalability for context-dependent coding is currently constrained by token limits and the challenge of incorporating full contextual information. The approach is particularly suitable for datasets too small for traditional supervised machine learning but large enough to benefit from automation. Future scalability will depend on advances in LLM context window size and efficient context summarization.",3636555.3636910
not_specified,When the Prompt becomes the Codebook: Grounded Prompt Engineering (GROPROE) and its application to Belonging Analytics,"['Sriram Ramanathan', 'Lisa-Angelique Lim', 'Nazanin Rezazadeh Mottaghi', 'Simon Buckingham Shum']",2025,LAK 2025: The 15th International Learning Analytics and Knowledge Conference,https://doi.org/10.1145/3706468.3706564,"Learning Analytics, Qualitative Research Methodology, Computational Text Analysis",deductive qualitative analysis using automated and semi-automated computational workflows,"Four domains of belonging framework (Ahn & Davis, 2020) extended with 'experiencing emotions' as a higher order code; codebook grounded in literature on affective engagement and belonging in higher education",860,undergraduate business students at University of Technology Sydney; further demographic details not_specified,written reflections collected at the start and end of semester (Stage I: goals for the subject; Stage II: evaluation of goals); maximum length 500 words per reflection,semi-automated,"['Azure Playground', 'GPT-4']","['Large Language Model-based deductive coding', 'Chain-of-Thought (CoT) prompting', 'Few-shot prompting', 'Prompt decomposition', 'Multi-prompt learning', 'Seed-word prompting']","['Development of codebook grounded in literature', 'Grouping indicators into higher order categories and sub-categories', 'Manual coding of sample set by human coders', 'Consensus meetings to resolve coding disagreements']","['Iterative refinement of codebook and translation into system prompt', 'Design and testing of prompt using GPT-4 in Azure Playground', 'Application of prompt to sample reflections for deductive coding', 'Inclusion of Chain-of-Thought reasoning in LLM outputs', 'Few-shot prompt construction with examples and explicit definitions', 'Iterative prompt engineering based on LLM output and human discussion', 'Repeated LLM coding of sample texts to assess output stability (LLMq metric)']","['Calculation of Inter-Annotator Reliability (IAR) using Cohen’s Kappa', 'Calculation of Large Language Model Quotient (LLMq) for coding consistency', 'Comparison of LLM coding with human coding', 'Analysis of LLM reasoning for code assignment', 'Reporting of findings and discussion of discrepancies']","Theory-driven, literature-grounded codebook based on the four domains of belonging (academic belonging, interpersonal belonging, belonging to surroundings, mattering as belonging) and experiencing emotions, with explicit subcategories and indicators; codebook iteratively refined and operationalized as a system prompt for LLM-based deductive coding.","Grounded Prompt Engineering (GROPROE); theory-driven, codebook-based, iterative refinement","['Zero-shot prompt: Initial prompt based on codebook definitions without examples (see Figure 4).', 'Final few-shot prompt: System prompt including explicit definitions, hierarchical codebook, multiple examples per code, step-by-step instructions, and Chain-of-Thought (CoT) reasoning (see Appendix).']","['Translation of literature-derived codebook into system prompt', 'Iterative prompt refinement based on LLM output and human discussion', 'Prompt decomposition', 'Multi-prompt learning with codebook', 'Inclusion of input-output exemplars (few-shot prompting)', 'Explicit construct/label directives', 'Chain-of-Thought (CoT) prompting for reasoning transparency', 'Seed-word prompting for clarity', 'Modification of instructions, formatting, and output criteria', 'Inclusion of supporting context and simplified definitions', 'Human-in-the-loop prompt validation and revision']",GPT-4 via Azure Playground; prompt tested and iteratively refined in this environment,"['The GROPROE (Grounded Prompt Engineering) process enables systematic, theory-grounded prompt engineering for deductive qualitative analysis using LLMs.', 'A codebook derived from literature on affective engagement and belonging was successfully translated into a system prompt for LLM-based coding.', 'Substantial agreement was achieved between human and LLM coding, with Cohen’s Kappa values of 0.74 (human-human) and 0.76 (human-LLM), indicating reliable automated coding.', 'LLM coding consistency, measured by the LLM Quotient (LLMq), showed stable application of most codes across 60 iterations, though some codes (e.g., interpersonal belonging, belonging to surroundings) exhibited more variability.', 'Iterative prompt refinement, including Chain-of-Thought (CoT) reasoning and few-shot examples, improved LLM coding accuracy and alignment with human coders.', 'The LLM’s reasoning sometimes prompted revision of the codebook, demonstrating productive human-AI interaction but also highlighting risks of LLM sycophancy.', 'The GROPROE pipeline is the first reported use of LLMs for deductive coding of affective engagement and belonging in student reflections.']","['Cohen’s Kappa (Inter-Annotator Reliability, IAR, and Inter-Rater Reliability, IRR)', 'Large Language Model Quotient (LLMq) for coding consistency']","Manual coding of a sample set (20 reflections) by two human coders using the codebook, calculation of IRR (Cohen’s Kappa), comparison of LLM coding to human coding (IAR, Cohen’s Kappa), repeated LLM coding (60 iterations per text) to compute LLMq for consistency assessment.","Substantial agreement between human and LLM coding (Cohen’s Kappa = 0.76); stable LLMq for most codes across multiple iterations; some variability in specific codes (e.g., interpersonal belonging, belonging to surroundings).","['Human-coded sample comprised only 2% of the full dataset, which may not be representative.', 'LLMq was calculated over 60 iterations per text, fewer than the 160 iterations in prior studies, due to technical limitations.', 'LLM exhibited occasional misclassification by considering factors outside the intended university context.', 'Potential for LLM sycophancy (bias to please the user) affecting coding decisions.', 'Generalizability of GROPROE to other domains or text types remains to be tested.']","['Inter-Rater Reliability (IRR) between human coders calculated using Cohen’s Kappa', 'Inter-Annotator Reliability (IAR) between human and LLM coding calculated using Cohen’s Kappa', 'Large Language Model Quotient (LLMq) to assess consistency of LLM coding across multiple iterations']","['Theory-driven codebook development grounded in established literature and frameworks (e.g., four domains of belonging)', 'Iterative refinement of codebook and prompt based on empirical outputs and researcher discussion', 'Use of few-shot and chain-of-thought (CoT) prompting to elicit reasoning and ensure alignment with theoretical constructs', 'Manual coding of a sample set by researchers to validate LLM outputs']","['Human-in-the-loop iterative prompt and codebook refinement to address discrepancies and update coding scheme', 'Explicit instruction to LLM to provide reasoning for code assignments (CoT) to enable researcher review and challenge', 'Awareness and monitoring of LLM sycophancy (bias to please user) with researchers taking responsibility for final coding decisions', 'Comparison of LLM coding with human coding to identify and address systematic differences']","['Introduction of Grounded Prompt Engineering (GROPROE) as a systematic, literature-grounded process for developing prompts for deductive qualitative analysis using Large Language Models (LLMs).', 'First demonstration of using LLMs to infer affective engagement and sense of belonging from student reflective writing in higher education.', 'Detailed worked example of translating theoretical constructs and empirical indicators into a hierarchical codebook and then into an LLM prompt for automated coding.', 'Empirical evaluation of human-LLM inter-annotator reliability (IAR) and LLM coding consistency using the Large Language Model Quotient (LLMq) metric.', ""Critical reflection on the dynamics of human-AI interaction in qualitative analysis, including the phenomenon of 'prompt becoming the codebook' and LLM agency/sycophancy.""]","['Automated or semi-automated deductive coding of large-scale qualitative datasets (e.g., student reflections) in educational research and learning analytics.', 'Embedding theory-grounded LLM prompts into survey analytics for efficient analysis of open-ended student responses.', 'Potential integration of GROPROE-based LLM prompts into student-facing chatbots to adapt conversational strategies based on detected affective engagement and belonging.', 'Augmentation of human qualitative analysis workflows with LLMs to improve coding consistency, scalability, and transparency.']","['Testing the GROPROE process and developed prompts on other qualitative datasets and educational contexts to assess generalizability.', 'Scaling up human validation of LLM-coded data to larger samples for more robust evaluation of reliability and validity.', 'Further investigation into mitigating LLM biases such as sycophancy and ensuring interpretive agency remains with human researchers.', 'Exploring advanced infrastructure to enable higher iteration counts for LLMq and deeper analysis of LLM coding stability.', 'Embedding LLM-based deductive coding tools into real-time analytics platforms and educational interventions.']","GROPROE enables deductive qualitative analysis at scale by leveraging LLMs to code large textual corpora (e.g., 860 student reflections) with substantial agreement to human coders. The process supports iterative refinement and validation of prompts/codebooks, but current human validation is limited to small samples due to resource constraints. LLMq allows for high-throughput consistency checks impractical for humans. Scalability is contingent on computational resources, prompt clarity, and ongoing human oversight to ensure reliability and mitigate model biases.",3706468.3706564
not_specified,From nCoder to ChatGPT: From Automated Coding to Refining Human Coding,"['Andres Felipe Zambrano', 'Xiner Liu', 'Amanda Barany', 'Ryan S. Baker', 'Juhan Kim', 'Nidhi Nasiar']",2024,not_specified,not_specified,"Qualitative Research Methodology, Computational Text Analysis, Quantitative Ethnography",deductive qualitative coding; automated and semi-automated coding comparison,Quantitative Ethnography; construct validity; interrater reliability; codebook-driven deductive coding,200,governmental leaders from seven countries (press releases and public addresses); specific demographic details not_specified,transcripts of press releases and public addresses delivered by governmental leaders,semi-automated,"['nCoder', 'ChatGPT (GPT-4)']","['regular expressions', 'large language models (LLMs)', 'semantic similarity analysis', 'iterative prompt engineering', 'agreement metrics calculation (Kappa, precision, recall, Shaffer’s rho)']","['random selection of training and test sets from dataset', 'definition and refinement of codebook/categories', 'provision of construct definitions to coding tools']","['application of regular expressions in nCoder to code training set', 'iterative refinement of regular expressions based on disagreements with human coders', 'application of optimized regular expressions to test set', 'provision of code definitions and examples to ChatGPT', 'iterative coding with ChatGPT in batches (due to prompt length limits)', 'requesting and reviewing ChatGPT explanations for disagreements', 'refinement of code definitions/prompts for ChatGPT based on explanations', 'application of refined prompts to code test set']","['calculation of agreement metrics (Kappa, precision, recall, Shaffer’s rho)', 'comparison of machine and human coding results', 'review of ChatGPT explanations for construct validity and consistency checks', 'identification and analysis of coding inconsistencies', 'potential revision of codebook based on insights']","deductive coding using a predefined codebook with seven categories (Medical Positive, Medical Negative, Economic Positive, Economic Negative, Social Positive, Social Negative, Political Positive) refined through iterative human-machine interaction",iterative refinement with human-in-the-loop,"['For each construct, provide ChatGPT with the construct name and original definition from the codebook.', 'After a disagreement between ChatGPT and human coders, request an explanation from ChatGPT regarding its coding decision.', ""Incorporate ChatGPT's explanations to enhance and clarify code definitions in the prompt, including clarifying statements and examples of appropriate and inappropriate phrases."", 'Limit each definition provided to ChatGPT to a maximum of five sentences to avoid information overload.', ""Conduct coding in subsets of 25 lines per prompt due to ChatGPT's maximum prompt length.""]","['Iterative prompt refinement based on disagreement analysis between ChatGPT and human coders.', 'Inclusion of construct definitions, clarifying statements, and positive/negative examples in prompts.', ""Soliciting ChatGPT's suggestions for updating code definitions and reviewing these suggestions with human researchers."", ""Prompt length management to fit within ChatGPT's input constraints."", 'Human review and fine-tuning of any ChatGPT-suggested definition changes before re-prompting.', 'Disregarding revised definitions that negatively impact agreement and proceeding to next disagreement.']","ChatGPT (GPT-4 model; see OpenAI GPT-4 Technical Report, 2023)","['Both ChatGPT (GPT-4) and nCoder have distinct advantages and disadvantages for automated coding of qualitative interview data, depending on the context, data nature, and research goals.', 'nCoder, which relies on regular expressions, achieves higher precision and agreement with human coders for constructs that can be explicitly defined with specific language patterns, but suffers from lower recall due to its inability to generalize beyond observed examples.', 'ChatGPT demonstrates higher recall than nCoder, effectively capturing semantic and contextual variations in language, but often exhibits lower precision due to overgeneralization, especially for constructs that are open to interpretation or less thematically discrete.', ""ChatGPT's ability to provide detailed explanations for its coding decisions supports human coders in refining code definitions, identifying ambiguities, and improving construct validity and interrater reliability."", 'Disagreements between automated tools and human coders can reveal inconsistencies or ambiguities in human coding schemes, and ChatGPT can serve as a peer-like support for critical reflection and systematic review of coding decisions.', 'ChatGPT outperforms nCoder for constructs with broad or complex semantic fields (e.g., Economic Positive), but underperforms for constructs prone to subjective interpretation (e.g., Social Positive/Negative).', 'Automated coding tools do not necessarily establish ground truth; lower agreement metrics may reflect fuzziness or ambiguity in human coding rather than tool inaccuracy.']","[""Cohen's Kappa"", 'Precision', 'Recall', ""Shaffer's rho""]",Comparison of automated coding outputs (nCoder and ChatGPT) to human-generated codes using a training set (100 lines) and a test set (100 unobserved lines) from a dataset of governmental press releases and public addresses. Iterative refinement of code definitions and regular expressions was performed based on disagreements. Agreement metrics were calculated for both training and test sets.,"nCoder achieved higher average Kappa (0.77 train, 0.53 test) and precision (0.79) but lower recall (0.60) compared to ChatGPT (Kappa: 0.54 train, 0.46 test; precision: 0.52; recall: 0.80). ChatGPT's performance varied by construct, with high precision and recall for concrete categories (e.g., Economic Positive) and lower precision for open or ambiguous constructs (e.g., Social Negative).","[""nCoder's reliance on regular expressions limits its ability to generalize to unseen language patterns, resulting in lower recall."", 'ChatGPT tends to overgeneralize for constructs that are open to interpretation or not thematically discrete, leading to lower precision.', 'ChatGPT may misinterpret or overlook relevant nuances in the data, especially for subjective or complex constructs.', ""The study did not re-code the dataset with human coders after refining code definitions based on ChatGPT's explanations, limiting the assessment of improvements in human coding consistency."", 'Agreement metrics only measure (dis-)agreement between human and machine coding, not absolute accuracy or correctness.', 'Potential for construct drift and coder inconsistency over time was not systematically addressed.', 'The approach may be less effective for inductive code development or for constructs that are not mutually exclusive and collectively exhaustive.', 'Prompt length and information overload constraints in ChatGPT required limiting code definitions to five sentences and coding in small batches.']","[""Cohen's Kappa"", 'Precision', 'Recall', ""Shaffer's rho"", 'Inter-rater agreement']","['Construct validity assessment via iterative refinement of code definitions', 'Use of ChatGPT explanations to identify ambiguity in code definitions', 'Critical examination of disagreements between human and machine coding', 'Review and refinement of code definitions based on machine explanations', 'Comparison of automated coding outputs to human-generated codes']","['Inclusion of original dataset author to reduce misinterpretation of codebook', 'Iterative review and refinement of regular expressions in nCoder', 'Human review and fine-tuning of ChatGPT-suggested code definitions', 'Systematic examination of disagreements to identify inconsistencies and idiosyncrasies in human coding', 'Use of explanations from ChatGPT to support reflexivity and critical reflection in human coding', 'Limiting prompt length to avoid information overload in ChatGPT', ""Review of ChatGPT's suggestions for updating code definitions before adoption""]","['Systematic comparison of ChatGPT (GPT-4) and nCoder for automated coding in Quantitative Ethnography (QE) using a real-world dataset of governmental press releases and addresses.', 'Development of an interactive, iterative workflow for refining code definitions and prompts in ChatGPT based on explanations of coding disagreements.', ""Demonstration of ChatGPT's ability to provide detailed, grounded explanations for coding decisions, supporting construct validity and consistency checks in human coding."", 'Empirical evaluation of agreement metrics (Kappa, precision, recall, Shaffer’s rho) for both nCoder and ChatGPT across multiple code categories.', 'Identification of the affordances and limitations of LLM-based coding versus regular expression-based automated coding tools.']","['Use of ChatGPT as a semi-automated coding assistant to support human coders in refining codebooks and resolving ambiguities in qualitative data analysis.', 'Application of ChatGPT explanations to enhance construct validity and interrater reliability in coding schemes.', 'Integration of ChatGPT into existing qualitative analysis pipelines to facilitate consistency checks and code definition refinement.', 'Potential for ChatGPT to assist in reviewing and improving consistency across large, human-coded datasets, including detection of coder drift.']","['Exploration of ChatGPT and other LLMs for supporting inductive code development and thematic analysis in qualitative research.', ""Investigation of ChatGPT's utility for addressing coder drift and improving consistency in longitudinal or large-scale qualitative coding projects."", 'Further study of the impact of ChatGPT explanations on human coder reflexivity and the iterative refinement of coding schemes.', 'Assessment of the potential for integrating regular expressions or other rule-based elements into ChatGPT prompts to emulate or enhance nCoder-like functionality.', 'Evaluation of LLM-based coding tools in diverse qualitative research contexts and with more complex or less discrete constructs.']","Manual coding is unsuitable for large datasets due to time and error constraints; nCoder scales well for constructs definable by regular expressions but struggles with recall and semantic nuance. ChatGPT, as a pre-trained LLM, can generalize to unseen vocabulary and semantic structures, offering higher recall and potential scalability for complex or varied data. However, ChatGPT's current prompt length limitations require batching data, and its performance may decrease for constructs that are open to interpretation or not mutually exclusive. Both tools require iterative refinement for optimal performance, but ChatGPT's interactive explanations can facilitate scalable, semi-automated codebook refinement and consistency checking.",ChatGPT_ICQE_FinalVersion
not_specified,ChatGPT for Education Research: Exploring the Potential of Large Language Models for Qualitative Codebook Development,"['Amanda Barany', 'Nidhi Nasiar', 'Chelsea Porter', 'Andres Felipe Zambrano', 'Alexandra L. Andres', 'Dara Bright', 'Mamta Shah', 'Xiner Liu', 'Sabrina Gao', 'Jiayi Zhang', 'Shruti Mehta', 'Jaeyoon Choi', 'Camille Giordano', 'Ryan S. Baker']",2024,"AIED 2024, LNAI 14830, pp. 134–149, Springer Nature Switzerland AG",https://doi.org/10.1007/978-3-031-64299-9_10,Educational Research / Qualitative Data Analysis / Artificial Intelligence in Education,"inductive qualitative coding (codebook development and evaluation), with comparative analysis of manual, automated, and hybrid (human-LLM) workflows",not_specified,4,9th grade students enrolled in Algebra I at high-poverty urban schools in the northeastern United States (2022–2023); tutoring sessions conducted virtually by trained tutors from Saga Education,transcripts of four 60-minute virtual math tutoring sessions,"hybrid (manual, semi-automated, and fully automated approaches compared; focus on hybrid human-LLM collaboration)","['ChatGPT (GPT-4, web-based chatbot version)', 'not_specified']","['Large Language Models (LLMs) for code suggestion, refinement, and codebook development', 'Prompt engineering for LLM interaction', 'Natural Language Processing (NLP) for text analysis', 'Cohen’s kappa for inter-rater reliability evaluation']","['Obtain and segment interview transcript data into batches (77–98 lines per batch, based on token limits)', 'Initial qualitative review of data for context and structure', 'Prompt engineering and testing for LLM consistency']","['Manual codebook development using established qualitative methods (e.g., Weston et al. [40])', 'LLM-assisted codebook development: prompt ChatGPT to generate preliminary codes, definitions, and examples', 'LLM-assisted codebook refinement: provide preliminary codebook and data batches to ChatGPT for iterative refinement', 'Hybrid workflows: human-led codebook development with LLM refinement, or LLM-led codebook development with human refinement', 'Batch-wise processing to accommodate LLM input limits', 'Manual review and correction of LLM outputs (e.g., replacing hallucinated examples with genuine quotes)']","['Independent human coding of transcripts using finalized codebooks', 'Survey-based evaluation of codebook utility (ease of use, clarity, mutual exclusivity, exhaustiveness)', 'Calculation of inter-rater reliability (Cohen’s kappa) across coding rounds', 'Social moderation sessions for coder consensus and codebook annotation', 'Cross-codebook conceptual overlap analysis']",Deductive and inductive coding frameworks; codebook development and refinement based on Weston et al. [40] and thematic analysis principles; hybrid human-LLM mutual learning and prompt engineering for codebook generation and refinement,hybrid and automated prompting for codebook development and refinement in qualitative analysis,"['You are a researcher helping develop a qualitative codebook for text data of a math tutor’s interactions with students. I will give you the first draft of the codebook, and then the data being coded, in batches. Please help me refine the codes and codebook, focusing on instructional strategies or techniques.', 'Please give me a refined codebook, with examples, based on all X batches of data so far.', 'Hi ChatGPT, I want to analyze the following interaction between an instructor and some students: [DATA] Please give me a codebook to analyze the instructional methodologies and the sentiment within this interaction.']","['Iterative prompt refinement based on best practices from prompt engineering frameworks', 'Batch processing of data to fit within model token limits (e.g., dividing transcripts into batches of 77–98 lines to stay within 4096 token limit)', 'Testing prompt consistency across sessions, browsers, and computers to ensure reproducibility (e.g., repeated prompt runs with no more than two codes difference across runs)', 'Explicit task specification in prompts (clear, concise, and specific task descriptions)', 'Human-in-the-loop review and correction of model outputs (e.g., replacing hallucinated example quotes with genuine dataset quotes)', 'Prompting for codebook refinement after every few data batches', 'Grouping and merging similar codes post-generation based on frequency and conceptual similarity']","ChatGPT (GPT-4), web-based chatbot version, 4096 token context window, no API used","['Hybrid approaches (combining human and ChatGPT involvement in codebook development or refinement) produced codebooks that were more reliably applied by human coders and rated as higher quality compared to fully manual or fully automated approaches.', 'Automating early stages of codebook development with ChatGPT reduced the overall time required to complete the process.', 'The fully automated (ChatGPT-only) approach was an outlier, producing codebooks with lower utility, lower inter-rater reliability, and less conceptual overlap with other approaches.', 'Hybrid and fully human approaches produced similar codebooks, while the fully automated approach generated more novel but less relevant themes and missed some prevalent themes.', 'Human participation remains essential for ensuring codebook quality, even when automation is used for codebook development or refinement.']","['Time spent on codebook development and refinement (in minutes)', 'Human coder Likert-scale ratings of codebook utility (ease of use, clarity, mutual exclusivity, exhaustiveness; scale 1-5)', 'Cohen’s kappa (κ) for inter-rater reliability across two rounds of coding', 'Percent agreement between coders', 'Conceptual overlap analysis (number and categories of overlapping codes across codebooks)']","Four codebooks (manual, fully automated, and two hybrid approaches) were independently developed and then applied by pairs of human coders (not involved in codebook creation) to the same qualitative interview data. Coders independently coded transcripts, completed surveys rating codebook utility, and participated in social moderation to resolve discrepancies. Inter-rater reliability was assessed before and after moderation. Conceptual overlap was evaluated by independent researchers comparing code pairs across codebooks.","Hybrid approaches achieved the highest ratings for codebook clarity, mutual exclusivity, and ease of use. They also demonstrated the highest average Cohen’s kappa values after social moderation (up to 0.70), and the greatest conceptual overlap with other codebooks. The fully automated approach had the lowest utility ratings (e.g., mutual exclusivity 1.5/5), lowest inter-rater reliability (average κ = 0.21–0.37), and least conceptual overlap.","['Study focused on inductive codebook development, though some references to deductive coding and frameworks are included.', 'Each codebook was developed by a single researcher to avoid bias, which may not reflect typical collaborative qualitative analysis practices.', 'Potential individual variation in time spent and coding quality due to differences between researchers.', 'Coding instructions and time spent on achieving inter-rater reliability were not strictly controlled across coder pairs.', 'Sample size limited to transcripts from four tutoring sessions, which may affect generalizability.', 'Some codes did not appear in all datasets, limiting calculation of agreement for those codes.', 'ChatGPT hallucinated example quotes in some conditions, requiring human correction.']","['Cohen’s kappa (κ) used to assess consistency of code applications between coders', 'Percent agreement calculated across two rounds of paired independent coding', 'Multiple rounds of coding with social moderation techniques to resolve inconsistencies', 'Testing prompt consistency for ChatGPT responses across sessions, browsers, and computers', 'Replication of prompt tests on multiple data subsets to confirm response stability', 'Inter-rater reliability established for conceptual overlap coding (Cohen’s κ = 0.86)']","['Human review and revision of codebooks generated or refined by ChatGPT to address errors and inconsistencies', 'Pilot testing codes during codebook refinement', 'Survey of coders to rate codebook utility (ease of use, clarity, mutual exclusivity, exhaustiveness) as a proxy for codebook quality', 'Evaluation of conceptual overlap across codebooks by independent researchers', 'Random checks for hallucinated example quotes in ChatGPT outputs, with replacement by genuine quotes from the dataset', 'Use of established codebook development frameworks (e.g., Weston et al. [40]) for manual and hybrid approaches', 'Application of best practices in prompt engineering to ensure clarity and specificity in ChatGPT tasks']","['Independent codebook development by separate researchers to avoid biasing results', 'Coders assigned to codebooks were not involved in codebook development and were unfamiliar with the data', 'Coders were blinded to the approach used to generate their assigned codebook', 'Exclusive assignment of each researcher to a single codebook to prevent order effects', 'Social moderation sessions for coders to discuss and resolve coding inconsistencies', 'Human intervention required to review and correct ChatGPT outputs, particularly for hallucinated examples', 'No participation of codebook developers in coding or moderation sessions to avoid influencing coder interpretations']","['Systematic comparison of four codebook development pipelines for qualitative interview data: fully manual, fully automated (ChatGPT-only), and two hybrid human-LLM workflows (human code development with ChatGPT refinement, and ChatGPT code development with human refinement).', 'Empirical evaluation of ChatGPT (GPT-4) as a tool for automating inductive codebook development and refinement in educational research interview transcripts.', 'Introduction of a structured, batch-based workflow for integrating ChatGPT into codebook development and refinement, including prompt engineering and iterative human-LLM collaboration.', 'Quantitative and qualitative assessment of codebook utility, inter-rater reliability, and conceptual overlap across codebooks generated by different pipelines.', 'Identification of the limitations of fully automated LLM-based codebook development, highlighting the necessity of human oversight for quality and reliability.']","['Acceleration of qualitative codebook development for large-scale educational interview datasets by leveraging hybrid human-LLM workflows.', 'Provision of prompt engineering strategies and batching techniques for researchers seeking to use ChatGPT for qualitative coding tasks.', 'Guidance for integrating ChatGPT into existing qualitative analysis pipelines to improve efficiency without sacrificing codebook quality or reliability.', 'Framework for evaluating codebook quality using coder ratings (ease of use, clarity, mutual exclusivity, exhaustiveness) and inter-rater reliability metrics (Cohen’s kappa).']","['Further investigation into optimal division of labor between humans and LLMs in qualitative coding, including more granular control over prompt design and workflow structure.', 'Exploration of reproducibility and consistency issues in LLM-generated codes, including strategies for mitigating hallucinations and non-reproducible outputs.', 'Extension of the comparative framework to other qualitative data types, domains, and LLM architectures.', 'Development of best practices for time allocation and coder training in hybrid human-LLM qualitative analysis pipelines.', 'Investigation of the impact of collaborative and iterative human-LLM codebook development on construct validity and codebook comprehensiveness.']","Hybrid human-LLM approaches demonstrated improved efficiency over fully manual pipelines, reducing total codebook development time (e.g., fully automated approach: 113 min; hybrid approaches: 167–245 min; manual: 220 min). However, fully automated LLM pipelines produced lower-quality, less reliable, and less conceptually comprehensive codebooks, indicating that scalability gains from automation must be balanced with human oversight to ensure codebook validity and reliability. Batch processing and prompt engineering are critical for managing LLM context window limitations and maintaining workflow scalability.",extracted_pages_134_149
16094069241231168,An Examination of the Use of Large Language Models to Aid Analysis of Textual Data,"['Robert H. Tai', 'Lillian R. Bentley', 'Xin Xia', 'Jason M. Sitt', 'Sarah C. Fankhauser', 'Ana M. Chicas-Mosier', 'Barnas G. Monteith']",2024,International Journal of Qualitative Methods,https://doi.org/10.1177/16094069241231168,"qualitative research methodology, computational text analysis, large language models","deductive qualitative coding using large language models (LLMs) as analytic instruments, with comparison to traditional human coding",codebook-driven deductive analysis based on pre-defined conceptual codes derived from prior inductive work; codes are linked to theoretical constructs relevant to researcher identity and scientific career development,125,"chemistry, physics, and chemical engineering graduate students, postdocs, scientists, research engineers, and individuals who had left scientific research; drawn from Project Crossover: A Study of the Transition from Student to Scientist",semi-structured interviews; interviews were recorded and transcribed,"semi-automated (human-in-the-loop, LLM-assisted deductive coding)","['ChatGPT 3.5 (OpenAI)', 'Dedoose (qualitative analysis software)']","['Large Language Model (LLM)-assisted deductive coding', 'Iterative prompt-based code detection', 'Pseudo-random number generator (PRNG) for response variation', 'Calculation of Large Language Model Quotient (LLMq) as an outcome metric']","['Selection and transcription of interview excerpts', 'Development of a codebook with clear definitions and examples', 'Design of contextually relevant, structured prompts for LLM input']","['Input of codebook and interview text into LLM (ChatGPT 3.5)', 'Prompting LLM to identify presence/absence of predefined codes (binary query)', 'Requesting supporting evidence (quotes) for each code detected', 'Iterative submission of the same prompt and text (logging out/in between iterations to reset LLM state)', 'Recording LLM responses for each iteration (160 per text sample)', 'Binary coding of LLM outputs (1 = code present, 0 = code absent)', 'Calculation of LLMq (proportion of positive responses per code per text across iterations)']","['Comparison of LLM coding results to traditional human coding', 'Resolution of discrepancies through group discussion among human coders', 'Interpretation of LLMq stability and convergence across iterations', 'Use of LLMq as a validation and reliability metric for code identification']","Deductive coding using a codebook with five predefined conceptual codes (Autonomy, Persistence, Perception of Own Identity or Self, Novelty, STEM Interests); binary code presence/absence per excerpt; codebook-driven prompt design for LLM input",codebook-driven deductive binary prompting,"['Can you find the five characteristics in the transcript below, yes or no? If yes, give us the quote.\n[Text 1]', ""We defined the characteristics below:\n1. Autonomy: is the ability to be self-driven in STEM research\n2. Persistence: is the continuance in a course of action in spite of difficulty\n3. 'Perception of own identity or self': is the internal recognition as an individual who can talk about research with an expert in the discipline or confidence\n4. Novelty: is the desire to create new knowledge or knowledge new to them\n5. STEM interests: is having an interest in a STEM field.""]","['Use of a structured codebook with explicit definitions for each code', 'Contextually relevant prompts to reduce LLM hallucinations', 'Binary (yes/no) queries for each code per text excerpt', 'Request for supporting evidence (quotes) for each code identified', 'Consistent prompt structure across all iterations and texts', 'Iterative prompting with session resets (log out/in) to induce response variability and simulate multiple coders', ""Conservative coding: ambiguous or vague LLM responses coded as 'no'"", 'Limiting input text length to LLM token constraints (2048–4096 tokens for ChatGPT 3.5)']","ChatGPT 3.5 (OpenAI), autoregressive LLM with >175B parameters, default randomness (temperature=1), accessed via web interface; methodology generalizable to other LLMs (e.g., BingChat, Bard AI, Claude 2, LLaMa 2, ErnieBOT); input limited to 2048–4096 tokens per prompt","['Large Language Models (LLMs), specifically ChatGPT 3.5, can be systematically used to support deductive qualitative coding of interview data.', 'LLM-based coding, when provided with a clear codebook and contextually relevant prompts, produces results that are consistent with traditional human coding, especially when multiple iterations are performed.', 'The study introduces the Large Language Model quotient (LLMq), a metric representing the proportion of positive code identifications across multiple LLM iterations, which stabilizes after approximately 40 iterations.', 'LLM-based analysis can serve as a supplementary tool for validation, efficiency, and bias reduction in qualitative research, offering nearly unlimited inter-rater measures.', 'Areas of misalignment between LLM and human coding can prompt valuable reflection and refinement of code definitions among researchers.', 'LLMs are not intended to replace human coders but can augment traditional qualitative analysis by providing systematic, repeatable, and scalable coding support.']","['Large Language Model quotient (LLMq): proportion of positive code identifications per total iterations', 'Comparison of LLMq values to traditional human coder agreement', 'Stability of LLMq values across increasing numbers of iterations', 'Qualitative comparison of code presence/absence between LLM and human coders']","Three interview excerpts were coded for five deductive codes using both LLM (ChatGPT 3.5) and three independent human coders. For the LLM, each prompt (codebook + text) was entered 160 times (each time after logging out and back in to maximize stochasticity), and the presence/absence of each code was recorded per iteration. LLMq was calculated at multiple iteration thresholds (5, 10, 20, 40, 80, 160). Human coders worked independently and then resolved discrepancies through discussion. LLMq results were compared to human coding outcomes for alignment and divergence.","LLMq values plateaued and stabilized after approximately 40 iterations, indicating consistent LLM coding. For texts where codes were clearly present, LLMq values exceeded 0.8–1.0, matching human coder consensus. For ambiguous texts, both LLM and human coders showed lower agreement. LLMq provided a nuanced, probabilistic measure of code presence, and a suggested cutoff of 0.95 (95% positive detection) was proposed for strong confirmation.","['LLMs rely on patterns in their training data; absence of specific linguistic nuances or subtleties may limit model understanding.', 'Quality and structure of input data affect LLM output; noisy, unstructured, or biased data can lead to inaccuracies or hallucinations.', 'LLMs have input length limitations (e.g., ChatGPT 3.5 default limit of 2048 tokens, extendable to 4096 with subscription), which may restrict analysis of longer texts or require segmentation.', 'LLMs may generate hallucinations—nonsensical or illogical outputs—especially with adversarial or ambiguous prompts.', 'LLM outputs are stochastic; single outputs are not reliable, necessitating multiple iterations for stable results.', 'LLMs are not autonomous and require carefully designed, contextually relevant prompts to generate valuable data.', 'Current LLMs are not domain-specific; future improvements in domain-specific training may enhance reliability and validity.', 'LLM-based coding should not replace human judgment; interpretation and prompt design remain essential researcher responsibilities.']","['Inter-rater reliability using Cohen’s kappa statistic', 'Inter-rater reliability using Fleiss’ kappa statistic', 'Calculation of Large Language Model Quotient (LLMq) across multiple iterations', 'Comparison of LLM coding outputs to traditional human coding', 'Stability of LLMq values across increasing iterations']","['Use of a detailed codebook with clear definitions and example quotes for deductive coding', 'Contextually relevant and structured prompts to minimize LLM hallucinations', 'Binary coding scheme (yes/no) with conservative interpretation for ambiguous responses', 'Post-hoc comparison of LLM outputs with traditional coder results for confirmatory analysis', 'Iterative refinement of code definitions based on discrepancies between LLM and human coding', 'Thresholding LLMq values (e.g., 0.950 as a cutoff for strong confirmation, analogous to p-value < 0.05)']","['Multiple coders independently coding and resolving disagreements through discussion', 'Use of LLM as an additional rater to identify and avoid potential implicit bias from researchers', 'Iterative application of codebooks and prompts to reduce subjectivity and increase alignment', 'Human review of LLM outputs to assess and correct for hallucinations or misclassifications', 'Conservative coding of ambiguous LLM responses as negative to avoid over-attribution', 'Screening and careful selection of input data to avoid noisy or biased transcripts']","['Proposes a systematic methodology for using Large Language Models (LLMs) to support traditional deductive coding in qualitative research.', 'Introduces the Large Language Model quotient (LLMq) as a quantitative measure representing the proportion of positive code identifications across multiple LLM iterations.', 'Demonstrates a recursive, multi-iteration LLM analysis pipeline to assess the stability and reliability of deductive coding outputs.', 'Provides empirical comparison between LLM-based coding and traditional human coding, highlighting areas of alignment and divergence.', 'Establishes LLMs as a potential supplementary tool for validation and reliability assessment in qualitative data analysis.']","['LLMs can be used as an efficient screening tool to identify the presence of deductive codes in large volumes of interview data, reducing manual labor.', 'LLMq enables researchers to quantify the consistency of code identification, supporting post-hoc validation of traditional coding results.', ""LLMs can serve as an independent 'rater' to check for implicit bias and prompt codebook refinement through external review."", 'Iterative LLM analysis can highlight ambiguous or contested coding areas, facilitating deeper team discussions and code definition adjustments.', 'LLMs can be integrated into existing qualitative data analysis workflows (e.g., with software like Dedoose) to augment human analysis.']","['Exploration of LLMs for inductive qualitative analysis, including theme and code generation from raw textual data.', 'Development of domain-specific LLMs trained on refined, context-rich datasets to improve code identification accuracy and reduce iteration requirements.', 'Investigation of optimal LLMq cutoff thresholds for code confirmation and their statistical justification.', 'Assessment of LLM performance across diverse qualitative research domains and languages.', 'Evaluation of LLM integration with other computational text analysis tools and mixed-methods research designs.']","LLMs offer high scalability for qualitative analysis by enabling rapid, repeated coding across large datasets with minimal human intervention. The iterative approach leverages LLM stochasticity to approximate population-level coding trends, and the LLMq metric stabilizes with sufficient iterations (typically beyond 40). However, scalability is constrained by input length limits (e.g., 2048–4096 tokens in ChatGPT 3.5), potential data quality issues, and the need for careful prompt engineering to mitigate hallucinations. As LLMs and training datasets expand, scalability and reliability are expected to improve, facilitating efficient large-scale qualitative analysis.",tai-et-al-2024-an-examination-of-the-use-of-large-language-models-to-aid-analysis-of-textual-data
